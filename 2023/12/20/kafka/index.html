<!DOCTYPE html><html lang="ch" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><title>Kafka | 后端开发</title><meta name="keywords" content="中间件,分布式"><meta name="author" content="XIAO YANG"><meta name="copyright" content="XIAO YANG"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#f7f9fe"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-touch-fullscreen" content="yes"><meta name="apple-mobile-web-app-title" content="Kafka"><meta name="application-name" content="Kafka"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#f7f9fe"><meta name="referrer" content="no-referrer"><meta property="og:type" content="article"><meta property="og:title" content="Kafka"><meta property="og:url" content="https://yangxiao23.github.io/yangxiao.github.io/2023/12/20/kafka/index.html"><meta property="og:site_name" content="后端开发"><meta property="og:description" content="kafka"><meta property="og:locale" content="ch"><meta property="og:image" content="https://yangxiao23.github.io/yangxiao.github.io/img/headimg.jpg"><meta property="article:author" content="XIAO YANG"><meta property="article:tag"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://yangxiao23.github.io/yangxiao.github.io/img/headimg.jpg"><meta name="description" content="kafka"><link rel="shortcut icon" href="/yangxiao.github.io/favicon.ico"><link rel="canonical" href="https://yangxiao23.github.io/yangxiao.github.io/2023/12/20/kafka/"><link rel="preconnect" href="//cdn.cbd.int"/><meta name="google-site-verification" content="xxx"/><meta name="baidu-site-verification" content="code-xxx"/><meta name="msvalidate.01" content="xxx"/><link rel="stylesheet" href="/yangxiao.github.io/css/index.css"><link rel="stylesheet" href="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  linkPageTop: undefined,
  peoplecanvas: {"enable":true,"img":"https://upload-bbs.miyoushe.com/upload/2023/09/03/125766904/ee23df8517f3c3e3efc4145658269c06_5714860933110284659.png"},
  postHeadAiDescription: {"enable":true,"gptName":"AnZhiYu","mode":"local","switchBtn":false,"btnLink":"https://afdian.net/item/886a79d4db6711eda42a52540025c377","randomNum":3,"basicWordCount":1000,"key":"xxxx","Referer":"https://xx.xx/"},
  diytitle: undefined,
  LA51: undefined,
  greetingBox: undefined,
  twikooEnvId: '',
  commentBarrageConfig:undefined,
  root: '/yangxiao.github.io/',
  preloader: {"source":3},
  friends_vue_info: undefined,
  navMusic: true,
  mainTone: undefined,
  authorStatus: {"skills":["🤖️ 数码科技爱好者"]},
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简","rightMenuMsgToTraditionalChinese":"转为繁体","rightMenuMsgToSimplifiedChinese":"转为简体"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":330},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    simplehomepage: true,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"copy":true,"copyrightEbable":false,"limitCount":50,"languages":{"author":"作者: XIAO YANG","link":"链接: ","source":"来源: 后端开发","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","copySuccess":"复制成功，复制和转载请标注本文地址"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#425AEF","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.min.js',
      css: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  shortcutKey: undefined,
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  configTitle: '后端开发',
  title: 'Kafka',
  postAI: '',
  pageFillDescription: 'Kafka, kafka总体概览, 服务端参数配置, 生产者相关, 序列化器, 分区器, 拦截器, kafka生产者客户端原理, 元数据的更新, 生产者重要参数, 消费者和消费组, 客户端开发, 必要的参数配置, 订阅主题和分区, 反序列化, 消费者消费, 位移提交, 控制或关闭消费, 指定位移消费, 再均衡, 消费者拦截器, 消费者重要参数, 主题和分区, 主题的管理, 创建主题, 分区副本的分配, 查看主题, 修改主题, 配置管理, 删除主题, 初识KafkaAdminClient, 主题合法性验证, 分区的管理, 优先副本的选举, 分区重分配, 复制限流, 修改副本因子, 如何选择合适的分区数, 日志存储, 文件目录布局, 消息压缩, 日志索引, 偏移量索引, 时间戳索引, 日志清理, 日志删除, 日志压缩, 磁盘存储, 页缓存, 磁盘Ix2FO流程, NOOP, CFQ, DEADLINE, ANTICIPATORY, 零拷贝, 深入服务端, 协议设计, 时间轮, 延时操作, 控制器, 控制器的选举及异常恢复, 分区leader的选举, 参数含义, kafka客户端, 分配分区策略, RangeAssignor分配策略, RoundRobinAssignor分配策略, StickyAssignor分配策略, 自定义分区分配策略, 消费者协调器和组协调器, 再均衡的原理, 选举消费组中的leader, 选举分区分配策略, consumer_offsets主题, 事务, 幂等, 事务, 可靠性, 副本刨析, ISR的伸缩, 日志同步机制, kafka高级应用, 过期时间（TTL）, 延时队列, 消息路由, 消息轨迹, Kafka简介, kafka消息删除机制, Producer消息路由, Push vs Pull, kafka副本同步机制, Partition Recovery机制, kafka高可用设置, Data Replication, Broker failover过程简介, 创建x2F删除Topic, Broker相应请求流程, Broker启动过程, Controller Failover, Partition重新分配, Follower从Leader Fetch数据, High Level Consumer Rebalance, coordinator和Rebalance, High Level Consumer, Low Level Consumer, 如何通过中心Coordinator实现Rebalance总体概览一个多分区多副本基于协调的分布式消息系统分布式流式处理平台流数据是一组顺序大量快速连续到达的数据序列一般情况下流数据可被视为一个随时间延续而无限增长动态数据的集合可以扮演的角色消息系统具备系统解耦冗余存储流量消峰缓冲异步通信拓展性和可恢复性还提供消息顺序性保障和回溯消费存储系统把消息持久化磁盘可以降低数据丢失风险流式处理平台不仅为每个流行的流式处理框架提供了可靠的数据来源还提供了一个完整的流式处理类库比如窗口连接变换和聚合等各类操作是用来负责集群元数据管理控制器选举等操作中消息以主题为单位进行归类同一主题下不同分区包含的消息是不同的分区在存储层面可以看作一个可追加的日志文件消息在被追加到分区日志文件的时候都会分配一个特定的偏移量不跨分区分区有序主题不有序每条消息被发送到之前会根据分区规则选择存储到某个具体分区多副本机制提高了系统的容灾能力副本之间是一主多从关系负责读写请求负责与保持消息同步以及故障恢复消费端也具备一定容灾能力采用拉模式从服务端拉取信息并且保存消费的具体位置当消费者宕机后恢复上线时可以根据保存的消费位置重新拉取所需要的信息进行消费不会造成消息丢失分区所有副本统称为所以与副本保持一定程度同步的副本包括组成与副本同步之后过多的副本组成副本负责维护和跟踪中所有副本的滞后状态当副本落后太多或失效副本会把集合中剔除默认情况下当副本发生故障时只有在集合中的副本才有资格被选举为新的而在集合的副本没有机会高水位表示一个特定的偏移量消费者只能拉取这个之前的消息当前日志文件中下一条待写入消息的分区集合中每个副本都会维护自身的而集合中最小的即为分区的的复制机制既不是完全的同步复制也不是单纯的异步复制机制有效权衡数据可靠性和性能之间的关系服务端参数配置指明要连接的集群地服务地址包括端口号多个节点通过逗号隔开如果想利用一个集群管理多个集群可以加上类似指明监听客户端连接的地址列表即为客户端要连接的入口地址列表配置格式为当前支持的协议有等此参数默认为如果有多个地址中间使用逗号分隔如果不指定主机名则表示绑定默认网卡可能会绑定到这样就无法对外提供服务所以主机名最好不要为空作用和类似默认值也为不过主要用于环境公有云上的机器一般配置多块网卡包含私有网卡和共有网卡对于这种情况可以设置参数绑定公网供外部客户端使用而配置参数来绑定私网地址供间通信使用指定集群中的唯一标识如果没有设置那么会默认自动生成一个和把所有消息都保存在磁盘上这两个参数用来配置日志文件存放的根目录一般情况用来配置单个根目录而用来配置多个根目录逗号分割优先级大于默认情况只配置为该参数用来指定所能接收信息的最大值默认为如果生产者发送的消息大于这个参数所设置的值那么就会报异常如果要修改这个参数还要考虑客户端参数参数等影响用于限制和请求的大小定义消费者可以接收的最大消息大小用来标识生产者的唯一标识生产者相关中生产消息对象主题分区号消息头部键可以用来计算分区好进而让消息发往特定分区值消息的时间戳消息头部版本引入这个属性大多时候用来设定一些与应用相关的信息用来指定消息的键它不仅是消息的附加信息还可以用来计算分区号进而可以让消息发往特定的分区同一个的消息会被划分到同一个分区中有的消息还可以支持日志压缩的功能消息体一般不为空为空则表示特定的消息墓碑消息消息的时间戳它有和两种类型前者表示消息创建的时间后者表示消息追加到日志文件的时间在生产者客户端中必须要填写的参数指定生产者客户端连接集群所需的地址清单不必全部列出生产者能从给定的查找到其它的信息建议设置两个以上和端接口消息必须以字节数组形式存在设定对应的客户端默认值为空字符串不设置会自动生成一个非空字符串是线程安全的可以在多个线程中共享单个实例也可以将实例进行池化供其它线程调用创建生产者实例和构建消息之后就可以开始发送消息发送消息主要有三种模式发后即忘同步异步发后既忘只负责往发送消息不关心消息是否正确到达在某些时候发生不可重试异常时会造成消息丢失性能最高可靠性最差同步发送可靠性最高要么发送成功要么发生异常性能会差很多需要阻塞等待一条消息发送成功才能发送另一条异步发送指定回调函数在返回响应时调用该函数进行异步发送确认一般会发生两种类型的异常可重试的异常和不可重试的异常对于可重试的异常只需要在配置次数内恢复就不会抛出异常生产者异步发送回调函数确认对于同一个分区而言如果消息于之前先发送那么就可以保证对应的在之前调用回调函数的调用也可以保证分区有序发送完这些消息之后需要调用的方法回收资源方法会阻塞等待之前所有发送请求完成后再关闭也提供带有时间参数方法超时强制退出序列化器生产者需要用序列化器把对象转换成字节数组才能通过网络发送给消费者需要用反序列化器把从收到的字节数组转换成相应的对象生产者序列化器格式分区器消息在通过方法发往的过程中有可能需要经过拦截器序列化器和分区器的一系列之后才能真正地被发往如果在消息中指定了字段那么就不需要分区器的作用分区器默认根据字段来计算的值为消息分配分区如果不为那么默认的分区器会对进行哈希算法根据计算的哈希值计算出分区号拥有相同的消息被写入同一个分区如果为那么消息将会以轮询的方式发往主题内的各个可用分区如果不为那么计算的得到的分区号会是所有分区中的任意一个如果为那么计算得到的分区号仅为可用分区中的任意一个在不改变主题分区数量的情况下与分区之间的映射可以保持不变不过一旦主题中增加了分区那么就难以保证与分区之间的映射关系默认每个实例都会创建自己的分区器实例拦截器拦截器是在中就已经引入的一个功能一共有两种拦截器生产者拦截器和消费者拦截器生产者拦截器既可以用来在消息发送前做一些准备工作比如按照某个规则过滤不符合要求的消息修改消息的内容等也可以用来在发送回调逻辑前做一些定制化的需求比如统计类工作自定义拦截器需要实现这个接口消息序列化计算分区之前调用消息被应答之前或消息发送失败时调用关闭拦截器执行时的资源清理接口中的方法主要用来获取配置信息及初始化数据方法这个方法运行再的线程中这个方法实现代码逻辑越简单越好否则影响消息的发送速度多拦截器之间使用进行分割生产者客户端原理整体生产者客户端由两个线程协调运行这两个线程分别是主线程和线程在主线程中由创建消息然后通过拦截器序列化器和分区器的作用之后缓存到消息收集器线程负责从消息收集器中获取消息并将其发送到中消息收集器主要用来缓存消息以便线程可以批量发送进而减少网络传输的资源消耗以提升性能消息收集器的缓存大小通过生产者客户端参数配置如果生产者发送消息的速度超过发送到服务器的速度则会导致生产者空间不足这时候调用方法要么被阻塞要么抛出异常这个取决于参数的配置主线程中发送过来的消息都会被追加到的某个双端队列为每个分区都维护了一个队列中的内容是消息写入缓存时追加到双端队列的尾部读取消息时从双端队列的头部读取可以包含一至多个通常被称为消息批次会被包含在中这样可以使字节的作用更加紧凑与此同时将较小的拼凑成一个较大的可以减少网络请求的次数以提升整体的吞吐量消息在网络上都是以字节的形式传输的在发送之前需要创建一块内存区域来保存对应的消息在生产者客户端中通过实现消息内存的创建和释放的内部还有一个它主要用来实现的复用以实现缓存的高效利用只能实现特定大小的内存复用的大小和参数有着密切关系当一条消息流入时会先寻找与消息分区所对应的双端队列如果没有则新建在从这个双端队列的尾部获取一个如果没有则新建查看中是否还可以写入这个如果可以则写入如果不可以则需要创建一个新的在新建时评估这条消息的大小是否超过如果不超过那么就以参数大小来创建这样在使用完这段区域之后可以通过的管理进行复用如果超过那么就以评估的大小来创建这段内存区域不会被复用从中获取缓存的消息之后会进一步将原本分区的保存形式转换变为的形式表示集群的节点在转换成的形式之后会进一步封装成形式这样就能将发往各个请求在线程发往之前还会保存到中保存对象的具体形式它的主要作用时缓存了已经发出去但还没有收到响应的请求还提供了很多管理类的方法并且通过配置参数还可以限制每个连接客户端和之间最多缓存的请求数默认为最多缓存个未响应的请求超过了该数值之后就不能再向这个连接发送更多的请求还可以获得即所有中负载最小的那一个负载大小通过每个还未确认的请求决定选择发送请求可以让请求尽快发出避免因网络堵塞等异常影响整体进度元数据的更新上述消息我们只知道要将此消息追加至指定主题的某个分区所对应的副本之前首先需要知道主题的分区数量然后经过计算得出目标分区之后需要知道目标分区的副本所在的节点地址端口等信息才能建立连接最终才能将消息发送至以上所需要的信息都属于元数据信息集群的元数据具体记录了集群中有哪些主题这些主题有哪些分区每个分区的副本分配在哪个节点上副本分配在哪些节点上哪些副本在等集合中集群中有哪些节点等当客户端中没有需要使用的元数据信息时或者超时间没有更新元数据都会引起元数据的更新操作当需要更新元数据会先挑选出然后这个发送请求来获取具体的元数据信息这个操作由线程发起在创建完之后同样会存入元数据由线程负责更新但是主线程也需要这些信息数据同步通过和关键字保障生产者重要参数用来指定分区中必须有多少个副本收到这条消息之后生产者才会认为这条消息是成功写入的涉及消息可靠性和吞吐量的权衡分为三种类型默认值生产者发送消息之后只要分区的副本成功写入消息那么他就会收到来自服务端的成功响应如果消息无法写入那么生产者就会收到一个错误的响应为了避免消息丢失生产者可以选择重发消息存在消息被认定成功写入之后发生丢失情况写入成功后崩溃中其它没有同步生产者发送消息之后不需要等待任何服务端的响应如果在消息从发送到写入的过程中出现某些异常导致没有收到这条消息生产者也无从得知吞吐量最大或生产者在消息发送之后需要等待中所有副本都成功写入消息之后才能收到服务端的成功响应可靠性最高但不意味着不会丢失数据如果只有副本退化成的情况了限制生产者客户端能发送的消息的最大值默认和用来配置生产者重试的次数默认为即在发生异常的时候不进行任何重试动作消息从生产者发送到成功写入服务器之前可能发生一些临时性的异常如网络抖动副本选举等这种异常往往可以自行恢复生产者可以通过配置进行内部重试默认用来设定两次重试之间的时间间隔消息的压缩方式默认消息压缩是时间换空间的一种做法对消息进行压缩可以降低网络指定在多久之后关闭闲置的连接默认分钟指定生产者发送之前等待更多消息加入的时间默认为生产者客户端会在被填满或等待时间超过值发送出去增大这个值可以提供吞吐量但会增加延迟设置接收消息缓冲区大小设置为为操作系统默认值设置发送消息缓冲区的大小配置等待请求响应的最长时间这个参数要比端要大这样可以减少因客户端重试而引起的消息重复概率配置参数限制了单个连接上未确认的并发请求数生产者客户端用于缓存消息的缓存区大小中方法和方法的阻塞时间当生产者的发送缓存区或者没有可用的元数据时这个方法就会阻塞是否开启幂等性功能设置事务必须唯一如果将配置为非零值并且参数配置大于那么就会出现乱序的现象发送顺序为失败重试发送之前成功发送出现乱序消费者和消费组消费者负责订阅中的主题并从订阅的主题上拉取消息每个消费者都有一个对应的消费组当消息发布到主题后只会被投递给订阅它的消费者中的一个消费者每个消费者只能消费所分配到的分区中的消息每一个分区只能被一个消费组中的一个消费者所消费当消费组内的消费者个数变化分区分配一般会进行改变消费者与消费组这种模型可以让整体的消费能力具备横向伸缩性可以通过增加减少消费者的数量来提高降低整体的消费能力对于分区数固定的情况一味的增加消费者并不会让消费能力上升如果消费者过多可能出现有消费者分配不到任何分区以上都是结论都是基于默认分区分配策略进行分析消息中间件一般有两种消息投递模式点对点和发布订阅模式点对点模式是基于队列的消息生产生发送消息到队列消息消费者从队列中接收消息发布订阅模式定义了如何向一个内容节点发布和订阅消息这个内容节点就是主题主题可以认为是消息传递的中介发布订阅模式在消息的一对多广播时采用同时支持两种消息传递模式如果所有消费者都隶属同一个消费组那么消息会被投递单个消费者相当于点对点如果所有消费者隶属不同的消费组那么所有消息都会广播给所有消费者消费者并非逻辑上的概念它是实际的应用实例可以是一个线程进程客户端开发之后推出使用编写的客户端一个正常的消费逻辑具备以下几个步骤配置消费者客户端参数及创建相应的消费者实例订阅主题拉取消息并消费提交消费位移关闭消费者实例必要的参数配置指定连接的集群所需的地址清单消费者隶属的消费组默认为如果为空则会报错和与生产者的和参数对应将从获取的字节数组转换成具体对象实例的反序列化器对应的客户端订阅主题和分区一个消费者可以订阅一个或多个主题可以使用方法可以以集合形式订阅多个主题也可以用正则表达式的形式订阅特定模式的主题订阅同时可以设置再均衡监听器如果消费者采用正则表达式的方式订阅再之后的过程中如果有人又创建了新的主题并且主题的名字和正则表达式相匹配那么这个消费者就可以消费到新添加到主题中的消息消费者不仅可以通过方法订阅主题还可以直接订阅某些主题的特定分区在中提供了一个方法来实现这些功能类属性方法可以用来查询指定主题元数据可以通过方法取消主题的订阅可以通过集合或者方式进行取消订阅如果将订阅的集合设置为空集合相当于取消订阅如果没有订阅任何主题或分区执行消费程序会抛出异常通过方法订阅主题具有消费者自动再均衡的功能再多个消费者的情况下可以根据分区分配策略来自动分配各个消费者与分区的关系当消费组内的消费者增加或减少时分区分配关系会自动调整而通过方法订阅分区时是不具备消费者自动均衡的功能的反序列化生产者有序列化器那么消费者就会有反序列化器提供了等反序列化器这些序列化器都实现了接口用来配置当前类执行反序列化如果为那么处理的时候直接返回用来关闭当前序列化器一般情况下不建议使用自定义序列化器或反序列化器因为这样会增加生产者与消费者之间的耦合度在系统升级换代的时候容易出错在实际应用中在提供的序列化器和反序列化器满足不了应用需求的前提下推荐使用等通用的序列化工具进行包装消费者消费中的消费是基于拉模式的消息的消费一般有两种模式推模式和拉模式推模式服务端主动将消息推送给消费者拉模式消费者主动向服务端发起请求来拉取消息中的消息消费是一个不断轮询的过程消费者所要做的就是重复地调用方法而方法返回的是所订阅的主题分区上的一组消息对于方法而言如果某些分区中没有可供消费的消息那么此分区对应的消息拉取的结果就为空如果订阅的所有分区都没有可供消费的消息那么方法返回为空的消息集合方法中有一个超时时间参数用来控制方法的阻塞时间在消费者缓冲区里没有可用数据时会发生阻塞的设置取决于应用程序对响应速度的要求比如需要在多长时间内将控制权移交给执行轮询的应用线程创建时间戳和消息追加到日志的时间戳经过序列化之后的大小用来获取消息集中所有分区在类中还提供按照主题维护来进行消费位移提交对于分区而言它的每个消息都有唯一的用来表示消息在分区中对应的位置消息者也有的概念消费者使用来表示消费到分区中某个消息所在的位置在新的消费者客户端中消费位移存储在内部的主题中提交的消费唯一是已经消费的位移最大值同步提交位移消费者对于位移的具体时机把握也很有讲究有可能会造成重复消费和消息丢失的现象参考下图当前操作所拉取的消息集为表示当前正在处理的位置如果拉取到消息之后就进行位移提交提交了那么当前消费遇到了异常在故障恢复之后我们重新拉取的消息是在开始的也就是说至之前的消息并未被消息出现消息丢失的现象另一种情形位移提交的动作是在消费完所有拉取的消息之后才执行那么当消费到的时候遇到了异常在故障恢复之后重新拉取消息从开始故又发生了重复消费的现象在中默认的消费位移的提交方式是自动提交由控制默认值为这个默认提交的含义是定时提交定期的周期由客户端配置默认为秒自动位移提交的动作是在方法逻辑里完成的在每次真正向服务端拉取请求之前会检查是否可以进行位移提交手动的位移提交方式可以让程序的逻辑在合适的地方进行位移提交开启手动提交功能的前提时消费者客户端参数设置为手动提交分为同步提交和异步提交可以在最后的时候通过同步提交进行提交位移把关控制或关闭消费提供了对消费速度进行控制的方法在有些应用场景我们可能需要暂停某些分区的消费而先消费其它分区当达到一定条件时在恢复这些分区的消费中使用和方法来分别实现暂停某些分区在拉取操作时返回数据给客户端和恢复某些分区向客户端返回数据的操提供了一个无参的方法来返回被暂停的分区集合可以通过调用的方法跳出消费者的逻辑是中唯一可以从其它线程里安全调用的方法调用方法后可以退出逻辑并抛出的异常跳出循环以后一定要显式关闭动作以释放运行过程中占用的各种系统资源指定位移消费在中每当消费者找不到所记录的消费位移时就会根据消费者客户端参数配置来决定从何处开始进行消费默认为表示从分区末尾开始消费表示消费者会从起始处开始消费意味着出现查不到消息位移时会抛出异常中的方法正好提供了这个功能让消费者具备回溯消费能力指定位移消费获取分区的末尾偏移量方法只能重置消费者分配到的分区的消费位置而分区的分配实在方法调用的过程中实现的在执行方法之前需要先执行一次方法等到分配到分区之后才可以重置消费位置一个分区的其实位置起初是但并不代表每日每刻都是因为日志清理的动作会清理旧的数据所以分区的起始位置会自然而然地增加提供一个方法通过来查询对应时间地分区位置该方法会返回时间戳大于等于待查询时间地第一条消息对应地位置和时间戳对应于地和字段位移越界会触发参数的执行位移越界是指直到消费为止却无法在实际分区中查找到再均衡再均衡是指分区的所属权从一个消费者转移到另一消费者的行为它为消费组提供了高可用性和伸缩性提供保障在均衡发生期间消费组内的消费者是无法读取消息的另外当一个分区被重新分配给另一个消费者时消费者当前的状态也会丢失可能会出现重复消费的情况分区原先所属的消费者没进行位移提交再均衡器用来设定发生再均衡动作前后的一些准备或收尾的动作包含两个方法再均衡开始之前和消费者停止读取消息之后可以通过这个回调方法进行位移的提交避免再均衡之后重复消费重新分配分区之后消费者开始读取消费之前调用表示再均衡之后分配到的分区消费者拦截器消费者拦截器主要在消费到消息或者在提交位移时进行一些定制化的操作消费者拦截器需要自定义实现接口需要实现三个方法方法返回之前调用这个方法中抛出异常会被捕获记录到日志不会向上传递再提交完消费位移之后调用会在方法返回之前调用拦截器的方法来对消息进行响应的定制化操作比如修改返回的消息内容按照某种规则过滤消息如果方法抛出异常那么会被捕获并记录到日志但是异常不会再向上传递使用进行消费数据过滤可能会提交错误的位移信息含有最大偏移量的消息可能会被消费者拦截器过滤了消费者也存在拦截链的概念按照参数设置的拦截器的顺序一一执行的配置的时候各个拦截器之间使用逗号隔开需要注意的是如果拦截链中某个拦截器执行失败那么下一个拦截器会接着从上一个执行成功的拦截器继续执行是线程安全的然而是线程非安全的中定义了一个方法用来检测当前是否只有一个线程再操作若有其它线程正在操作则会抛出异常中每个公用方法在执行动作都会调用这个方法只有方法例外方法底层是通过原子类计数实现消费者重要参数配置在一次拉取请求中能从拉取的最小数据量默认值为在收到的拉取请求时如果返回给小于这个参数所配置的值那么它就需要进行等待直到数据量满足这个参数的配置大小调大这个参数能一定程度提高吞吐量也会造成更大的延迟用来配置在一次拉取请求中从拉取的最大数据量默认能够接收最大消息的大小通过服务端参数来设置如果这个参数设置的值比任何一条写入的消息要小那么会不会造成无法消费该参数设定的不是绝对的最大值如果在第一个非空分区中拉取的第一条消息大于该值那么该消息将仍然返回以确保消费者可以继续工作用来指定的等待时间默认如果中没有足够多的消息而满足不了参数的要求那么最终会等待降低这个值可以相应降低延迟用来配置从每个分区里返回给的最大数据量默认用来配置在一次拉取请求中拉取的最大消息数默认值为条如果消息的大小都比较小可以适当调大这个参数值提升一定的消费速度用来指定在多久之后关闭限制的连接内部有两个主题和用来指定中的内部主题是否可以向消费者公开默认为如果设置为那么只能使用的方法不能使用的方式来订阅内部主题设置为则没有这个限制用来限制接收消息缓冲区的大小默认为如果设置则使用操作系统默认值用来设置发送消息缓冲区的大小默认值为等待请求的最大响应时间默认配置元数据的过期时间默认分钟如果元数据在此参数所限定的时间范围内没有进行更新则会被强制更新即使没有任何分区变化或加入配置尝试重新连接指定主机之前的等待时间避免频繁地连接主机默认值为这种机制适用于消费者向发送地所有请求用来配置尝试重新发送失败地请求到指定地主题分区之前地等待退避时间避免在某些故障情况下频繁地重复发送默认值为配置消费者地事务隔离级别字符串类型有效值为和表示消费者所消费到的位置如果设置为那么消费者就会忽略事务未提交地消息即只能消费到地位置默认为即可消费到主题和分区主题作为消息的归类可以再细分为一个或多个分区分区可以看作为对消息的二次归类分区的划分不仅为提供了可伸缩性水平拓展的能力还可以通过多副本机制来为提供数据冗余以提高数据可靠性从的底层实现来说主题和分区都是逻辑上的概念分区可以有一至多个副本每个副本对应一个日志文件每个日志文件对应一至多个日志分段每个日志分段还可以细分为索引文件日志存储文件和快照文件等主题的管理主题管理包括创建主题查看主题消息修改主题和删除主题等脚本实际上是调用类来执行主题管理的操作主题的管理并非只有使用脚本这一种方式我们还可以通过的方式实现这种方式实际上是通过发送等请求实现的甚至可以通过直接操纵日志文件和节点实现创建主题如果端配置参数设置为那么当生产者向一个尚未创建的主题发送消息时会自动创建一个分区为默认为副本因子为默认值为的主题除此之外当一个消费者开始从未知主题中读取消息或者当任意一个客户端向未知主题发送元数据请求时都会按照和的值来创建一个相应的主题一般不建议将设置为同一个分区中的多个副本必须分布在不同的中这样才能提供有效的数据冗余脚本中还提供了一个参数来手动指定分区副本的分配方案可以省略和者两个参数脚本在创建主题时会检测是否包含或字符因为的内部做埋点时会根据主题的名称来命名名称并且将改成下划线主题命名规则必须由大小写字母数字点号连接线下划线组成不能为空不能只有点号也不能只有双点号且长度不能超过从版本开始支持指定的机架信息如果指定了机架信息则在分区副本分配时会尽可能地让分区副本分配到不同的机架上指定机架信息是通过端参数来配的当创建主题时如果中某些有机架配置某些不存在机架信息则会报错可以使用参数来忽略机架信息对分区副本的分配影响分区副本的分配在创建主题时如果使用了此参数那么就按照指定的方案来进行分区副本的创建如果没有使用参数那么就需要按照内部的逻辑来计算分配方案了按照机架信息划分成两种策略未指定机架信息和指定机架信息创建主题时实质上是在中的节点上创建与该主题对应的子节点并写入分区副本分配方案并且在节点下创建与该主题对应的子节点并写入主题相关的配置信息创建主题的实质性动作是交给控制器异步去完成的查看主题脚本有五种指令类型和使用可以添加参数可以找出包含与集群不一致配置的主题可以找出所有包含失效副本的分区查看主题中没有副本的分区这些分区已经处于离线状态修改主题当一个主题被创建之后仍然允许我们对其做一定的修改比如修改分区个数修改配置等脚本的指令提供修改分区个数时当主题中的消息中不为根据计算分区的行为会收到影响对于基于计算的主题而言建议在一开始就设置好分区数量避免以后对其进行调整目前只支持增加分区数而不支持减少分区数为什么不支持减少分区呢删除分区后分区中的消息该如何处理删除消息会导致消息的可靠性如何保证保留的话需要考虑内部复制的成本时间消息戳的处理复制过程导致的可用性可以使用修改主题的配置过时修改配置删除配置配置管理脚本是专门用来对配置进行操作的指在运行状态下修改原有的配置如此可以达到动态变更的目的不仅可以操作主题相关的配置还可以支持操作用户和客户端这个类型的配置指定查看配置的实体类型指定操作的实体名称使用指令变更配置时需要配合和这两个参数一起使用用来实现配置的增改实现配置删除即删除被覆盖的配置以恢复默认值与主题相关的配置参数在层面都有对应参数如果没有修改过主题的任何配置参乎就会使用端的作为默认值删除主题脚本中指令就可以用来删除主题主题是否删除和端配置参数有关使用脚本删除主题的行为本质上只是在中的路径上创建一个与待删除主题同名的节点以此标记改主题为待删除状态与创建主题相同的是真正删除主题的动作也是由的控制器负责实现我们可以直接通过的客户端来删除主题可以通过手动的方式删除主题主题中的元数据存储在中和路径下主题中的消息存储在或配置路径下中删除主题的步骤步骤可互换删除集群中所有与主题有关的文件删除日志文件初识如果我们希望将主题管理类的功能集成到公司的内部系统中打造集管理监控运维告警为一体的生态平台那么就需要以程序调用的方式去实现不仅可以用来管理配置和还可以管理主题主题合法性验证一般情况下在生产环境下参数会被设置为自动创建主题会被禁止脚本创建的方式一般由运维人员使用就为普通用户提供了一种方式去创建主题端中一个参数默认为它提供一个入口用来验证主题创建的合法性分区的管理优先副本的选举分区使用多副本机制提升可靠性但只有副本对外提供读写服务而只负责在内部进行消息的同步同一个不可能出现一个分区的多个副本某个分区的不可用就意味着整个分区不可用主题创建之时会默认将各个副本的副本均匀分布到各个节点但是如果出现故障转移可能会造成副本在各上分配不均匀的状况为了能够有效的治理负载失衡的概念引入优先副本所谓的优先副本是指在集合列表中的第一个副本比如主题中分区的集合列表为那么分区的优先副本即为理想情况下优先副本就是该分区的副本所以也可以称之为理想情况下要确保所有主题的优先副本在集群中均匀分布这样就保证了所有分区的均衡分布如果分布过于集中就会造成集群负载不均衡优先副本的选举就是通过一定的方式促使优先副本选举成副本以此来促进集群的负载均衡分区平衡并不意味着集群的负载均衡可以提供分区自动平衡的功能对应的端参数是默认为如果开启分区自动平衡功能的控制器会启动一个定时任务会轮询所有节点计算每个节点的分区不平衡率不平衡率非优先副本的个数分区总数是否超过默认为如果超过设定的比值则会自动执行优先副本的选举动作以求分区平衡执行周期由参数控制默认值为秒即分钟不建议在生产环境将设置为可能会造成负面的性能影响也有可能引起客户端一定时间的阻塞建议在合适的时候执行手动分区平衡脚本提供对分区副本进行重新平衡的功能优先副本选举的过程时是一个安全的过程已经过时了代替了使用示例最新可配合参数来分批手动执行指定主题分区优先副本选举但是最好是手动执行优先副本选举分区重分配当集群中的一个节点突然宕机下线这个节点上的所有分区副本都属于功能失效的状态并不会将这些失效的分区副本自动的迁移到集群中剩余的可用节点上如果放任不管不仅会影响这个集群的负载均衡还会影响服务的可靠性和可用性当集群中新增节点时只有新创建的主题分区才有可能被分配到这个节点上而之前的主题分区并不会自动分配到新加入的节点中脚本可以执行分区重分配的工作它可以在集群扩容节点失效的场景对分区进行迁移脚本的使用步骤创建一个包含主题清单的文件根据主题清单和节点清单生成一个重分配的方案根据生成的方案执行具体的重分配动作分区重分配的基本原理是先通过控制器为每个分区添加新副本增加副本因子新的副本将从分区的副本那里复制所有的数据复制完成之后控制器将旧副本从副本清单里清除恢复原先的副本因子数重分配过程中要确保足够的空间分区重分配对集群的性能有很大影响需要占用额外的资源网络和磁盘在实际操作中我们将降低重分配的力度分成多个小批次来执行以此来降低影响如果需要将某个下线那么在执行分区重分配之前最好先关闭或重启这样这个就不再是任何分区的了复制限流数据复制会占用额外的资源如果重分配的量太大必然会严重影响整体的性能尤其是业务高峰期的时候减小重分配的粒度以小批次的方式来操作是一种可行的解决思路如果某个分区的流量在某段时间非常大减少粒度不足应对可以对副本间复制流量加以限制保证重分配过程中整体服务不受影响副本间复制限流有两种实现方式和脚本脚本主要以动态配置的方式来达到限流的目的在级别有两个与复制限流相关的配置参数和前者用来设置副本复制的速度后者用于设置副本传输的速度单位为在主题级别也有两个相关的参数来限制复制的速度和分别用来设置被限制速度的主题所对应的副本列表和副本列表可以使用脚本配合参数方式可以在重分配之后自动删除复制限流的配置如果分区重分配会引起某个分期的集合变更那么这个分区中与的有关限制会应用于重分配之前的所有副本因为任何一个副本都可能是而与有关的限制会应用于所有移动的目的地修改副本因子创建主题之后可以修改分区个数同样可以修改副本因子修改副本因子的功能也是通过重分配所使用的脚本实现与分区不一样副本数还可以减少如何选择合适的分区数在中性能和分区数有着必然的关系在设定分区数时一般也需要考虑性能的因素本身提供用于生产者性能测试的和用于消费者性能测试的分区是中最小的并行操作单元对生产者而言每一个分区的数据写入是完全可以并行化的对消费者而言只允许单个分区中的消息被一个消费者线程消费一个消费组的并行消费完全依赖于分区数随着分区数增加相应的吞吐量会增加一旦分区数超过某个阈值之后整体的吞吐量不升反降可以在创建主题时指定分区数为这样可以通过分区消费一致性达到主题消费一致性日志存储文件目录布局中消息以主题为基本单位进行归类各个主题在逻辑上相互独立每个主题又可以分为一个或多个分区分区的数量可以在主题创建的时候指定也可以在之后进行修改每条消息在发送的时候会根据分区规则被追加到指定的分区中分区中每条消息会被分配一个唯一的序列号也就是偏移量如果分区规则设置得合理那么所有的消息可以均匀的分布在不同的分区中这样就可以实现水平拓展不考虑多副本的情况一个分区对应一个日志为了防止过大又引入日志分段的概念将切分成多个相当于将一个巨型文件被平均分配为多个相对较小的文件这样也便于消息的维护和清理在物理上只以文件夹的形式存储而对应磁盘上的一个日志文件和两个索引文件以及可能的其他的文件比如为后缀的事务索引文件索引文件偏移量索引文件时间戳索引文件向中追加消息是顺序写入的只有最后一个才能执行写入操作在此之前所有都不能插入数据为了便于消息的检索每个的日志文件都对应两个索引文件偏移量索引文件结尾和时间戳索引文件为文件后缀每个都有一个基准偏移量表示当前中第一条消息的日志文件和两个索引文件都是根据基准偏移量命名的版本的消息结构新增了时间戳类型同时字段的第四位用来标志时间戳是消息创建时间还是日志记录时间通过端参数进行配置消息压缩常见的压缩算法是数据量越大压缩效果越好实现的压缩方式是将多条消息一起进行压缩这样就可以保证较好的压缩效果在一般情况下生产者发送的压缩数据在中也是保持压缩状态进行存储的消费者从服务端获取的也是压缩信息消费者在处理消息之前才会解压消息这样保证了端对端的压缩日志使用哪种压缩方式是通过来配置的默认值为表示保留生产者使用的压缩方式压缩率是压缩后的大小与压缩之前对比压缩率越小越好日志索引日志分段文件对应两个索引文件主要用来提高查找消息的效率偏移量索引文件用来建立消息偏移量到物理地址之间的映射关系方便快速定位消息所在的物理文件位置时间戳索引文件则根据指定的时间戳来查找对应的偏移量信息中的索引文件以稀疏索引的方式构造消息的索引并不保证每个消息在索引文件中都有对应的索引项每当写入一定量指定的消息时偏移量索引文件和时间戳索引文件分别增加一个偏移量索引项和时间戳索引项稀疏索引通过将索引文件映射到内存中以加快索引的查询速度偏移量索引文件中偏移量是单调递增的查询指定偏移量使用二分查找法快速定位偏移量的位置如果指定的偏移量不在索引文件中则会返回小于指定偏移量的最大偏移量要找到对应的物理文件位置还需要根据偏移量索引文件进行再次定位时间戳索引文件中时间戳也是保持严格递增的查询指定时间戳时也会根据二分查找来查找不大于该时间戳的最大偏移量如果要找到对应的物理文件位置还需要根据偏移量索引文件来进行再次定位日志分段文件切分包含以下几个条件满足一个即可当前日志分段文件大小超过端参数配置值当前日志分段中消息的最大时间戳与当前系统的时间戳的差值大于或参数配置的值的优先级高偏移量索引文件或时间戳索引文件的大小达到端参数配置的值追加的消息偏移量与当前日志分段的偏移量之间的差值大于即要追加的消息偏移量不能转化为相对偏移量对于非活跃日志分段其对应的索引文件内容已经固定索引被设定为只读在创建索引的时候会为其预分配大小的空间只有当索引文件进行切分的时候会把索引文件裁剪到实际的数据大小也就代表着当前活跃的日志分段对应的索引文件大小固定为其余日志分段对应的索引文件为实际占用的空间偏移量索引每个索引项占用个字节分为两个部分相对偏移量表示消息相对于的偏移量占用个字节物理地址消息在日志分段文件中对应的物理地址索引项中没有直接使用绝对偏移量而改为只占用个字节的相对偏移量这样可以减小索引文件占用的空间如何确定查找的日志分段呢使用跳跃表结构的每个日志对象中使用了来保存各个日志分段每个日志分段的作为这样可以根据指定偏移量来快速定位到消息所在的日志分段中要求索引大小文件必须是索引项大小的整数倍对于偏移量索引文件而言必须为的整数倍时间戳索引每个索引项占个字节当前日志分段的最大时间戳时间戳所对应的消息的相对偏移量时间戳索引文件中包含若干时间戳索引项每个追加的时间戳索引项中的必须大于之前追加的索引项的否则不予追加如果端参数设置为则无法保证递增生产者可以指定时间戳的值不同时钟问题可能会导致时间戳无法单调递增时间戳索引文件大小必须是索引项的整数倍如果不满足默认会进行转换每当写入一定量的消息就会在偏移量索引和时间戳索引文件中分别增加一个偏移量索引项和时间戳索引项两个文件增加索引项是同时进行的但不意味着偏移量索引中的相对偏移量和时间戳索引中的相对偏移量是一个值日志清理将消息存储在磁盘中为了控制磁盘占用空间的不断增加就需要对消息做一个定时清理每一个分区对应一个而又分为多个日志分段便于日志清理操作提供了两个日志清理策略日志删除按照一定的保留策略直接删除不符合条件的日志分段日志压缩针对每个消息的进行整合对于有相同的不同值只保留最后一个版本通过端参数来设置日志清理策略此参数的默认值为是压缩同时还需要设置为可以通过将参数设置为还可以同时支持日志删除和日志策略两种策略日志清理的粒度可以控制到主题级别日志删除的日志管理器中会有一个专门的日志删除任务来周期性地检测和删除不符合保留条件地日志分段文件周期通过来进行设置保留策略基于时间日志删除会检查当前日志文件是否有保留时间超过设置阈值来寻找可删除日志分段文件集合通过端进行设置超过阈值会对过期地日志段和索引文件进行标记然后由延迟删除任务来进行执行通过时间戳索引进行查找若该日志所有日志分段都过期必须保证有一个活跃的日志分段会先切分出一个新的日志分段基于日志大小日志删除任务会检查当前日志的大小是否超过设定阈值来寻找可删除的日志分段的文件集合阈值通过段参数来配置整个所有日志文件大小默认值为表示无穷大单个日志文件大小由来设置基于日志起始偏移量某日志分段的下一个日志分段的起始偏移量是否小于等于若是则可以删除此日志分段一般情况下日志文件的其实偏移量等于第一个日志分段的但不是绝对的的值可以通过请求日志的清理和截断等操作进行修改删除日志分段时首先会从对象中所维护的日志分段跳跃表中移除待删除的日志分段保证没有线程对这些日志分段进行读取然后将日志分段所对应的所有文件添加后缀最后交给一个以命名的延迟任务删除这些文件延迟任务执行时间可以使用参数调配日志压缩对于由相同的不同值只保留最后一个版本如果应用只关心对应的最新值则可以开启的日志清理功能会定期将相同的消息进行合并只保留最新的执行前后日志分段中的每条消息的偏移量和写入时的偏移量保持一致会生成新的日志分段文件日志分段中每条消息的物理位置会重新按照新文件来组织执行过后的偏移量不再是连续的不过这并不影响日志的查询在或参数设置的日志存放目录每一个日志目录下都有一个文件这个文件就是清理检查点文件用来记录每个主题的每个分区已清理的偏移量通过清理检查点文件可以将分为已经清理的部分和未清理的部分在日志清理的同时客户端也可以读取日志中的消息部分的消息时逐一增加的而部分的消息偏移量是断续的如果客户端总能赶上部分就能读取到日志的所有信息不会参与的执行支持通过参数来配置消息在被清理前的最小保留时间是针对的所以使用时应注意每个消息的值不为每个会启动个日志清理线程负责执行清理任务这些线程会优先选择污浊率最高的日志文件进行清理为了防止日志不必要的频繁清理操作使用来限定可进行清理操作的最小污浊率中用于保存消费者消费唯一的主题使用的就是策略中的每个日志清理线程会使用一个名为的对象来构建与的映射关系的哈希表日志清理需要遍历两次日志文件第一次遍历把每个的哈希值和最后出现的都保存在中第二次遍历会检查每个消息是否符合保留条件如果符合就保留下来否则就会被清理会保留相应的最新值那么当需要删除一个时提供一个墓碑消息不为为日志清理线程发现墓碑消息会先进性常规的清理并把保留墓碑消息一段时间墓碑消息的保留条件是当前墓碑消息所在的日志分段的最近修改时间大于通过端参数配置执行过后的日志分段的大小会比原先的日志分段要小为了防止出现大量小文件在实际清理过程中并不会对单个日志分段进行单独清理而是对多个文件分组减少生成的日志分段磁盘存储依赖文件系统磁盘来存储和缓存消息事实上磁盘可能比我们预想的要快也可能比我们预想的要慢这完全取决于我们如何使用它操作系统针对线性读写做了深层次的优化比如预读提前将一个比较大的磁盘块读入内存和后写将很多小的逻辑写操作合并成一个大的物理写操作技术顺序写盘的速度不仅比随机写盘的速度快而且也比随机写内存的速度快在设计时采用了文件追加的方式来写入消息属于典型的顺序写盘的操作但这并不是在性能具备足够竞争力的唯一因素页缓存操作系统实现的一种主要磁盘缓存以此用来减少对磁盘的操作把磁盘中的数据缓存到内存中把对磁盘的访问变为对内存的访问中大量使用页缓存这是实现高吞吐的重要因素之一虽然消息都是先被写入页缓存然后由操作系统负责具体的刷盘任务的但是中同样提供了同步刷盘及间接性强制刷盘的功能这些功能可以通过等参数进行控制同步刷盘可以保证消息的可靠性但不建议通过这种方式刷盘任务应该交由操作系统去调配消息的可靠性应交给多副本机制来实现同步刷盘太消耗性能系统会使用磁盘的一部分作为分区这样就可以进行进程的调度把非活跃的进程调入分区以此把内存空出来让给活跃的进程对大量使用系统页缓存的而言应该尽量避免这种内存交换可以通过修改系统参数来进行调节磁盘流程一般磁盘的场景由以下四种用户调用标准库进行操作数据流为应用程序库标准文件系统缓存页通过具体文件系统到磁盘用户调用文件数据流为应用程序文件系统页缓存通过具体文件系统到磁盘用户打开文件时使用绕过页缓存直接读写磁盘用户使用类似工具并使用参数绕过系统与文件系统直接写磁盘请求处理通用块层根据请求构造一个或多个结构并提交给调度层调度器将结构进行排序和合并成队列且确保读写操作即可能理想将一个或多个进程的读操作合并到一起读将一个或多个进程的写操作合并到一起写即可能变随机为顺序读必须优先满足写也不能等太久选择具备不同调度策略的调度器也会影响的写入性能系统中调度策略该算法实现了最简单的队列所有请求大致按照先来后到的顺序进行操作通过会在的基础上做相邻请求的合并并不完全按照先进先出规则请求顺序排序顺序按照请求地址进行排序而不是先来后到的顺序进行相应是默认磁盘调度算法试图均匀的分布对带宽的访问为每个进程单独创建一个队列来管理该进程所产生的请求各个队列之间使用时间片进行调度调度器每次执行一个进程的次请求出发点是尽量少的磁盘旋转来满足尽可能多的请求去相比于的缺点是先来的请求并不一定能被满足可能会出现饿死情况在的基础上解决了请求饿死的极端情况除了本身的排序队列额外分为读和写提供了队列读队列的最大等待时间为写的最大等待时间为队列中的请去优先级比队列中的高读优先级高于写优先级和考虑的满足零散请求上对于连续的请求并没有做优化在的基础上为每个读都设置了的等待时间窗口如果内收到相邻位置的读请求就可以立即满足将多个随机的小写入流合并成一个大的写入流零拷贝还使用零拷贝技术来进一步提升性能零拷贝就是将数据从磁盘文件复制到网卡设备中而不需要经由应用程序之手零拷贝大大提高了应用程序的性能减少了内核和用户模式之间的上下文切换对应系统的方法不适用零拷贝一个文件发送的步骤读取文件内容复制到内核模式的控制将内核模式的数据复制到用户模式下将用户模式下的数据复制到内核模式下的将内核模式下的的数据复制到网卡设备中传送零拷贝技术通过技术将文件内容复制到内核模式下的不过没有复制到相反只有包含数据的位置和长度的信息描述符被加到引擎直接将数据从内核模式中传递到网卡设备协议引擎这里数据只经历两次复制就从磁盘中传送出去了并且上下文切换也变为两次零拷贝是针对内核模式而言的数据在内核模式下实现了零拷贝深入服务端协议设计经常被用作高性能可拓展的消息中间件自定义了一组基于的二进制协议只要遵守这组协议的格式就可以向发送消息也可以从中拉取消息或者比如提交消费位移等操作每种类型的请求都包含相同结构的协议请求头和不同结构的请求体协议请求头中包含标识比如代表发送消息版本号客户指定一个数字来唯一标识这次请求的服务端处理完请求后也会把这个通过返回给客户端客户端通过这个能把请求和相应对应起来客户端协议响应头和请求头中的相对应时间轮中存在大量延时操作如延迟生产延时拉取和延时删除使用基于时间轮的概念自定义了一个用于延时功能的定时器基于时间轮可以将插入和删除操作的时间复杂度都降为中的时间轮是一个存储定时任务的环形队列底层采用数组实现数组中的每个元素可以存放一个定时任务列表是一个环形的双向链表链表中的每一项表示的都是定时任务项其中封装了真正的定时任务时间轮由多个时间格组成每个时间格代表当前时间轮的基本时间跨度时间轮的时间格个数是固定的用表示整个事件轮的总体事件跨度通过计算得出时间轮由一个表盘指针用来表示当前时间轮当前所处的时间是的整数倍可以将整个时间轮划分为过期部分和未到期过程到期意味着需要处理此时间格对应的中的所有任务层次时间轮当任务的到期时间超过当前时间轮所表示的时间范围时就会尝试添加到上层时间轮上一层时间轮的当前层层级时间轮解决单层时间轮延迟时间优先的问题上一层的是下一层的总时间跨度时间轮升级和降级实现时间轮的小细节中每个双向环形链表都会有一个哨兵节点用来简化边界条件中定时器只需要持有的第一层时间轮引用每一层时间轮都会有一个引用指向更高一层的一个用使用的来协助推进时间轮会根据对应的超时时间来排序最短的会被排在的队头延时操作如果在使用生产者客户端发送消息的时候将参数设置为那么就意味着需要等待集合中的所有副本都确认收到消息之后才能正确收到相应消息或者捕获超时异常在将消息写入副本的本地日志之后会创建一个延时的生产操作用来处理消息正常写入所有副本或超时的情况以返回相应的响应结果给客户端控制器集群中会有一个或多个其中有一个会被选举为控制器它负责管理整个集群中所有分区和副本的状态某个分区副本出现故障某个分区的集合发生变化控制器负责通知所有更新其元信息增加分区数量控制分区分配控制器的选举及异常恢复的控制器选举工作依赖于成功竞选为控制器的会在中创建这个临时节点在任意时刻集群中有且仅有一个控制器每个启动的时候会去尝试读取节点的的值如果不为则放弃竞选否则尝试去尝试创建这个节点每个都会在内存中保存当前控制器的值中有个节点这个节点是持久节点节点中存放一个整型的值代表控制器发生变更的次数每个和控制器交互的请求都会携带这个字段判断消息是不是无效请求通过的值进行比较来保证控制器的唯一性控制器身份的需要承担更多的职责监听分区相关的变化为的节点注册用来处理分区重分配的工作为中的节点注册用来处理集合变更的动作为中的节点添加用来处理优先副本的选举动作监听主题相关的变化为中的节点添加用来处理主题增减变化为中的节点添加用来处理删除主题的动作监听的变化为中的节点添加用来处理增减的变化从中获取当前所有与主题分区及有关消息并进行相应的管理对所有主题对应的添加用来监听主题中分区分配变化启动并管理分区状态机和副本状态机更新集群的元数据信息如果参数设置为则会开启一个名为的定时任务来维护分区的优先副本的均衡控制器在选举成功之后会读取中各个节点的数据来初始化上下文信息并且管理这些上下文信息的处理监听的事件采用单线程基于事件队列的模型将每个事件都做一层封装然后按照事件发生的先后顺序暂存到中最后使用一个专用的线程按照的原则顺序处理各个事件在多线程间维护线程安全在的早期版本并没有采用这样的概念来对分区和副本的状态进行管理而是依赖于每个都会在上为分区和副本注册大量的监听器会唤醒很多不必要的监听器现在除之后只需要鉴定以此监听此节点的数据变化关闭过程分区的选举分区副本的选举由控制器负责具体实施当创建分区创建主题或增加分区或分区上线分区中原先的副本下线的时候都需要执行的选举动作对应的策略为这种策略的基本思路是按照集合中副本的顺序查找第一个存活的副本并且这个副本在集合中如果集合中没有可用副本那么还要检查以下所配置是否为为会从集合中找到第一个存活的副本作为当分区进行重分配的时候也需要执行选举动作对应的选举策略为选举思路从重分配的列表找到第一个存活的副本且这个副本在目前列表当发生优先副本的选举时直接将优先副本设置为即可集合中第一个副本即为优先副本还有一种情况会发生的选举当某节点被优雅地关闭也就是执行时位于这个节点上的副本都会下线所以与此对应的分区需要执行的选举与此对应的选举策略为从列表中找到第一个存活的副本且这个副本在目前的列表中与此同时还要确保这个副本不处于正在被关闭的节点上参数含义自动创建主题功能自动在均衡功能后台任务的线程数消息的压缩类型是否可以删除主题检查是否分布不均衡的周期允许不均衡的比例超过就会触发在均衡客户端分配分区策略中提供了消费者客户端参数来设置消费者与订阅主题之间的分区分配策略默认情况此参数的值为此外还有两种分配策略和消费者客户端参数可以配置多个分配策略彼此之间以逗号分隔分配策略按照消费者总数和分区总数进行整除运算来获得一个跨度然后将分区按照跨度进行平均分配以保证分区尽可能均匀的分配给所有消费者对于每个主题策略会将消费组内所有订阅这个主题的消费者按照名称的字典序进行排序然后为每个消费者划分固定的分区范围如果不够平均分配那么字典序靠前的消费者会被多分配一个分区分配策略将消费组内所有消费者及消费者订阅的所有主题的分区按照字典序排序然后通过轮询的方式以此分配给每个消费者如果同一个消费组内所有的订阅信息都是相同的那么分配策略会是均匀的如果同一个消费者内的消费者订阅的消息是不同的那么在执行分区的时候就并不是完全的轮询分配有可能导致分区分配得不均匀分配策略这种分配的目的是分区的分配要尽可能均匀分区的分配尽可能与上次分配的保持相同的优先级大于这种分配策略在出现分区重分配情况下尽可能让前后两次分配保持相同进而减少系统资源的损耗以及其他异常情况的发生自定义分区分配策略用于定义消费者成员如何分配分区这个策略决定了当新的消费者加入消费者组现有的消费者离开消费者组或者主题的分区数发生变化分区如何重新分配给消费者组中的成员中机架感知的主要好处和作用提高数据冗余的主题可以有多个副本通过机架感知可以确保主题的各个副本分布在不同的机架上这样即使整个机架发生故障仍然可以从其他机架上的副本中读取和写入数据故障隔离机架感知确保单个机架或者多个机架的故障不会导致数据丢失或者服务中断因为至少有一个副本位于健康的机架网络流量优化机架内的服务器之间的网络流量通常比跨机架之间的流量更快更稳定的机架感知可以优化数据的复制流程使得大部分的数据复制操作都在机架内部完成同时提高效率消费者协调器和组协调器如果消费者客户端中配置了多个分区分配策略那么以哪个为准多个消费者之间的分区分配是需要协同的这一切都是交给消费者消费者协调器和组协调器来完成的消费者协调器和组协调器的概念是针对消费者客户端而言早期通过监听节点实现在均衡操作集群中两个比较严重的问题羊群效应中一个被监听的节点变化大量的通知被发送到客户端导致在通知期间的其它操作延迟也有可能发生类似死锁的问题脑裂问题消费者进行再均衡操作时每个消费者都与进行通信以判断消费者或变化的情况由于本身特性可能导致再同一时刻各个消费者获取的状态不一致这样会导致异常问题发生再均衡的原理新的消费者客户端进行了重新设计将全部消费组分成多个子集每个消费组的子集在服务端对应一个对其进行管理是服务端用于管理消费组的组件而消费者客户端的组件负责与进行交互与之间最重要的职责就是负责执行消费者在均衡的操作包括前面提及的分区分配工作也是在再均衡期间完成的会触发再均衡的操作有新的消费者加入消费组有消费者宕机下线消费者并不一定需要真正下线长时间网络延迟导致消费者长期未向发送心跳等情况时会认为消费者已经下线有消费者主动退出消费组请求消费组对应的节点发生了变更消费组内所订阅的任意主题或者主题的分区发生了变化当有消费者加入消费组时消费者消费组及组协调器之间经历的阶段消费者需要确定它所属消费组对应的所在的并创建与该相互通信的网络连接如果消费者已经保存了与消费者对应的信息并且正确建立了连接则可以进入第二阶段否则向集群中某个节点负载最小的节点发送请求来查找对应的位于该消费组对应分区的副本所在的节点在成功找到消费组对应的之后就进入加入消费组的阶段消费者会发送请求并处理响应的结构包含的域超过指定时间内没有收到心跳报文则认定此消费者已经下线对应消费端参数当消费组再平衡的时候等待各个消费者重新加入的最长等待时间分配给消费者的标识消费者第一次发送请求时设置此字段为消费组实现的协议对于消费者此字段设置为数组类型囊括多个分区分配策略如果原有的消费者重新加入消费组那么在真正发送请求之前还要执行一些准备工作如果消费者参数设置为自动提交位移功能那么在请求加入消费组之前需向提交消费位移阻塞执行如果消费者添加了自定义的再均衡监听器那么此时会调用方法再重新加入消费组之前实施自定义的规则逻辑比如清除一些状态提交位移重新加入消费组之前和节点之间的心跳检测就不需要了所以成功加入消费组之前需要禁止心跳检测的运作选举消费组中的需要为消费组内的消费者选举出一个消费组的分两种情况如果消费组内还没有那么第一个加入消费组的消费者即为消费组的如果存在取中保存消费者信息的第一个对应的消费者元信息比较随意选举分区分配策略每个消费者都可以设置自己的分区分配策略对消费组而言需要从各个消费者选举的分配策略中选举出一个彼此都信服的策略来进行整体的分区分配这个分区分配的选举是根据消费组内各个消费者投票决定的最终选举的分配策略基本上是被各个消费者支持最多的策略具体选举过程收集各个消费者支持的所有分配策略组成候选集每个消费者从候选集中找出第一个自身支持的策略为这一策略投一票计算候选集中各个策略的选票数选票最多的策略即为消费者的分配策略如果有的消费者不支持选出来的分配策略会抛出异常就是这个消费者没有配置这个分配策略就会不支持消费者根据在第二阶段中选举出来的分区分配策略来实施具体的分区分配在此之后需要将分配的方案同步给各个消费者通过进行转发同步分配方案在第三阶段也就是同步阶段各个消费者会向发送请求来同步分配方案服务端在收到消费者发送的请求之后会交由来负责具体的逻辑处理同样会先对请求做合法性校验在此之后会将从消费者发送过来的分配方案提取出来连同整个消费组的元数据信息一起存入的主题中最后发送响应给各个消费者以提供给各个消费者各自所属的分配方案当消费者收到所属的分配方案之后会调用中的方法随后再调用中的方法之后开启心跳任务消费者定期向服务端的发送来确定彼此在线消费者客户端提交的消费位移会保存再的主题中消费组的元数据信息也会保存在这里阶段进入这个阶段消费组中的所有消费者都进入正常工作状态在正式消费之前消费者还需要确定拉取消息的起始位置假设之前已经将最后的消费位移提交到了并且将其保存到了内部的主题中此时消费者可以通过请求获取上次提交的消费位移并从此处继续消费消费者通过向发送心跳来维持它们与消费组的从属关系以及它们对分区的所有权关系只要消费者以正常的时间间隔发送心跳就被认为是活跃的说明它还在读取分区中的消息心跳线程是一个独立的线程可以在轮询消息的空档发送心跳如果消费者停止发送心跳的时间足够长则整个会话就被判定为过期也会认为这个消费者已经死亡就会触发一次再均衡行为消费者的心跳间隔时间由参数指定默认值为即秒这个参数必须比参数设定的值要小一般情况下的配置值不能超过配置值的这个参数可以调整得更低以控制正常重新平衡的预期时间如果一个消费者发生崩溃并停止读取消息那么会等待一小段时间确认这个消费者死亡之后才会触发再均衡在这一小段时间内死掉的消费者并不会读取分区里的消息这个一小段时间由参数控制该参数的配置值必须在端参数默认值为即秒和默认值为即分钟允许的范围内还有一个参数它用来指定使用消费者组管理时方法调用之间的最大延迟也就是消费者在获取更多消息之前可以空闲的时间量的上限主题位移提交的内容最终会保存到的内部主题中一般情况下当集群中第一次由消费者消费消息时会自动创建主题它的副本因子受约束默认为分区数可以通过参数设置默认为客户端提交消费位移使用请求实现请求体中包含表示当前提交的消费位移所能保留的时长不过对于消费者而言这个值保持为表示按照端的配置来确定保留时长默认为天超过这个时长后消费位移的消息就会被删除使用墓碑消息或日志压缩策略有些定时消费的任务在执行完某次消费任务之后保存了消费位移之后隔了一段时间再次执行消费任务如果这个间隔时间超过的配置值那么原先的位移信息就会丢失最后只能根据客户端参数来决定开始消费的位置遇到这种情况时就需要根据实际情况来调配参数的值中的其余字段大抵也是按照分区的粒度来划分消费位移的如果有若干消费者消费了某个主题中的消息并且也提交了相应的消费位移那么再删除这个主题之后会一并将这些消费位移消息删除位移自定义元数据信息位移提交的时间戳消息位移被判断超时的时间戳删除主题之后会一起将这些消费位移信息删除事务一般而言消息中间件的消息传输保证有三个层级至多一次消息可能会丢失但绝对不会重复传输最少一次消息绝不会丢失但可能会重复传输恰好一次每条消息肯定会被传输一次且仅传输一次的消息传输保障机制非常直观当生产者向发送消息时一旦消息被成功提交到日志文件由于多副本机制的存在这条消息就不会被丢失对于生产者来说如果生产者发送到之后遇到网络问题而造成通信中断那么生产者无法判断该消息是否提交虽然无法确定网络故障期间发生了什么但生产者可以进行多次重试来确保消息已经写入这个重试过程中有可能会造成消息的重复写入提供的消息传输保障为对于消费者而言消费者处理消息和提交消费位移的顺序再很大程度上决定了消费者提供哪一种消息传输保障如果消费者在拉取完消息之后应用逻辑先处理消息后提交消息位移宕机可能出现重复消费对应的是如果消费者在拉完消息之后应用逻辑先提交消费位移宕机重启之后可能会丢失数据此时对应的是引入幂等和事务特性以此来实现精确一次幂等幂等就是对接口的多次调用所产生的结果和调用一次是一致的生产者在进行重试的时候可能会重复写入消息而使用幂等性功能之后就可以避免这种情况开启幂等性功能需要显示将生产者客户端参数设置为为了使用生产者的幂等性引入了和序列号每个生产者实例在初始化时都会被分配一个对于每个消息发送的每一个分区都有对应的序列号这些序列号从开始递增生产者每发送一条消息就会将分区对应序列号的值加端会在内存为每一对分区维护一个序列号对于接收到的每一条消息只有当他的序列号的值比端中维护的对应的序列号的值大时才会接收它否则丢弃如果序列号大于或更大则标志出现消息丢失生产者会抛出异常引入序列号来实现幂等也只是针对每一对分区而言代表着幂等只能保证单个生产者会话单分区的幂等事务幂等性并不能跨多个分区运作而事务可以弥补这个缺陷事务可以保证对多个分区写入操作的原子性对流式应用而言一个典型的应用模式为在这种模式下消费和生产并存应用程序从某个主题中消费消息经过一系列转换写入另一个主题消费者可能在提交消费位移的过程中出现问题而导致重复消费也有可能生产重复生产消息中的事务可以使应用程序将消费消息生产消息提交消费位移当作原子操作来处理同时成功或失败为了实现事务应用程序必须提供唯一的可以通过客户端参数来显式设置事务要求生产者开启幂等特性因此通过将参数设置为非空从而开启事务特性的同时需要将设置为与一一对应两者之间所不同的是由用户显式设置由内部分配另外为了保证新的生产者启动后具有相同的的旧生产者能够立即生效每个生产者通过获取的同时还会获取一个单调递增的如果使用同一个开启两个生产者那么前一个生产者会报错从生产者的角度分析通过事务可以保证跨生产者会话的消息幂等发送以及跨生产者会话的事务恢复前者表示具有相同的新生产者示例被创建且工作的时候旧的且拥有相同的的生产者示例将不再工作或者指当某个生产者实例宕机后新的生产者实例可以保证任务未完成的旧事务要么被提交要么被中止消费者的角度分析事务保证的语义相对偏弱以下原因不能保证已提交的事务中的所有消息都能够被消费对采用日志压缩策略的主题而言事务中的某些消息可能被清理事务中消息可能分布在同一个分区的多个日志分段当老的日志分段被删除对应的消息可能会丢失消费者可以通过方法访问任意消息可能遗漏事务中的部分消息消费者在消费时可能没有分配到事务内的所有分区如此它就不能读取事务中的所有消息中提供的事务相关的方法初始化事务开启事务消费在事务内的位移提交操作提交事务终止事务在消费端有一个参数这个参数默认值为意思是消费端应用可以看到未提交的事务可以设置未表示消费端不可以看到尚未提交事务内的消息不过内部会缓存这些消息知道生产者执行才能将这些消息推送给消费端应用日志文件除了普通的消息还有一种消息专门用来标志一个事务的结束那就是控制消息控制消息包括和分别表示事务已经成功提交或已经被成功终止可以通过事务已经成功提交或被成功中断结合来决定是否将对应的消息返回给消费者应用为了实现事务的功能还引入了事务协调器来处理事务类似组协调器每一个生产者都会被指派一个特定的所有的事务逻辑包括等都是由来负责实施的会将事务状态持久化到内部主题中事务状态包含可靠性副本刨析副本是分布式系统对数据和服务提供的一种冗余方式副本分为数据副本和服务副本数据副本不同的节点持久化同一份副本当某个节点存储的数据丢失可以从副本读取数据服务副本多个节点提供同样的服务每个节点都有能力接收来自外部的请求并进行相应的处理任何在设计阶段考虑的异常情况一定会在系统实际运行中发生并且在系统实际运行过程中还会遇到很多在设计时没有考虑到的异常故障正常情况下所有分区的副本都处于状态但是难免会出现异常从而某些副本不处于集合中这些副本被称为失效副本显式主题中包含失效副本分区的情况通过为一个的参数当集合中副本之后副本时间超过则判断为同步失败失效副本的判断实现原理当副本将副本之前的日志全部同步时则任务副本已经追赶上副本此时更新该副本的标识的副本管理器会启动一个副本过期检测的定时任务取检查当前时间与副本差值是否大于参数指定的值的伸缩启动的时候会开启两个与相关的定时任务分别为和任务会周期性检测一半的值每个分区是否需要缩减其集合存在中的失效副本就会被缩容如果某个分区的集合发生变更则会将变更后的数据记录到对应的节点中节点的数据控制器的当前分区副本所在的节点版本号当前分区纪元变更后的列表除此之外当集合发生变更时还会将变更后的记录缓存到中任务会周期性检查如果发现存在变更记录那么它会在的路径下创建一个以开头的持久顺序节点并将中的信息保存到这个节点中控制器为添加了一个当这个节点中有子节点发生变化时会触发的动作以此通知控制器更新相关元数据信息并向它管理的节点发送更新元数据的请求最后删除路径下已经处理过的节点频繁的触发会影响控制器甚至其它的性能为了避免添加了如下限定条件需要满足个才可以将集合的变化写入目标节点上一次集合发生变化距离已经超过上一次写入的时间距离现在超过随着副本不断与副本进行消息同步副本的也会逐渐后移并追赶上副本此时就有资格进入集合追赶上副本的标准是不小于副本的接下来和集合减少情况相同通过定时任务创建节点多分区消息追加过程生产者客户端发送消息至副本中消息被追加到副本的本地日志并且会更新日志的偏移量副本副本和副本向副本请求同步数据副本所在服务器读取本地日志并更新对应拉取的副本的信息副本收到副本返回的拉取结果将消息追加到本地日志中并更新日志的偏移量信息副本向副本拉取信息在拉取的请求中会自带自身的信息这个信息对应的是请求中的会根据所有传递的来更新的副本返回给副本响应的信息并且还自带自身的信息收到副本的响应会更新自己的并且会更新自己的信息副本所在的节点会记录所有副本的而副本所在节点只会记录自身的而不会记录其他副本的根目录下和四个检查点文件和这两个文件分别对应的和中会有定时任务负责将所有分区的刷写到恢复点文件中定时周期由端参数来配置文件对应开始引入的概念再需要截断数据的时候使用作为参考依据而不是原本的每个副本还会增设一个矢量其中用来标识当前下写入的第一条消息的偏移量写入到文件再发生变更时对应的矢量写入到这个文件中是主写主读的生产消费模型为什么不支持读写分离主写从读的缺点数据一致性问题数据从主节点到从节点之间必然有一个延时的时间窗口这个时间窗口可能导致主从节点数据不一致问题延时问题主从同步需要经过网络主节点内存主节点磁盘网络从节点内存从节点磁盘这期间会耗费大量的时间对于延时敏感的应用主写从读的功能并不太适用日志同步机制在分布式系统中日志同步机制既要保证数据的一致性也要保证数据的顺序性最简单的方式是从集群中选出一个来负责处理数据写入的顺序性通常情况下只要不宕机我们就不需要关心的同步问题不过当宕机时我们就需要从中选举出一个新的的同步状态可能落后很多甚至还可能处于宕机状态所需必须确保选择具有最新日志消息的作为新的日志同步机制的一个基本原则如果告知客户端已经成功提交了某条消息那么即使宕机也要保证新选举出来的中能够包含这些消息这里就有一个需要权衡的地方如果在消息提交前需要等待更多的确认那么在它宕机之后就有更多的替代它不过会造成性能的下降有一种方案是少数服从多数它可以用来负责提交决策和选举决策副本保证提交之前进行确认这种方案有一个很大的优势系统的延迟取决于最快的几个节点劣势就是为了保证选举的正确进行它所能容忍的失败的比较少比较经典使用案例使用的更像是微软算法动态维护着一个集合处于集合内的节点保持于相同的只要位列其中的副本配置为才有资格被选举为新的在模型副本数配置下一个分区能够容忍最大个节点失败相比于少数服从多数所需副本数大大减少一般同步策略依赖于稳定的存储系统来做数据恢复表明在数据恢复时日志文件不可丢失且不能有数据上的丢失而不是必须宕机之后之后只能在本地数据日志进行恢复允许宕机副本重新加入集合但是进行之前必须保证自己能够重新同步完中所有数据高级应用过期时间使用消息的字段和拦截器接口的方法不过还需要消息中字段来做配合将消息的的设定值以键值对的形式保存在消息的中这样消费者消费这条消息可以在拦截器中根据中设定的超时时间来判断是否超时延时队列队列是存储消息的载体延时队列存储的对象是延时消息延时消息消息被发送以后并不想让消费者立即获取而是等待特定时间后消费者才能获取这些消息原生的并不具备延时队列的功能不过我们可以对其进行改造和实现实现延时队列的方式有很多种延时队列可以通过消费者客户端拦截器来实现但存在不好处理的情况某一批拉取到的消息集中有一条消息的延迟时间很长其它的消息延时时间很短而很快被消费那么如何进行处理如果这时提交消费位移那么延时时间很长的那条消息会丢失如果这时不继续拉取消息而等待这条延时时间很长的消息到达延时时间这样又会导致消费滞后很多而且如果位于这条消息后面的很多消息的延迟时间很短那么就会导致这些消息无端的拉长延时时间如果这时候不提交消费位移而继续拉取消息等待这条延时时间很长的消息满足条件之后再提交消费位移那么在此期间这些消息需要常驻内存中而且还需要一个定时机制来定时检测是否满足被消费的条件会引起内存保障并且如果发生异常会造成大量数据的重复消费有一种改变方案就是消费者拉取一批消息如果这批消息中有未达到延时时间的消息那么就将这写消息重新写入主题等待后续消费但是如果出现消息堆积会造成消息严重的滞后消费另一种可行性方案在发送延时消息的时候并不是先投递到要发送的真实主题而是先投递到一些的内部主题中这些主题对用户不可见然后通过一个自定义服务拉取这些内部主题中的消息并将满足条件的消息再投递到要发送的真实主题中消费者所订阅的还是真实的主题延时时间一般以秒来计算若要支持小时之内的延时时间的消息那么显然不能按照延时时间来分类这些主题如果采用这种方案一般是按照不同的延时等级来划分的比如设定等级延时的消息按照延时时间投递到不同等级的主题中投递到同一主题中的消息的延迟时间会被强转为与此主题延时等级一致的延时时间这样延时误差就控制再两个延时等级的时间差范围内具体实现消息拉取重新投递通过代码中可以保证消息按照再次投递时间进行有序排序这样下游的消息发送线程就能按照先后顺序获取最先投递条件的消息消息路由消息路由时消息中间件中常见的概念中就使用路由键来进行消息路由中生产者将消息发送到交换机中然后由交换器根据指定的路由键将消息路由到一个或多个队列中消费者消费的是队列中的消息从整体上看通过路由键将原本发往一个地方的消息做了区分然后让不同的消费者消费到自己关注的消息默认按照主题进行路由消息发往主题之后会被订阅的消费者全盘接收这里没有类似消息路由的功能来将消息进行二级路由这一点从逻辑概念上来说并无任何问题但是如果业务需要复用相同的主题就会出现消息接收时的混乱如果需要消息路由那么完全可以通过细粒度化切分主题来实现除了设计缺陷还有一些历史遗留问题希望具备一个消息路由功能如果原先系统使用这种具备消息路由的生产消费模型运行一段时间之后需要更换为并且还需要保留原有系统的逻辑我们可以进行一层映射消费者根据消息特定的标识来获取消息其余的都全部过滤具体的实现方式可以在消息的字段中加入一个键值为特定业务标识的然后再消费端中使用拦截器挑选出特定业务标识的消息中消息路由的实现架构如下图所示消费组根据特定的标识和来消费主题和中对应的消息而忽略标识为的消息消息轨迹问题消息发送成功了吗为什么发送的消息在消费端消费不到为什么消费端重复消费了消息对于此类问题我们可以引入消息轨迹来解决消息轨迹指的是一条消息从生产者发出经由存储再到消费者消费的整个过程中各个相关节点的状态时间地点等数据汇聚而成的完整链路消息生产者消费者这个角色在处理消息的过程中都会在链路中增加相应的信息将这些信息汇聚处理之后就可以查询任意消息的状态进而为生产环境中的故障排除提供强有力的数据支持对消息轨迹而言最常见的实现是封装客户端在保证正常生产消费的同时添加相应的轨迹消息埋点逻辑无论生产还是消费在执行之后都会由相应的轨迹信息我们需要将这些消息保存起来下面这种实现方式参考的做法它将消费位移消息保存到中对应地我们同样将轨迹消息保存到地某个主题中简介是一种分布式的基于发布订阅的消息系统主要设计目标如下以时间复杂度为的方式提供消息持久化能力即使级以上数据也能保证常数时间复杂度的访问性能高吞吐率即使在非常廉价的商用机器上也能做到单机支持每秒以上消息的传输支持间的消息分区及分布式消费同时保证每个分区内消息顺序传输同时支持离线数据处理和实时数据处理支持在线水平扩展消息删除机制会保留消息数据无论消费与否当然因为磁盘限制不可能永远保留所有数据提供两种策略删除数据一是基于时间二是基于文件大小因为读取特定消息的时间复杂度为即与文件大小无关所以这里删除过期文件与提高性能无关选择怎样的删除策略只与磁盘以及具体的需求有关另外会为每一个保留一些信息当前消费的消息的也即这个由控制正常情况下会在消费完一条消息后递增该当然也可将设成一个较小的值重新消费一些消息因为由控制所以是无状态的它不需要标记哪些消息被哪些消费过也不需要通过去保证同一个只有一个能消费某一条消息因此也就不需要锁机制这也为的高吞吐率提供了有力保障消息路由发送消息到时会根据机制选择将其存储到哪一个如果机制设置合理所有消息可以均匀分布到不同的里这样就实现了负载均衡可以通过修改配置文件进行设置新建的默认数量也可以在新建时进行指定在发送一条消息时可以指定这条消息的根据这个和机制来判断应该将这条消息发送到哪个机制可以通过指定的这一参数来指定该必须实现接口作为一个消息系统遵循了传统的方式选择由向消息由从消息模式和模式各有优劣模式很难适应消费速率不同的消费者因为消息发送速率是由决定的模式的目标是尽可能以最快速度传递消息但是这样很容易造成来不及处理消息典型的表现就是拒绝服务以及网络拥塞而模式则可以根据的消费能力以适当的速率消费消息但是有个缺点就是没有可供消费的消息将导致不断在循环中轮询直到新消息到达为了避免这点有个参数可以让阻塞直到新消息到达也可以阻塞直到消息的数量达到某个特定的量进行批量发副本同步机制的每个有一个预写式日志文件每个都由一系列有序的不可变的消息组成这些消息被连续的追加到中中的每个消息都有一个连续的序列号叫做确定它在分区日志中唯一的位置每个的具有多个副本采用多副本机制实现故障自动转移副本分为和断线会自动选举一个作为证的可用性只要有一个副本没有断线就可用处理的所有读写请求与此同时会被动定期地去复制上的数据类似与消费者消息成功复制到所有同步副本之后才算提交成功消息复制延迟受最慢的限制重要的是快速检测慢副本如果落后太多或者失效将会把它从从移除在中移除设置为表明只要落后不超过就不会从同步副本列表中移除设置为表明只要向每隔都能发送就不会被标记为死亡也不会从同步副本列中移除的复制机制既不是单纯的同步复制也不是简单的异步复制事实上同步复制要求所有能工作的都复制完这条消息才会被认为这种复制方式极大的影响了吞吐率高吞吐率是非常重要的一个特性而异步复制方式下异步的从复制数据数据只要被写入就被认为已经这种情况下如果都落后于而如果突然宕机则会丢失数据而的这种使用的方式则很好的均衡了确保数据不丢失以及吞吐率可以批量的从复制数据这样极大的提高复制性能批量写磁盘极大减少了与的差距只解决不处理拜占庭问题一条消息只有被里的所有都从复制过去才会被认为已提交这样就避免了部分数据被写进了还没来得及被任何复制就宕机了而造成数据丢失无法消费这些数据而对于而言它可以选择是否等待消息这可以通过来设置这种机制确保了只要有一个或以上的一条被的消息就不会丢失的三种取值代表生产者不需要等待同步完成的确认继续发送下一条消息当服务器发生故障某些数据会丢失如已死但不知情发出去的消息就收不到这意味着在已成功收到的数据并得到确认后发送下一条宕机未与同步可能会丢失数据这意味者在副本确认接受到数据后才算一次发送完成三种机制性能一次递减数据健壮性则一次递增如何处理所有都不工作中至少有一个时可以确保已经的数据不丢失但如果某个的所有都宕机了就无法保证数据不丢失了这种情况下有两种可行的方案等待中的任一个恢复并且选它作为选择第一个恢复的作为两种方案需要在可用性和一致性当中作出选择如果一定要等待中的活过来那不可用的时间就可能会相对较长而且如果中的所有都无法活过来了或者数据都丢失了这个将永远不可用选择第一个活过来的作为而这个不是中的那即使它并不保证已经包含了所有已的消息它也会成为而作为的数据源前文有说明所有读写都由完成什么原因导致副本和不一致慢副本在一定周期时间内不能追赶上最常见的原因之一是瓶颈导致追加复制消息速度慢于从拉取速度卡住副本在一定周期时间内停止从拉取请求卡住了是由于暂停或失效或死亡新启动副本当用户给主题添加副本因子时新的不在同步副本列表中直至它们完全追上日志机制每个会在磁盘记录一个记录已经到磁盘的最大当重启时会进行首先会读取该的找到包含的及以后的这些就是可能没有完全到磁盘然后调用的重新读取各个的并重建索引只从拉取数据数据可靠性保证当向发送数据时可以通过参数设置数据可靠性的级别无论写入是否成功不需要给发送如果发生异常会终止连接触发更新数据写入成功后即发送此种情况如果会丢失数据等待所有接收到消息后再给发送这是最强保证仅设置也不能保证数据不丢失当列表中只有时同样有可能造成数据丢失要保证数据不丢除了设置还要保证的大小大于等于具体参数设置设置为等待所有列表中的接收到消息后采算写成功设置为大于等于保证中至少有两个包括节点数据一致性保证一致性定义若某条消息对可见那么宕机了在新上数据依然可以得到简称的高水位取一个对应的中最小的作为消费者最多只能消费到所在的位置另外每个都有和各自负责更新自己的状态对于新写入的不能立刻消费会等待该消息被所有中的同步后更新此时该消息才能被消费即最多只能消费到位置对于内部的读取请求没有的限制也会自己设置一份集群默认分配解析中复制机制中每个启动时都会创建一个副本管理服务该服务负责维护与其他链路连接关系该中存在多少的对应分布在不同的上有多少就会创建相同数量的线程同步对应数据中间复制数据是由扮演角色主动向获取消息每次读取消息都会更新状态每当的发生变更影响所在变化时就会新建或销毁相应的高可用设置将所有均匀分布到整个集群为了更好的做负载均衡尽量将所有的均匀分配到整个集群上一个典型的部署方式是一个的数量大于的数量分配的算法如下将所有假设共个和待分配的排序将第个分配到第个上将第个的第个分配到第个上为了提高性能每个在接收到数据后就立马向发送而非等到数据写入中因此对于已经的消息只能保证它被存于多个的内存中而不能保证它们被持久化到磁盘中也就不能完全保证异常发生后该条消息一定能被消费但考虑到这种场景非常少见可以认为这种方式在性能和数据持久化上做了一个比较好的平衡在将来的版本中会考虑提供更高的持久性如何选举启动时会在所有中选择一个作为创建添加分区修改副本数量之类的管理任务都是由完成分区选举也是由决定的在集群启动的时候每个都会尝试去上注册成为临时节点但只有一个竞争成功其他的会注册该节点的监视器一旦该临时节点状态发生变化就可以进行相应的处理也是高可用的一旦某个崩溃其他的会重新注册为所有的选举都由决定会将的改变直接通过的方式通知需为此作出响应的读取到当前分区的只要有一个还幸存就选择其中一个作为否则任意选一个作为如果该的所有都已经宕机则新的为过程简介在注册一旦有宕机其在对应的会自动删除会注册的读取最新的幸存的决定该集合包含了宕机的所有上的所有对中的每一个从读取该当前的决定该的新如果当前中有至少一个还幸存则选择其中一个作为新新的则包含当前中所有幸存的否则选择该中任意一个幸存的作为新的以及该场景下可能会有潜在的数据丢失如果该的所有都宕机了则将新的设置为将新的和新的及写入注意该操作只有其在第一步至第三部的过程中无变化时才会执行否则跳转到第一步直接通过向相关的发送命令可以在一个操作中发送多个命令从而提高效率创建删除在上的节点上注册一旦某个被创建或删除则会通过得到新创建删除的的分配对于删除操作工具会将该名字存于若为则注册在上的被通过回调向对应的发送若为则不会在上注册也就不会对该事件作出反应此时操作只被记录而不会被执行对于创建操作会从读取当前所有可用的列表对于中的每一个从分配给该的所有称为中任选一个可用的作为新的并将设置为新的因为该是新创建的所以中所有的都没有数据可认为它们都是同步的也即都在中任意一个都可作为将新的和写入直接通过向相关的发送相应请求流程通过及相关模块接受各种请求并作出响应整个网络通信模块基于开发并采用模式其中包含个负责接受客户请求个负责读写数据个处理业务逻辑的主要职责是监听并接受客户端请求发起方包括但不限于的连接请求并建立和客户端的数据传输通道然后为该客户端指定一个至此它对该客户端该次请求的任务就结束了它可以去响应下一个客户端的连接请求了主要负责从客户端读取数据并将响应返回给客户端它本身并不处理具体的业务逻辑并且其内部维护了一个队列来保存分配给它的所有的方法会循环从队列中取出新的并将其注册到上然后循环处理已就绪的读请求和写响应读取完数据后将其封装成对象并将其交给是和交换数据的地方它包含一个队列用来存放加入的会从里面取出来处理同时它还包含一个用来存放处理完后返还给客户端的会通过方法依次将中保存的取出并将对应的事件注册到上当的方法返回时对检测到的可写通道调用方法将返回给客户端循环从中取并交给处理具体的业务逻辑启动过程启动后首先根据其在的创建临时节点创建成功后的注册其上的会被从而通过回调方法完成以下步骤向所有新启动的发送将新启动的上的所有设置为状态同时这些会为这些启动线程通过触发也需要每个都会在上注册一个当前失败时对应的会自动消失因为它是此时该被所有活着的都会去竞选成为新的创建新的但是只会有一个竞选成功这点由保证竞选成功者即为新的竞选失败者则重新在新的上注册因为的是一次性的被一次之后即失效成功竞选为新的后会触发方法并在该方法中完成如下操作读取并增加在上注册在上注册通过在上注册若设置为默认值是则在上注册通过在上注册初始化对象设置当前所有的活着的列表所有的及等启动和将状态设置为将每个的信息发送给所有活着的若配置为默认值是则启动线程若设置为且中有值则删除相应的重新分配管理工具发出重新分配请求后会将相应信息写到上而该操作会触发从而通过执行回调函数来完成以下操作将中的更新为强制更新中向中的每个发送将中的设置为状态等待直到中所有的都与其同步将中所有的都设置为状态将中的设置为若不在中则从中重新选举出一个新的并发送若新的不是从中选举而来则还要增加中的将中的所有设置为状态该过程包含两部分第一将上中的移除并向发送从而通知这些已经从中移除第二向中的发送从而停止不再分配给该的将中的所有设置为状态从而将其从磁盘上删除将中的设置为删除注意最后一步才将中的更新因为这是唯一一个持久存储的地方如果在这一步之前新的仍然能够继续完成该过程从数据通过向发送获取消息每个请求都要指定最大等待时间和最小获取字节数以及由和构成的实际上从数据和从数据都是通过请求完成所以在结构中其中一个字段是并且其默认值是收到请求后通过相应该请求响应结果如下根据请求读出数据存入中如果该请求来自则更新其相应的以及相应的根据算出可读消息长度字节并存入中满足下面个条件中个即立即将对应数据返回请求不希望等待即请求不要求一定能取到消息即也即为空有足够的数据可供返回即读取数据时发生异常若不满足以上个条件将不会立即返回并将该请求封装成检查该是否满足若满足则返回请求否则将该请求加入列表保证同一中只有一个会消费某条消息实际上保证的是稳定状态下每一个实例只会消费某一个或多个特定的数据而某个的数据只会被某一个特定的实例所消费也就是说对消息的分配是以为单位分配的而非以每一条消息作为分配单元这样设计的劣势是无法保证同一个里的均匀消费数据优势是每个不用都跟大量的通信减少通信开销同时也降低了分配难度实现也更简单另外因为同一个里的数据是有序的这种设计可以保证每个里的数据可以被有序消费的算法如下将目标下的所有排序存于集合对某下所有排序存于集合第个记为向上取整解除对原来分配的的消费权从开始将第到个分配个在这种策略下每一个或者的增加或者减少都会出发每个只负责调整自己所消费的为了保证整个的一致性当一个出发时该的其它所有也应该同时出发有以下缺点任何或者的增减都会触发所有的每个分别单独通过判断哪些和宕机了那么不同在同一时刻从看到的就可能不一样这就可能造成不正确的尝试调节结果不可控所有都并不知道其他的是否正确这可能会导致工作在一个不正确的状态以后的版本提供了来解决上述缺点和新的加入组已有主动离开组或已有崩溃的时候会出发每个都会分配一个用于组管理和位移管理这个比原来承担了更多的责任比如组成员管理位移提交保护机制等当的启动时他会去和确定谁是它们组的之后该内所有成员都会和进行协调通信这种设计不再需要了性能得到很大提升的消费信息由之前存在在改为存储到一个特殊的中如何确定组内第一个消费者向集群中任意一个发送一个请求服务端会返回一个负载最小的节点的并将该设置为的位移信息写入哪个那么其分区所在就是用来标识之后的一代成员主要用于保护隔离无效提交的比如上一代的成员无法提交位移到下一代会报错误每次之后采用五个协议来处理问题请求需要定期给发送心跳来表明自己还活着请求主动告诉我要离开请求第一个加入的消费者把分配方案告诉组内所有成员请求成员请求加入组显示组的所有信息包括成员信息协议名称分配方案订阅信息等的五种状态组内已经没有任何成员的最终状态组的元数据信息也已经被移除这种状态响应各种请求都是一个组内无成员但是位移信息还没有过期这种状态只能响应请求如果所有都过期的话就会变成组准备开始新的等待成员加入正在等待分配方案给各个成员稳定的状态具体过程加入加入组这一步所有成员都向发送请求请求入组一旦所有成员都发送了请求会从中选择一个担任的角色和不是一个概念负责消费方案的执行同步开始分配消费方案即哪个负责消费哪些的哪些一旦完成分配会将这个方案封装进请求发送给非也会发请求只是内容为空接受到分配方案之后会把方案塞进的发送给各个这样组内的成员都直到自己应该消费哪些分区新增移除崩掉客户端只希望从顺序读取并处理数据而不太关心具体的也希望提供一些语义例如同一条消息只被某一个消息单播或被所有消息提供一个从消费数据的高层抽象从而屏蔽掉其中的细节并提供丰富的语义下订阅的下的每个分区只能分配给某个下的一个将从某个读取最后一条信息的存储于中是整个集群全局唯一的而非针对某个消费完的数据不会被立即删除可以选择立即删除或者对数据进行压缩使用的主要原因是用户希望比更好的控制数据的消费比如同一条消息读多次只读取某个的部分管理事务从而确保每条消息被处理一次且仅被处理一次与相比要求用户做大量的额外工作必须在应用程序中跟踪从而确定下一条应该消费哪条信息应用程序需要通过程序获知每个的是谁必须处理的变化使用的一般流程如下查找到一个活着的并且找出每个的找出每个的定义好请求该请求应该能描述应用程序需要哪些数据数据识别的变化并对之作出必要的响应如何通过中心实现成功的结果是被订阅的所有的每一个将会被内的一个有且仅有一个拥有每一个将被选举为某些的某个的负责在该的成员变化或者所订阅的的变化时协调操作',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-12-20 22:48:08',
  postMainColor: '',
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#18171d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#f7f9fe')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body data-type="anzhiyu"><div id="web_bg"></div><div id="an_music_bg"></div><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" alt="加载头像" src="/yangxiao.github.io/img/headimg.jpg"/><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.getElementById('loading-box').classList.add("loaded");
  },
  initLoading: () => {
    document.getElementById('loading-box').classList.remove("loaded")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })
setTimeout(function(){preloader.endLoading();},10000)

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.10/progress_bar/progress_bar.css"/><script async="async" src="https://cdn.cbd.int/pace-js@1.2.4/pace.min.js" data-pace-options="{ &quot;restartOnRequestAfter&quot;:false,&quot;eventLag&quot;:false}"></script><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><a id="site-name" href="/yangxiao.github.io/" accesskey="h"><div class="title">后端开发</div><i class="anzhiyufont anzhiyu-icon-house-chimney"></i></a></span><div class="mask-name-container"><div id="name-container"><a id="page-name" href="javascript:anzhiyu.scrollToDest(0, 500)">PAGE_NAME</a></div></div><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/yangxiao.github.io/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/yangxiao.github.io/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/yangxiao.github.io/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/yangxiao.github.io/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于本人</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/yangxiao.github.io/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="javascript:toRandomPost()"><i class="anzhiyufont anzhiyu-icon-shoe-prints1 faa-tada" style="font-size: 0.9em;"></i><span> 随便逛逛</span></a></li></ul></div></div></div><div id="nav-right"><div class="nav-button" id="randomPost_button"><a class="site-page" onclick="toRandomPost()" title="随机前往一个文章" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-dice"></i></a></div><input id="center-console" type="checkbox"/><label class="widget" for="center-console" title="中控台" onclick="anzhiyu.switchConsole();"><i class="left"></i><i class="widget center"></i><i class="widget right"></i></label><div id="console"><div class="console-card-group-reward"><ul class="reward-all console-card"><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png" target="_blank"><img class="post-qr-code-img" alt="微信" src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png" target="_blank"><img class="post-qr-code-img" alt="支付宝" src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div><div class="console-card-group"><div class="console-card-group-left"><div class="console-card" id="card-newest-comments"><div class="card-content"><div class="author-content-item-tips">互动</div><span class="author-content-item-title"> 最新评论</span></div><div class="aside-list"><span>正在加载中...</span></div></div></div><div class="console-card-group-right"><div class="console-card tags"><div class="card-content"><div class="author-content-item-tips">兴趣点</div><span class="author-content-item-title">寻找你感兴趣的领域</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/yangxiao.github.io/tags/Mysql/" style="font-size: 1.05rem;">Mysql<sup>1</sup></a><a href="/yangxiao.github.io/tags/test/" style="font-size: 1.05rem;">test<sup>1</sup></a><a href="/yangxiao.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/" style="font-size: 1.05rem;">中间件<sup>3</sup></a><a href="/yangxiao.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 1.05rem;">分布式<sup>1</sup></a><a href="/yangxiao.github.io/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/" style="font-size: 1.05rem;">搜索引擎<sup>1</sup></a></div></div><hr/></div></div><div class="console-card history"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-box-archiv"></i><span>文章</span></div><div class="card-archives"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/yangxiao.github.io/archives/2023/12/"><span class="card-archive-list-date">December 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">5</span><span>篇</span></div></a></li></ul></div><hr/></div></div></div><div class="button-group"><div class="console-btn-item"><a class="darkmode_switchbutton" title="显示模式切换" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-moon"></i></a></div><div class="console-btn-item" id="consoleHideAside" onclick="anzhiyu.hideAsideBtn()" title="边栏显示控制"><a class="asideSwitch"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></a></div><div class="console-btn-item" id="consoleMusic" onclick="anzhiyu.musicToggle()" title="音乐开关"><a class="music-switch"><i class="anzhiyufont anzhiyu-icon-music"></i></a></div></div><div class="console-mask" onclick="anzhiyu.hideConsole()" href="javascript:void(0);"></div></div><div class="nav-button" id="nav-totop"><a class="totopbtn" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i><span id="percent" onclick="anzhiyu.scrollToDest(0,500)">0</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" title="切换"><i class="anzhiyufont anzhiyu-icon-bars"></i></a></div></div></div></nav><div id="post-info"><div id="post-firstinfo"><div class="meta-firstline"><a class="post-meta-original">原创</a><span class="article-meta tags"><a class="article-meta__tags" href="/yangxiao.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>中间件</span></a><a class="article-meta__tags" href="/yangxiao.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>分布式</span></a></span></div></div><h1 class="post-title" itemprop="name headline">Kafka</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="anzhiyufont anzhiyu-icon-calendar-days post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" itemprop="dateCreated datePublished" datetime="2023-12-20T14:48:08.499Z" title="发表于 2023-12-20 22:48:08">2023-12-20</time><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-history post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" itemprop="dateCreated datePublished" datetime="2023-12-20T14:48:08.492Z" title="更新于 2023-12-20 22:48:08">2023-12-20</time></span></div><div class="meta-secondline"><span class="post-meta-separator">       </span><span class="post-meta-position" title="作者IP属地为长沙"><i class="anzhiyufont anzhiyu-icon-location-dot"></i>长沙</span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section><div id="post-top-cover"><img class="nolazyload" id="post-top-bg" src=""></div></header><main id="blog-container"><div class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container" itemscope itemtype="https://yangxiao23.github.io/yangxiao.github.io/2023/12/20/kafka/"><header><a href="/yangxiao.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/" tabindex="-1" itemprop="url">中间件</a><a href="/yangxiao.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" tabindex="-1" itemprop="url">分布式</a><h1 id="CrawlerTitle" itemprop="name headline">Kafka</h1><span itemprop="author" itemscope itemtype="http://schema.org/Person">XIAO YANG</span><time itemprop="dateCreated datePublished" datetime="2023-12-20T14:48:08.499Z" title="发表于 2023-12-20 22:48:08">2023-12-20</time><time itemprop="dateCreated datePublished" datetime="2023-12-20T14:48:08.492Z" title="更新于 2023-12-20 22:48:08">2023-12-20</time></header><h1 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h1><h2 id="kafka总体概览"><a href="#kafka总体概览" class="headerlink" title="kafka总体概览"></a>kafka总体概览</h2><blockquote>
<p>kafka一个多分区、多副本基于zookeeper协调的分布式消息系统，分布式流式处理平台。</p>
</blockquote>
<blockquote>
<p>流数据是一组顺序、大量、快速、连续到达的数据序列。一般情况下，流数据可被视为一个随时间延续而无限增长动态数据的集合。</p>
</blockquote>
<p>kafka可以扮演的角色：</p>
<ul>
<li>消息系统： 具备系统解耦、冗余存储、流量消峰、缓冲、异步通信、拓展性和可恢复性。还提供消息顺序性保障和回溯消费。</li>
<li>存储系统： kafka把消息持久化磁盘，可以降低数据丢失风险。</li>
<li>流式处理平台： Kafka 不仅为每个流行的流式处理框架提供了可靠的数据来源，还提供了一个完整的流式处理类库，比如窗口、连接、变换和聚合等各类操作。</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://gitee.com/yangxiao2000/md_img/raw/master/images/20230910152026.png" alt="1694330420239.png"></p>
<blockquote>
<p>zookeeper是kafka用来负责集群元数据管理、控制器选举等操作。</p>
</blockquote>
<blockquote>
<p>kafka中消息以主题为单位进行归类。同一主题下不同分区包含的消息是不同的，分区在存储层面可以看作一个可追加的日志文件，消息在被追加到分区日志文件的时候都会分配一个特定的偏移量。offset不跨分区，分区有序、主题不有序。</p>
</blockquote>
<blockquote>
<p>每条消息被发送到broker之前，会根据<strong>分区规则</strong>选择存储到某个具体分区。多副本机制提高了系统的容灾能力。副本之间是”一主多从“关系，leader负责读写请求，follower负责与leader保持消息同步，以及故障恢复。</p>
</blockquote>
<blockquote>
<p>kafka消费端也具备一定容灾能力。consumer采用拉模式从服务端拉取信息，并且保存消费的具体位置，当消费者宕机后恢复上线时可以根据保存的消费位置重新拉取所需要的信息进行消费，不会造成消息丢失。</p>
</blockquote>
<blockquote>
<p>分区所有副本统称为AR。所以与Leader副本保持一定程度同步的副本(包括leader)组成ISR。与leader副本同步之后过多的副本组成OSR。leader副本负责维护和跟踪ISR中所有follower副本的滞后状态，当follower副本落后太多或失效，leader副本会把ISR集合中剔除。<strong>默认情况下</strong>，当leader副本发生故障时，只有在ISR集合中的副本才有资格被选举为新的leader，而在OSR集合的副本没有机会。</p>
</blockquote>
<blockquote>
<p>HW(High Watermark)高水位，表示一个特定的偏移量，消费者只能拉取这个offset之前的消息。LEO(Log End Offset)，当前日志文件中下一条待写入消息的offset。分区ISR集合中每个副本都会维护自身的LEO，而ISR集合中最小的LEO即为分区的HW。</p>
</blockquote>
<blockquote>
<p>kafka的复制机制既不是完全的同步复制也不是单纯的异步复制。isr机制有效权衡数据可靠性和性能之间的关系。</p>
</blockquote>
<h2 id="服务端参数配置"><a href="#服务端参数配置" class="headerlink" title="服务端参数配置"></a>服务端参数配置</h2><ul>
<li><p>zookeeper.connect:指明broker要连接的zookeeper集群地服务地址（包括端口号）。多个zookeeper节点通过逗号隔开。如果想利用一个zookeeper集群管理多个kafka集群，可以加上chroot。类似localhost:2181&#x2F;chroot.</p>
</li>
<li><p>listeners: 指明broker监听客户端连接的地址列表，即为客户端要连接broker的入口地址列表，配置格式为protocol1:&#x2F;&#x2F;hostname1:port1,protocol2:&#x2F;&#x2F;hostname2:port2。&#96;protocol当前支持的协议有PLAINTEXT、SSL、SASL_SSL等。此参数默认为null。如果有多个地址，中间使用逗号分隔。如果不指定主机名，则表示绑定默认网卡，可能会绑定到127.0.0.1,这样就无法对外提供服务，所以主机名最好不要为空。</p>
</li>
<li><p>advertised.listeners:作用和listeners类似，默认值也为null。不过advertised.listeners主要用于IaaS环境。公有云上的机器一般配置多块网卡，包含私有网卡和共有网卡，对于这种情况，可以设置advertised.listeners参数绑定公网IP供外部客户端使用，而配置listeners参数来绑定私网IP地址供broker间通信使用。</p>
</li>
<li><p>broker.id:指定kafka集群中broker的唯一标识。如果没有设置，那么kafka会默认自动生成一个。</p>
</li>
<li><p>log.dir和log.dirs:kafka把所有消息都保存在磁盘上，这两个参数用来配置kafka日志文件存放的根目录。一般情况，log.dir用来配置单个根目录，而log.dirs用来配置多个根目录（逗号分割）。log.dirs优先级大于log.dir。默认情况只配置log.dir为&#x2F;tmp&#x2F;kafka-logs。</p>
</li>
<li><p>message.max.bytes:该参数用来指定broker所能接收信息的最大值。默认为1000012B.如果生产者发送的消息大于这个参数所设置的值，那么就会报<code>RecordTooLargeException</code>异常。如果要修改这个参数还要考虑<code>max.request.size</code>(客户端参数)、<code>max.message.bytes</code>(topic参数)等影响。</p>
</li>
<li><p>max.request.size: 用于限制producer和consumer请求的大小。</p>
</li>
<li><p>max.message.bytes: 定义消费者可以接收的最大消息大小。</p>
</li>
<li><p><code>client.id</code>：用来标识kafka生产者的唯一标识。</p>
</li>
</ul>
<h2 id="生产者相关"><a href="#生产者相关" class="headerlink" title="生产者相关"></a>生产者相关</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//java中生产消息对象</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ProducerRecord</span>&lt;K,V&gt; &#123;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> String topic;<span class="comment">//主题</span></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> Integer partition;<span class="comment">//分区号</span></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> Headers headers;<span class="comment">//消息头部</span></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> K key;<span class="comment">//键，可以用来计算分区好进而让消息发往特定分区</span></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> V value;<span class="comment">//值</span></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> Long timestamp;<span class="comment">//消息的时间戳</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>headers:消息头部，kafka 0.11.x版本引入这个属性，大多时候用来设定一些与应用相关的信息。</li>
<li>key：用来指定消息的键，它不仅是消息的附加信息，还可以用来计算分区号进而可以让消息发往特定的分区。**同一个key的消息会被划分到同一个分区中。有key的消息还可以支持日志压缩的功能。</li>
<li>value:消息体，一般不为空。为空则表示特定的消息-墓碑消息。</li>
<li>timestamp:消息的时间戳。它有CreateTime和LogAppendTime两种类型，前者表示消息创建的时间，后者表示消息追加到日志文件的时间。</li>
</ul>
<p>在java生产者客户端中必须要填写的参数:</p>
<ul>
<li>bootstrap.servers: 指定生产者客户端连接kafka集群所需的broker地址清单。不必全部列出，<strong>生产者能从给定的broker查找到其它broker的信息。</strong> 建议设置两个以上。</li>
<li>key.serializer和value.serializer: broker端接口消息必须以<strong>字节数组形式存在</strong>。</li>
<li>client.id :   设定kafkaProducer对应的客户端id，默认值为空字符串。不设置会自动生成一个非空字符串。</li>
</ul>
<blockquote>
<p> <strong>KafkaProducer是线程安全的</strong>，可以在多个线程中共享单个KafkaProducer实例，也可以将KafkaProducer实例进行池化供其它线程调用。</p>
</blockquote>
<blockquote>
<p>创建生产者实例和构建消息之后，就可以开始发送消息。发送消息主要有三种模式：发后即忘、同步、异步。</p>
</blockquote>
<ul>
<li>发后既忘： 只负责往kafka发送消息，不关心消息是否正确到达。在某些时候(发生不可重试异常时)会造成消息丢失。性能最高，可靠性最差。</li>
<li>同步发送： 可靠性最高，要么发送成功，要么发生异常。性能会差很多，需要阻塞等待一条消息发送成功才能发送另一条。</li>
<li>异步发送： 指定回调函数，kafka在返回响应时调用该函数进行异步发送确认。</li>
</ul>
<p>KafkaProducer一般会发生两种类型的异常：可重试的异常和不可重试的异常。对于可重试的异常，只需要在配置retries次数内恢复，就不会抛出异常。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//生产者异步发送，回调函数确认</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">NoSyncSend</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">TOPIC</span> <span class="operator">=</span> <span class="string">&quot;topic-demo&quot;</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> KafkaConfigUtil.initProducerConfig();</span><br><span class="line">        KafkaProducer&lt;String,String&gt; producer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;String, String&gt;(properties);</span><br><span class="line">        ProducerRecord&lt;String, String&gt; record = <span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;String, String&gt;(TOPIC, <span class="string">&quot;hello&quot;</span>);</span><br><span class="line">        Future&lt;RecordMetadata&gt; future = producer.send(record, <span class="keyword">new</span> <span class="title class_">Callback</span>() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCompletion</span><span class="params">(RecordMetadata metadata, Exception e)</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> (<span class="literal">null</span> != e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    System.out.println(metadata.topic()+<span class="string">&quot; -&quot;</span>+metadata.partition()+<span class="string">&quot;-&quot;</span>+metadata.offset()+metadata.timestamp());</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>对于同一个分区而言，如果消息record1于record2之前先发送，那么kafkaProducer就可以保证对应的callback1在callback2之前调用，<strong>回调函数的调用也可以保证分区有序。</strong></p>
</blockquote>
<blockquote>
<p>发送完这些消息之后，需要调用kafkaProducer的close方法回收资源。close方法会阻塞等待之前所有发送请求完成后再关闭kafkaProducer.也提供带有时间参数close方法，超时强制退出。</p>
</blockquote>
<h3 id="序列化器"><a href="#序列化器" class="headerlink" title="序列化器"></a>序列化器</h3><blockquote>
<p>生产者需要用序列化器<strong>把对象转换成字节数组</strong>才能通过网络发送给broker。消费者需要用反序列化器把从broker收到的字节数组转换成相应的对象。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//生产者序列化器格式</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">StringSerializer</span> <span class="keyword">implements</span> <span class="title class_">Serializer</span>&lt;String&gt; &#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="type">String</span> <span class="variable">encoding</span> <span class="operator">=</span> <span class="string">&quot;UTF8&quot;</span>;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">StringSerializer</span><span class="params">()</span> &#123;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Map&lt;String, ?&gt; configs, <span class="type">boolean</span> isKey)</span> &#123;  </span><br><span class="line">        <span class="type">String</span> <span class="variable">propertyName</span> <span class="operator">=</span> isKey ? <span class="string">&quot;key.serializer.encoding&quot;</span> : <span class="string">&quot;value.serializer.encoding&quot;</span>;  </span><br><span class="line">        <span class="type">Object</span> <span class="variable">encodingValue</span> <span class="operator">=</span> configs.get(propertyName);  </span><br><span class="line">        <span class="keyword">if</span> (encodingValue == <span class="literal">null</span>) &#123;  </span><br><span class="line">            encodingValue = configs.get(<span class="string">&quot;serializer.encoding&quot;</span>);  </span><br><span class="line">        &#125;  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">if</span> (encodingValue <span class="keyword">instanceof</span> String) &#123;  </span><br><span class="line">            <span class="built_in">this</span>.encoding = (String)encodingValue;  </span><br><span class="line">        &#125;  </span><br><span class="line">  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="type">byte</span>[] serialize(String topic, String data) &#123;  </span><br><span class="line">        <span class="keyword">try</span> &#123;  </span><br><span class="line">            <span class="keyword">return</span> data == <span class="literal">null</span> ? <span class="literal">null</span> : data.getBytes(<span class="built_in">this</span>.encoding);  </span><br><span class="line">        &#125; <span class="keyword">catch</span> (UnsupportedEncodingException var4) &#123;  </span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">SerializationException</span>(<span class="string">&quot;Error when serializing string to byte[] due to unsupported encoding &quot;</span> + <span class="built_in">this</span>.encoding);  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="分区器"><a href="#分区器" class="headerlink" title="分区器"></a>分区器</h3><blockquote>
<p>消息在通过send()方法发往broker的过程中，有可能需要经过拦截器(Interceptor)、序列化器(Serializer)和分区器(Partitiner)的一系列之后才能真正地被发往broker。<strong>如果在消息ProducerRecord中指定了partition字段，那么就不需要分区器的作用。</strong></p>
</blockquote>
<blockquote>
<p>分区器默认根据key字段来计算partition的值，为消息分配分区。如果key不为null，那么默认的分区器会对key进行哈希算法，根据计算的哈希值计算出分区号，拥有相同key的消息被写入同一个分区。如果key为null，那么消息将会<strong>以轮询的方式发往主题内的各个可用分区。</strong><br>如果key不为null，那么计算的得到的分区号会是<strong>所有分区</strong>中的任意一个；如果key为null，那么计算得到的分区号仅为<strong>可用分区</strong>中的任意一个。</p>
</blockquote>
<blockquote>
<p>在不改变主题分区数量的情况下，key与分区之间的映射可以保持不变。不过，一旦主题中增加了分区，那么就难以保证key与分区之间的映射关系。</p>
</blockquote>
<blockquote>
<p>默认每个<code>kafkaProducer</code>实例都会创建自己的分区器实例。</p>
</blockquote>
<h3 id="拦截器"><a href="#拦截器" class="headerlink" title="拦截器"></a>拦截器</h3><blockquote>
<p>拦截器是在kafka0.10.0.0中就已经引入的一个功能。kafka一共有两种拦截器：生产者拦截器和消费者拦截器。<br>生产者拦截器既可以用来在消息发送前做一些准备工作，比如按照某个规则过滤不符合要求的消息、修改消息的内容等。也可以用来在发送回调逻辑前做一些定制化的需求,比如统计类工作。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//自定义拦截器需要实现这个接口</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">ProducerInterceptor</span>&lt;K, V&gt; <span class="keyword">extends</span> <span class="title class_">Configurable</span> &#123;  </span><br><span class="line">    <span class="comment">//消息序列化、计算分区之前调用。</span></span><br><span class="line">    ProducerRecord&lt;K, V&gt; <span class="title function_">onSend</span><span class="params">(ProducerRecord&lt;K, V&gt; var1)</span>;  </span><br><span class="line">    <span class="comment">//消息被应答之前或消息发送失败时调用</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">onAcknowledgement</span><span class="params">(RecordMetadata var1, Exception var2)</span>;  </span><br><span class="line">    <span class="comment">//关闭拦截器执行时的资源清理</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span>;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Configurable接口中的configure()方法主要用来获取配置信息及初始化数据。</p>
</blockquote>
<blockquote>
<p>onAcknowledgement方法，这个方法运行再Producer的I&#x2F;O线程中，这个方法实现代码逻辑越简单越好，否则影响消息的发送速度。</p>
</blockquote>
<blockquote>
<p>多拦截器之间使用<code>,</code>进行分割。</p>
</blockquote>
<h2 id="kafka生产者客户端原理"><a href="#kafka生产者客户端原理" class="headerlink" title="kafka生产者客户端原理"></a>kafka生产者客户端原理</h2><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/86ef202cb49d48c6a6642d09f45308e5~tplv-k3u1fbpfcp-watermark.image" alt="faf2b2119313b07e0cf5f90de9f18e2b97dd8c1e.webp"></p>
<blockquote>
<p>整体生产者客户端由两个线程协调运行，这两个线程分别是<code>主线程</code>和<code>Sender线程</code>。</p>
</blockquote>
<blockquote>
<p>在主线程中由kafkaProducer创建消息，然后通过拦截器、序列化器和分区器的作用之后<strong>缓存到消息收集器</strong>。sender线程负责从消息收集器中获取消息并将其发送到kafka中。</p>
</blockquote>
<blockquote>
<p>RecordAccumlator(消息收集器)主要用来<code>缓存消息以便sender线程可以批量发送，进而减少网络传输的资源消耗以提升性能</code>。消息收集器的缓存大小通过生产者客户端参数<code>buffer.memory</code>配置。如果生产者发送消息的速度超过发送到服务器的速度，则会导致生产者空间不足，这时候调用send方法要么被阻塞，要么抛出异常，这个取决于参数<code>max.block.ms</code>的配置，</p>
</blockquote>
<blockquote>
<p>主线程中发送过来的消息都会被追加到RecordAccumlator的某个双端队列(为每个分区都维护了一个)，队列中的内容是ProducerBatch。消息写入缓存时，追加到双端队列的尾部；sender读取消息时，从双端队列的头部读取。ProducerBatch可以包含一至多个ProducerRecord，通常被称为<code>消息批次</code>。<strong>ProducerRecord会被包含在ProducerBatch中，这样可以使字节的作用更加紧凑。与此同时，将较小的ProducerReord拼凑成一个较大的ProducerBatch，可以减少网络请求的次数以提升整体的吞吐量。</strong></p>
</blockquote>
<blockquote>
<p>消息在网络上都是以<code>字节</code>的形式传输的，在发送之前需要创建一块内存区域来保存对应的消息。在kafka生产者客户端中，通过java.io.ByteBuffer实现消息内存的创建和释放。RecordAccumulator的内部还有一个<code>BufferPool</code>，它主要用<strong>来实现ByteBuffer的复用，以实现缓存的高效利用</strong>。BufferPool只能实现特定大小(batch.size)的内存复用。</p>
</blockquote>
<blockquote>
<p>ProducerBatch的大小和<code>batch.size</code>参数有着密切关系。当一条消息(ProducerRecord)流入RecordAccumulator时，会<strong>先寻找与消息分区所对应的双端队列</strong>（如果没有则新建），在<strong>从这个双端队列的尾部获取一个ProducerBatch</strong>（如果没有则新建），查看ProducerBatch中<strong>是否还可以写入这个ProducerRecord</strong>，如果可以则写入，<strong>如果不可以则需要创建一个新的ProducerBatch。</strong> 在新建ProducerBatch时评估这条消息的大小是否超过batch.size，如果不超过，那么就以batch.size参数大小来创建ProducerBatch，这样在使用完这段区域之后，可以通过BufferPool的管理进行复用；如果超过，那么就以评估的大小来创建ProducerBatch，这段内存区域不会被复用。</p>
</blockquote>
<blockquote>
<p>Sender从RecordAccumulator中获取缓存的消息之后，会进一步将原本&lt;分区, Deque&lt; ProducerBatch&gt;&gt;的保存形式转换变为&lt; Node , List &lt; ProducerBatch&gt;&gt;的形式。Node表示kafka集群的broker节点。在转换成&lt;Node, List&lt; ProducerBatch&gt;&gt;的形式之后，Sender会进一步封装成&lt;Node, Request&gt;形式，这样就能将Request发往各个Node。</p>
</blockquote>
<blockquote>
<p>请求在Sender线程发往Kafka之前还会保存到InFlightRequests中，InFlightRequests保存对象的具体形式Map&lt;NodeId, Deque&lt; Request&gt;&gt;,它的主要作用时<strong>缓存了已经发出去但还没有收到响应的请求。</strong> InflightRequests还提供了很多管理类的方法，并且通过配置参数(<code>max.in.flight.requests.per.connection</code>)还可以限制每个连接（客户端和Node之间）最多缓存的请求数。默认为5，最多缓存5个未响应的请求。超过了该数值之后就不能再向这个连接发送更多的请求。</p>
</blockquote>
<blockquote>
<p>InFlightRequests还可以获得leatLoadedNode，即所有Node中负载最小的那一个。负载大小通过每个Node还未确认的请求决定。选择leastLoadedNode发送请求可以让请求尽快发出，避免因网络堵塞等异常影响整体进度。</p>
</blockquote>
<h3 id="元数据的更新"><a href="#元数据的更新" class="headerlink" title="元数据的更新"></a>元数据的更新</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ProducerRecord&lt;String,String&gt; record = <span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(topic, <span class="string">&quot;hello kafka&quot;</span>);</span><br></pre></td></tr></table></figure>

<blockquote>
<p>上述消息我们只知道topic,kafkaProducer要将此消息追加至指定主题的某个分区所对应的leader副本之前，首先需要知道主题的分区数量，然后经过计算得出目标分区，之后kafkaProducer需要知道目标分区的leader副本所在的broker节点地址、端口等信息才能建立连接，最终才能将消息发送至kafka。<strong>以上所需要的信息都属于元数据信息。</strong></p>
</blockquote>
<blockquote>
<p>kafka集群的元数据具体记录了集群中有哪些主题，这些主题有哪些分区，每个分区的leader副本分配在哪个节点上，follower副本分配在哪些节点上，哪些副本在AR、ISR等集合中，集群中有哪些节点等。</p>
</blockquote>
<blockquote>
<p>当客户端中没有需要使用的元数据信息时或者超<code>metadata.max.age.ms</code>时间没有更新元数据都会引起元数据的更新操作。当需要更新元数据，会先挑选出leastLoadedNode，然后这个Node发送MetadataRequest请求来获取具体的元数据信息。这个操作由Sender线程发起，在创建完MetadataRequest之后同样会存入InFlightRequests。<strong>元数据由Sender线程负责更新</strong>，但是主线程也需要这些信息，数据同步通过synchronized和final关键字保障。</p>
</blockquote>
<h3 id="生产者重要参数"><a href="#生产者重要参数" class="headerlink" title="生产者重要参数"></a>生产者重要参数</h3><ul>
<li><code>acks</code>: 用来指定分区中必须有多少个副本收到这条消息，之后生产者才会认为这条消息是成功写入的。涉及消息可靠性和吞吐量的权衡，分为三种类型。<ul>
<li>acks&#x3D;1:默认值生产者发送消息之后，只要分区的leader副本成功写入消息，那么他就会收到来自服务端的成功响应。如果消息无法写入leader那么生产者就会收到一个错误的响应，为了避免消息丢失，生产者可以选择重发消息。存在消息被认定成功写入之后发生丢失情况,leader写入成功后崩溃，isr中其它followere没有同步。</li>
<li>acks&#x3D;0: 生产者发送消息之后不需要等待任何服务端的响应。如果在消息从发送到写入kafka的过程中出现某些异常，导致kafka没有收到这条消息，生产者也无从得知。吞吐量最大。</li>
<li>acks&#x3D;-1或acks &#x3D;all: 生产者在消息发送之后，需要等待ISR中所有副本都成功写入消息之后才能收到服务端的成功响应。<strong>可靠性最高</strong>。但不意味着不会丢失数据，如果isr只有leader副本，退化成acks&#x3D;1的情况了。</li>
</ul>
</li>
<li><code>max.request.size</code>:限制生产者客户端能发送的消息的最大值。默认1MB。</li>
<li><code>retries</code>和<code>retry.backoff.ms</code>: retries用来配置生产者重试的次数，默认为0。即在发生异常的时候不进行任何重试动作。 消息从生产者发送到成功写入服务器之前可能发生一些临时性的异常，如网络抖动、leader副本选举等，这种异常往往可以自行恢复，生产者可以通过配置retries进行内部重试。 retry.backoff.ms默认100，用来设定两次重试之间的时间间隔。</li>
<li><code>compression.type</code>:消息的压缩方式，默认none。消息压缩是时间换空间的一种做法。对消息进行压缩，可以降低网络I&#x2F;O。<br>-<code> connections.max.idle.ms</code>: 指定在多久之后关闭闲置的连接。默认9分钟。</li>
<li><code>linger.ms</code>:指定生产者发送ProducerBatch之前等待更多消息加入ProducerBatch的时间，默认为0.生产者客户端会在ProducerBatch被填满或等待时间超过linger.ms值发送出去。增大这个值可以提供吞吐量，但会增加延迟。</li>
<li><code>receive.buffer.bytes</code>:设置Socket接收消息缓冲区大小。设置为-1为操作系统默认值。</li>
<li><code>send.buffde.bytes</code>: 设置Socket发送消息缓冲区的大小。</li>
<li><code>request.timeout.ms</code>:配置Producer等待请求响应的最长时间。这个参数要比broker端<code>replica.lag.time.max.ms</code>要大，这样可以减少因客户端重试而引起的消息重复概率。</li>
<li><code>max.in.flight.requests.per.connection</code>: 配置参数限制了单个连接上未确认的并发请求数。</li>
<li><code>buffer.memory</code>: 生产者客户端用于缓存消息的缓存区大小。</li>
<li><code>max.blcok.ms</code>: kafkaProducer中send方法和partitionsFor方法的阻塞时间。当生产者的发送缓存区或者没有可用的元数据时，这个方法就会阻塞。</li>
<li><code>enable.idempotence</code>: 是否开启幂等性功能。</li>
<li><code>transactional.id</code>: 设置事务id，必须唯一。</li>
</ul>
<blockquote>
<p>如果将<code>acks</code>配置为非零值，并且<code>max.in.flight.requests.per.connection</code>参数配置大于1,那么就会出现乱序的现象。发送顺序为A、B，A失败，重试发送之前，B成功发送，出现乱序。</p>
</blockquote>
<h2 id="消费者和消费组"><a href="#消费者和消费组" class="headerlink" title="消费者和消费组"></a>消费者和消费组</h2><blockquote>
<p>消费者负责订阅kafka中的主题，并从订阅的主题上<strong>拉取</strong>消息。每个消费者都有一个对应的消费组。<strong>当消息发布到主题后，只会被投递给订阅它的消费者中的一个消费者。</strong>每个消费者只能消费所分配到的分区中的消息。每一个分区只能被一个消费组中的一个消费者所消费。</p>
</blockquote>
<p><strong>当消费组内的消费者个数变化，分区分配一般会进行改变</strong>。</p>
<blockquote>
<p>消费者与消费组这种模型可以让整体的消费能力具备<strong>横向伸缩性</strong>，可以通过增加（减少）消费者的数量来提高（降低）整体的消费能力。对于分区数固定的情况，一味的增加消费者并不会让消费能力上升，如<strong>果消费者过多，可能出现有消费者分配不到任何分区。</strong></p>
</blockquote>
<p><strong>以上都是结论都是基于默认分区分配策略进行分析。</strong></p>
<p>消息中间件，一般有两种消息投递模式：点对点和发布&#x2F;订阅模式。</p>
<ul>
<li>点对点模式是基于队列的，消息生产生发送消息到队列，消息消费者从队列中接收消息。</li>
<li>发布订阅模式：定义了如何向一个内容节点发布和订阅消息，这个内容节点就是<strong>主题</strong>，主题可以认为是消息传递的中介。发布&#x2F;订阅模式在消息的一对多广播时采用。</li>
</ul>
<p>kafka同时支持两种消息传递模式。</p>
<ul>
<li>如果所有消费者都隶属同一个消费组，那么消息会被投递单个消费者，相当于点对点。</li>
<li>如果所有消费者隶属不同的消费组，那么所有消息都会广播给所有消费者。</li>
</ul>
<blockquote>
<p>消费者并非逻辑上的概念，它是实际的应用实例，可以是一个线程，进程。</p>
</blockquote>
<h2 id="客户端开发"><a href="#客户端开发" class="headerlink" title="客户端开发"></a>客户端开发</h2><p>kafka 0.9.x之后推出使用java编写的客户端。<br>一个正常的消费逻辑具备以下几个步骤：</p>
<ul>
<li>配置消费者客户端参数及创建相应的消费者实例。</li>
<li>订阅主题。</li>
<li>拉取消息并消费。</li>
<li>提交消费位移。</li>
<li>关闭消费者实例。</li>
</ul>
<h3 id="必要的参数配置"><a href="#必要的参数配置" class="headerlink" title="必要的参数配置"></a>必要的参数配置</h3><ul>
<li><code>bootstrap.servers</code>:指定连接的kafka集群所需的broker地址清单。</li>
<li><code>group.id</code>:消费者隶属的消费组。默认为“”.如果为空，则会报错。</li>
<li><code>key.deserializer</code>和<code>value.deserializer</code>:与生产者的key.serializer和value.serializer参数对应。将从broker获取的字节数组转换成具体对象实例的反序列化器。</li>
<li><code>client.id</code> : kafkaConsumer对应的客户端clientId.</li>
</ul>
<h3 id="订阅主题和分区"><a href="#订阅主题和分区" class="headerlink" title="订阅主题和分区"></a>订阅主题和分区</h3><blockquote>
<p>一个消费者可以<strong>订阅一个或多个主题</strong>，可以使用subscribe()方法可以以集合形式订阅多个主题，也可以用正则表达式的形式订阅特定模式的主题。订阅同时可以设置再均衡监听器。</p>
</blockquote>
<blockquote>
<p>如果消费者采用正则表达式的方式订阅，再之后的过程中，如果有人又创建了新的主题，并且主题的名字和正则表达式相匹配，那么这个消费者就可以消费到新添加到主题中的消息。</p>
</blockquote>
<blockquote>
<p>消费者不仅可以通过kafkaConsumer.subscribe()方法订阅主题，还<strong>可以直接订阅某些主题的特定分区</strong>，在kafkaconsumer中提供了一个assign()方法来实现这些功能。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">assign</span><span class="params">(Colletion&lt;TopicPartition&gt; partitions)</span></span><br><span class="line"><span class="comment">//类属性</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">class</span> <span class="title class_">TopicPartition</span> <span class="keyword">implements</span> <span class="title class_">Serializable</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> <span class="variable">hash</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> partition;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String topic;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//kafkaConsumer.partitionFor()方法可以用来查询指定主题元数据。</span></span><br><span class="line"><span class="keyword">public</span> List&lt;PartitionInfo&gt; <span class="title function_">partitionFor</span><span class="params">(String topic)</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">partitionInfo</span>&#123;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> String topic;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> partition;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> Node leader;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> node[] replicas;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> node[] inSyncReplicas;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> node[] offlineReplicas;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>可以通过unsubscribe()方法取消主题的订阅。可以通过集合或者Pattern方式进行取消订阅。如果将subscribe订阅的集合设置为空集合相当于取消订阅。如果没有订阅任何主题或分区，执行消费程序会抛出异常。</p>
</blockquote>
<blockquote>
<p>通过subescribe()方法订阅主<strong>题具有消费者自动再均衡的功能</strong>，再多个消费者的情况下可以根据分区分配策略来自动分配各个消费者与分区的关系。当消费组内的消费者增加或减少时，分区分配关系会自动调整。而通过assign()方法订阅分区时，是<strong>不具备消费者自动均衡的功能的。</strong></p>
</blockquote>
<h3 id="反序列化"><a href="#反序列化" class="headerlink" title="反序列化"></a>反序列化</h3><blockquote>
<p>生产者有序列化器那么消费者就会有反序列化器。kafka提供了ByteBufferDeserializer、ByteArrayDeserializer等反序列化器。这些序列化器都实现了Deserializer接口，。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Map&lt;String, ?&gt; configs, <span class="type">boolean</span> isKey)</span><span class="comment">//用来配置当前类</span></span><br><span class="line">T <span class="title function_">deserialize</span><span class="params">(String topic, <span class="type">byte</span>[] var2)</span>;</span><br><span class="line">data)<span class="comment">//执行反序列化，如果data为null，那么处理的时候直接返回null。</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span><span class="comment">//用来关闭当前序列化器。</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>一般情况下，不建议使用自定义序列化器或反序列化器，因为这样会增加生产者与消费者之间的耦合度。在系统升级换代的时候容易出错。</p>
</blockquote>
<blockquote>
<p>在实际应用中，在kafka提供的序列化器和反序列化器满足不了应用需求的前提下，推荐使用Avro、JSON等通用的序列化工具进行包装。</p>
</blockquote>
<h3 id="消费者消费"><a href="#消费者消费" class="headerlink" title="消费者消费"></a>消费者消费</h3><blockquote>
<p>kafka中的消费是基于拉模式的。消息的消费一般有两种模式：推模式和拉模式。<br>推模式：服务端主动将消息推送给消费者。<br>拉模式：消费者主动向服务端发起请求来拉取消息。</p>
</blockquote>
<blockquote>
<p>kafka中的消息消费是一个<strong>不断轮询</strong>的过程，消费者所要做的就是重复地调用poll()方法，而poll()方法返回的是<strong>所订阅的主题（分区）上的一组消息</strong>。<br>  对于poll()方法而言，如果某些分区中没有可供消费的消息，那么此分区对应的消息拉取的结果就为空。如果订阅的所有分区都没有可供消费的消息，那么poll()方法返回为空的消息集合。</p>
</blockquote>
<blockquote>
<p>poll方法中有一个超时时间参数timeout，用来控制Poll()方法的阻塞时间，<strong>在消费者缓冲区里没有可用数据时会发生阻塞。</strong><br>  timeout的设置取决于应用程序对响应速度的要求，比如需要在多长时间内将控制权移交给执行轮询的应用线程。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ConsumerRecord</span>&lt;K, V&gt; &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">NO_TIMESTAMP</span> <span class="operator">=</span> -<span class="number">1L</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">NULL_SIZE</span> <span class="operator">=</span> -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">NULL_CHECKSUM</span> <span class="operator">=</span> -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String topic;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> partition;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">long</span> offset;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">long</span> timestamp;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> TimestampType timestampType;<span class="comment">//创建时间戳和消息追加到日志的时间戳</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> serializedKeySize;<span class="comment">//经过序列化之后key的大小</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> serializedValueSize;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Headers headers;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> K key;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> V value;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Optional&lt;Integer&gt; leaderEpoch;</span><br></pre></td></tr></table></figure>

<blockquote>
<p><code>CosumerRecords.partitions()</code>用来获取消息集中所有分区。在consumerRecords类中还提供按照主题维护来进行消费。</p>
</blockquote>
<h3 id="位移提交"><a href="#位移提交" class="headerlink" title="位移提交"></a>位移提交</h3><blockquote>
<p><strong>对于kafka分区而言，它的每个消息都有唯一的offset，用来表示消息在分区中对应的位置。</strong> 消息者也有offset的概念，消费者使用offset来表示消费到分区中某个消息所在的位置。</p>
</blockquote>
<blockquote>
<p><strong>在新的消费者客户端中，消费位移存储在kafka内部的主题_consumer_offsets中。</strong> 提交的消费唯一是已经消费的位移最大值+1.</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> kafka.consumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.TopicPartition;</span><br><span class="line"><span class="keyword">import</span> util.KafkaConfigUtil;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.time.Duration;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestConsumer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">TOPIC</span> <span class="operator">=</span> <span class="string">&quot;topic-demo&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> KafkaConfigUtil.initConsumerConfig();</span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;&gt;(properties);</span><br><span class="line">        <span class="type">TopicPartition</span> <span class="variable">partition</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TopicPartition</span>(TOPIC, <span class="number">0</span>);</span><br><span class="line">        consumer.assign(Arrays.asList(partition));</span><br><span class="line">        <span class="type">long</span> <span class="variable">lastConsumedOffset</span> <span class="operator">=</span> -<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>(<span class="literal">true</span>)&#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(<span class="number">1000</span>));</span><br><span class="line">            <span class="keyword">if</span> (records.isEmpty()) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            List&lt;ConsumerRecord&lt;String, String&gt;&gt; list = records.records(partition);</span><br><span class="line">            lastConsumedOffset = list.get(list.size() - <span class="number">1</span>).offset();</span><br><span class="line">            consumer.commitAsync();<span class="comment">//同步提交位移</span></span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">&quot;comsumerd offset is &quot;</span>+ lastConsumedOffset);</span><br><span class="line">        <span class="type">OffsetAndMetadata</span> <span class="variable">offsetAndMetadata</span> <span class="operator">=</span> consumer.committed(partition);</span><br><span class="line">        System.out.println(offsetAndMetadata.offset());</span><br><span class="line">        System.out.println(consumer.position(partition));</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>消费者对于位移的具体时机把握也很有讲究，有<strong>可能会造成重复消费和消息丢失的现象。</strong></p>
</blockquote>
<blockquote>
<p>参考下图，当前poll（）操作所拉取的消息集为[x+2, x+7],x+5表示当前正在处理的位置。如果拉取到消息之后就进行位移提交，提交了x+8,那么当前消费x+5遇到了异常，在故障恢复之后，我们重新拉取的消息是在x+8开始的。也就是说，x+5至x+7之前的消息并未被消息，出现消息丢失的现象。</p>
</blockquote>
<blockquote>
<p>另一种情形，位移提交的动作是在消费完所有拉取的消息之后才执行，那么当消费到x+5的时候遇到了异常，在故障恢复之后，重新拉取消息从x+2开始，故又发生了重复消费的现象。</p>
</blockquote>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8138de947c0141d9ae2c57f24183b01a~tplv-k3u1fbpfcp-watermark.image" alt="截图.png"></p>
<blockquote>
<p>在kafka中<strong>默认的消费位移的提交方式是自动提交</strong>。由<code>enable.auto.commit</code>控制，默认值为true.这个默认提交的含义是定时提交，定期的周期由客户端<code>auto.commit.interval.ms</code>配置，默认为5秒。自动位移提交的动作是在poll方法逻辑里完成的，在每次真正向服务端拉取请求之前会检查是否可以进行位移提交。</p>
</blockquote>
<blockquote>
<p>手动的位移提交方式可以让程序的逻辑在合适的地方进行位移提交。开启手动提交功能的前提时消费者客户端参数<code>enable.auto.commit</code>设置为false。手动提交分为同步提交(commitSync)和异步提交(commitAsync)。</p>
</blockquote>
<blockquote>
<p>可以在最后的时候通过同步提交进行提交位移把关。</p>
</blockquote>
<h3 id="控制或关闭消费"><a href="#控制或关闭消费" class="headerlink" title="控制或关闭消费"></a>控制或关闭消费</h3><blockquote>
<p>kafkaConsumer提供了对消费速度进行控制的方法，在有些应用场景我们可能需要暂停某些分区的消费而先消费其它分区，当达到一定条件时在恢复这些分区的消费。</p>
</blockquote>
<blockquote>
<p>kafkaConusumer中使用<code>pause</code>和<code>resume</code>方法来分别实现暂停某些分区在拉取操作时返回数据给客户端 和 恢复某些分区向客户端返回数据的操.kafkaConsumer提供了一个无参的<code>paused</code>方法来返回被暂停的分区集合。</p>
</blockquote>
<blockquote>
<p>可以通过调用kafkaConsumer的wakeup方法跳出消费者的poll逻辑，wakeup是kafkaConsumer中唯一可以从其它线程里安全调用的方法。调用wakeup方法后可以退出poll逻辑，并抛出wakeupException的异常。跳出循环以后一定要显式关闭动作以释放运行过程中占用的各种系统资源。</p>
</blockquote>
<h3 id="指定位移消费"><a href="#指定位移消费" class="headerlink" title="指定位移消费"></a>指定位移消费</h3><blockquote>
<p>在kafka中每当消费者找不到所记录的消费位移时，就会根据消费者客户端参数<code>auto.offset.reset</code>配置来决定从何处开始进行消费，默认为<code>latest</code>，表示从分区末尾开始消费。<code>earliest</code>表示消费者会从起始处开始消费。<code>none</code>意味着出现查不到消息位移时，会抛出异常。<br>    kafkaConsumer中的seek()方法正好提供了这个功能，让消费者具备回溯消费能力。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//指定位移消费</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">seek</span><span class="params">(TopicPartition partition, <span class="type">long</span> offset)</span>;</span><br><span class="line"><span class="comment">//获取分区的末尾偏移量</span></span><br><span class="line">Map&lt;TopicPartition, Long&gt; <span class="title function_">endOffsets</span><span class="params">(Collection&lt;TopicPartition&gt; topicPartitions)</span>;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>seek方法只能重置消费者分配到的分区的消费位置，而分区的分配实在poll()方法调用的过程中实现的。在执行seek()方法之前，需要先执行一次poll()方法，等到分配到分区之后才可以重置消费位置。</p>
</blockquote>
<blockquote>
<p>一个分区的其实位置起初是0，但并不代表每日每刻都是0，因为日志清理的动作会清理旧的数据，所以分区的起始位置会自然而然地增加。</p>
</blockquote>
<blockquote>
<p>kafkaConsumer提供一个offsetsForTimes()方法，通过timestamp来查询对应时间地分区位置。该方法会返回时间戳大于等于待查询时间地第一条消息对应地位置和时间戳,对应于offsetAndTimestamp地offset和timestamp字段。</p>
</blockquote>
<blockquote>
<p>位移越界会触发<code>auto.offset.reset</code>参数的执行，位移越界是指直到消费为止却无法在实际分区中查找到。</p>
</blockquote>
<h3 id="再均衡"><a href="#再均衡" class="headerlink" title="再均衡"></a>再均衡</h3><blockquote>
<p>再均衡是指分区的所属权从一个消费者转移到另一消费者的行为，它为消费组提供了<code>高可用性和伸缩性</code>提供保障。<strong>在均衡发生期间，消费组内的消费者是无法读取消息的。</strong> 另外当一个分区被重新分配给另一个消费者时，消费者当前的状态也会丢失。<strong>可能会出现重复消费的情况。分区原先所属的消费者没进行位移提交。</strong></p>
</blockquote>
<blockquote>
<p>再均衡器用来设定发生再均衡动作前后的一些准备或收尾的动作。ConsumerRebalanceListener包含两个方法</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> <span class="title function_">onPartitionsRevoked</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span></span><br><span class="line"><span class="comment">//再均衡开始之前和消费者停止读取消息之后。可以通过这个回调方法进行位移的提交避免再均衡之后重复消费</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">onPartitionAssigned</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span></span><br><span class="line"><span class="comment">//重新分配分区之后，消费者开始读取消费之前调用。partitions表示再均衡之后分配到的分区。</span></span><br></pre></td></tr></table></figure>
<h3 id="消费者拦截器"><a href="#消费者拦截器" class="headerlink" title="消费者拦截器"></a>消费者拦截器</h3><blockquote>
<p>消费者拦截器主要在消费到消息或者在提交位移时进行一些定制化的操作。<br>   消费者拦截器需要自定义实现ConsumerInterceptor接口，需要实现三个方法</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//poll方法返回之前调用，这个方法中抛出异常会被捕获记录到日志，不会向上传递</span></span><br><span class="line"><span class="keyword">public</span> ConsumerRecords&lt;K,V&gt; <span class="title function_">onConsumer</span><span class="params">(ConsumerRecords&lt;K,V&gt; records)</span>;</span><br><span class="line"><span class="comment">//再提交完消费位移之后调用。</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">OnCommit</span><span class="params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets)</span>;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span>;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>KafkaConsumer会在<strong>poll()方法返回之前调用拦截器的onConsumer()方法</strong>来对消息进行响应的定制化操作，比如修改返回的消息内容、按照某种规则过滤消息。如果onConsumer方法抛出异常，那么会被捕获并记录到日志，但是异常不会再向上传递。</p>
</blockquote>
<blockquote>
<p>使用ttl进行消费数据过滤，可能会提交错误的位移信息，含有最大偏移量的消息可能会被消费者拦截器过滤了。</p>
</blockquote>
<blockquote>
<p>消费者也存在拦截链的概念，按照interceptor.classes参数设置的拦截器的顺序一一执行的（配置的时候，各个拦截器之间使用逗号隔开）。需要注意的是如果拦截链中某个拦截器执行失败，那么下一个拦截器会接着从上一个执行成功的拦截器继续执行。</p>
</blockquote>
<blockquote>
<p><strong>kafkaProducer是线程安全的，然而KafkaConsumer是线程非安全的。</strong> kafkaConusmer中定义了一个acquire方法，用来检测当前是否只有一个线程再操作，若有其它线程正在操作则会抛出异常。</p>
</blockquote>
<blockquote>
<p>kafkaConsumer中每个公用方法在执行动作都会调用这个acquire方法，只有wackeup方法例外。acquire方法底层是通过原子类AtomicLong计数实现。</p>
</blockquote>
<h3 id="消费者重要参数"><a href="#消费者重要参数" class="headerlink" title="消费者重要参数"></a>消费者重要参数</h3><ul>
<li><p><code>fetch.min.bytes</code>:配置Consumer在一次拉取请求中能从kafka拉取的最小数据量，默认值为1（B）.kafka在收到Consumer的拉取请求时，如果返回给consumer小于这个参数所配置的值，那么它就需要进行等待，直到数据量满足这个参数的配置大小。<strong>调大这个参数能一定程度提高吞吐量，也会造成更大的延迟。</strong><br>-<code> fetch.max.bytes</code>:用来配置Consumer在一次拉取请求中从Kafka拉取的最大数据量，默认50MB.kafka能够接收最大消息的大小通过服务端参数message.max.bytes来设置。<br>如果这个参数设置的值比任何一条写入kafka的消息要小，那么会不会造成无法消费?</p>
<blockquote>
<p>该参数设定的不是绝对的最大值，如果在第一个非空分区中拉取的第一条消息大于该值，那么该消息将仍然返回，以确保消费者可以继续工作。</p>
</blockquote>
</li>
<li><p><code> fetch.max.wait.ms</code>:用来指定kafka的等待时间，默认500ms。如果kafka中没有足够多的消息而满足不了fetch.min.bytes参数的要求，那么最终会等待500ms。降低这个值可以相应降低延迟。</p>
</li>
<li><p><code>max.partition.fetch.bytes</code>: 用来配置从<strong>每个分区</strong>里返回给Consumer的最大数据量。默认1MB。</p>
</li>
<li><p><code>max.poll.records</code>: 用来配置Consumer在一次拉取请求中拉取的最大消息数，默认值为500条。如果消息的大小都比较小，可以适当调大这个参数值提升一定的消费速度。</p>
</li>
<li><p><code>connections.max.idle.ms</code>: 用来指定在多久之后关闭限制的连接。</p>
</li>
<li><p><code>exclude.internal.topics</code>: kafka内部有两个主题<code>__consumer_offsets</code>和<code>__transaction_state</code>。exclude.internal.topics用来指定kafka中的内部主题是否可以向消费者公开，默认为true。如果设置为true，那么只能使用subscribe(Collection)的方法不能使用subscribe(Pattern)的方式来订阅内部主题，设置为false则没有这个限制。</p>
</li>
<li><p><code>receive.buffer.bytes</code>: 用来限制Socket接收消息缓冲区的大小，默认为64KB，如果设置-1，则使用操作系统默认值。</p>
</li>
<li><p><code>send.buffer.bytes</code>:用来设置Socket发送消息缓冲区的大小，默认值为128KB.</p>
</li>
<li><p><code>request.timeout.ms:</code>等待请求的最大响应时间。默认30000</p>
</li>
<li><p><code>metadata.max.age.ms</code>:配置元数据的过期时间，默认5分钟。如果元数据在此参数所限定的时间范围内没有进行更新，则会被强制更新。即使没有任何分区变化或broker加入。</p>
</li>
<li><p><code>reconnect.backoff.ms</code>:配置尝试重新连接指定主机之前的等待时间，避免频繁地连接主机，默认值为50ms。这种机制适用于消费者向broker发送地所有请求。</p>
</li>
<li><p><code>retry.backoff.ms:</code>用来配置尝试重新发送失败地请求到指定地主题分区之前地等待（退避）时间,避免在某些故障情况下频繁地重复发送，默认值为100ms。</p>
</li>
<li><p><code>isolation.level</code>:配置消费者地事务隔离级别。字符串类型，有效值为”read_uncommitted”和”read_committed”,表示消费者所消费到的位置，如果设置为”read_committed”,那么消费者就会忽略事务未提交地消息，即只能消费到LSO地位置。默认为”read_uncommitted”，即可消费到HW。</p>
</li>
</ul>
<h2 id="主题和分区"><a href="#主题和分区" class="headerlink" title="主题和分区"></a>主题和分区</h2><blockquote>
<p>主题作为消息的归类，可以再细分为一个或多个分区，分区可以看作为对消息的二次归类。分区的划分不仅为kafka提供了<strong>可伸缩性、水平拓展的能力</strong>，还可以通过多副本机制来为kafka提供数据冗余以提高数据可靠性。<br>从kafka的底层实现来说，主题和分区都是逻辑上的概念，分区可以有一至多个副本，每个副本对应一个日志文件，每个日志文件对应一至多个日志分段，每个日志分段还可以细分为<code>索引文件</code>、<code>日志存储文件</code>和<code>快照文件</code>等。 </p>
</blockquote>
<h3 id="主题的管理"><a href="#主题的管理" class="headerlink" title="主题的管理"></a>主题的管理</h3><blockquote>
<p>主题管理包括创建主题、查看主题消息、修改主题和删除主题等。kafka-topiccs.sh脚本实际上是调用kafka.admin.TopicCommand类来执行主题管理的操作。</p>
</blockquote>
<blockquote>
<p>主题的管理并非只有使用kafka-topics脚本这一种方式，我们还可以通过kafkaAdminClient的方式实现（这种方式实际上是通过发送CreateTopicsRequest、DeleteTopicsRequest等请求实现的）。甚至可以通过直接操纵日志文件和Zookeeper节点实现。</p>
</blockquote>
<h4 id="创建主题"><a href="#创建主题" class="headerlink" title="创建主题"></a>创建主题</h4><blockquote>
<p>如果broker端配置参数<code>auto.create.topics.enable</code>设置为true,那么当生产者向一个尚未创建的主题发送消息时，会自动创建一个分区为<code>num.partitions</code>默认为1、副本因子为<code>default.replication.factor</code>默认值为1的主题。除此之外，当一个消费者开始从未知主题中读取消息，或者当任意一个客户端向未知主题发送元数据请求时，都会按照<code>num.partition</code>和<code>default.replication.faccctor</code>的值来创建一个相应的主题。<br>一般不建议将<code>auto.create.topics.enable</code>设置为true.</p>
</blockquote>
<blockquote>
<p><strong>同一个分区中的多个副本必须分布在不同的broker中，这样才能提供有效的数据冗余。</strong></p>
</blockquote>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9ddd14957dd64fb084e03de5be53a165~tplv-k3u1fbpfcp-watermark.image" alt="企业微信截图_1672020313991.png"></p>
<blockquote>
<p>kafka-topics.sh脚本中还提供了一个replica-assignment参数来手动指定分区副本的分配方案。可以省略partitions和replica-factor者两个参数。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6216390eff95457fb2551558ce48337c~tplv-k3u1fbpfcp-watermark.image" alt="企业微信截图_16720204587399.png"></p>
</blockquote>
<blockquote>
<p>kafka-topis.sh脚本在创建主题时会检测是否包含”.”或”_<em>“ 字符。因为kafka的内部做埋点时会根据主题的名称来命名Metric名称，并且将“.”改成下划线”</em>“。</p>
</blockquote>
<blockquote>
<p>主题命名规则：必须由大小写字母、数字、点号、连接线、下划线组成，不能为空，不能只有点号，也不能只有双点号，且长度不能超过249.</p>
</blockquote>
<blockquote>
<p>kafka从0.110.x版本开始<code>支持指定broker的机架信息</code>。如果指定了机架信息，则在分区副本分配时会尽可能地让分区副本分配到不同的机架上。指定机架信息是通过broker端参数<code>broker.rack</code>来配的。</p>
</blockquote>
<blockquote>
<p><code>broker.rack=RACK1</code>.当创建主题时如果broker中某些有机架配置某些不存在机架信息则会报错，可以使用<code>disable-rack-aware</code>参数来忽略机架信息对分区副本的分配影响.</p>
</blockquote>
<h4 id="分区副本的分配"><a href="#分区副本的分配" class="headerlink" title="分区副本的分配"></a>分区副本的分配</h4><blockquote>
<p>在创建主题时，如果使用了<code>replica-assignment</code>此参数，那么就按照指定的方案来进行分区副本的创建；如果没有使用replica-assignment参数，那么就需要按照内部的逻辑来计算分配方案了。按照机架信息划分成两种策略：未指定机架信息和指定机架信息。</p>
</blockquote>
<blockquote>
<p>创建主题时，实质上是在Zookeeper中的<code>/brokers/topics</code>节点上创建与该主题对应的子节点并写入分区副本分配方案，并且在<code>/config/topics/</code>节点下创建与该主题对应的子节点并写入主题相关的配置信息。<strong>kafka创建主题的实质性动作是交给控制器异步去完成的</strong>。</p>
</blockquote>
<h4 id="查看主题"><a href="#查看主题" class="headerlink" title="查看主题"></a>查看主题</h4><p>kafka-topics.sh脚本 有五种指令类型:create、list、describe、alter和delete。<br>使用describe可以添加参数:</p>
<ul>
<li><code>topic-with-overrides</code>:可以找出包含与集群不一致配置的主题。</li>
<li><code>under-replicated-partition</code>:可以找出所有包含失效副本的分区。</li>
<li><code>unavailable-partitions</code>:查看主题中没有leader副本的分区，这些分区已经处于离线状态。</li>
</ul>
<h4 id="修改主题"><a href="#修改主题" class="headerlink" title="修改主题"></a>修改主题</h4><blockquote>
<p>当一个主题被创建之后，仍然允许我们对其做一定的修改，比如修改分区个数、修改配置等。<code>kafka-topics.sh</code>脚本的alter指令提供。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --zookeeper localhost:2181 --alter --topic-config --partitions 3</span><br></pre></td></tr></table></figure>
<blockquote>
<p>修改分区个数时，当主题中的消息中key不为null，根据key计算分区的行为会收到影响。对于基于key计算的主题而言，建议在一开始就设置好分区数量，避免以后对其进行调整。目前kafka只支持增加分区数而不支持减少分区数。</p>
</blockquote>
<p>为什么不支持减少分区呢？</p>
<ul>
<li>删除分区后，分区中的消息该如何处理？</li>
<li>删除消息会导致消息的可靠性如何保证。</li>
<li>保留的话，需要考虑内部复制的成本，时间消息戳的处理，复制过程导致的可用性。</li>
</ul>
<p>可以使用alter修改主题的配置（过时）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// 修改配置</span><br><span class="line">bin/kafka-topics.sh --zookeeper localhost:2181 --alter -topic topic-config --config max.message.bytes=20000</span><br><span class="line">//删除配置</span><br><span class="line">bin/kafka-topics.sh --zookeeper localhost:2181 --alter -topic topic-config --delete-config max.message.bytes</span><br></pre></td></tr></table></figure>
<h4 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h4><blockquote>
<p>kafka-config.sh脚本是专门用来对配置进行操作的，指在运行状态下修改原有的配置，如此可以达到动态变更的目的。<br>  kafka-configs.sh不仅可以操作主题相关的配置，还可以支持操作broker、用户和客户端这3个类型的配置。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-configs.sh --zookeeper localhost:2181 --describe --entity-type topics --entity-name topic-config</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">entity-type指定查看配置的实体类型，entity-name指定操作的实体名称</span></span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/69af4b96f253485e8cf226f0337b3c36~tplv-k3u1fbpfcp-watermark.image" alt="企业微信截图_16720336912847.png"></p>
<blockquote>
<p>使用alter指令变更配置时，需要配合add-config和delete-config这两个参数一起使用。add-config用来实现配置的增、改。delete-config 实现配置删除，即删除被覆盖的配置以恢复默认值。</p>
</blockquote>
<blockquote>
<p>与主题相关的配置参数在broker层面都有对应参数。如果没有修改过主题的任何配置参乎，就会使用Broker端的作为默认值。</p>
</blockquote>
<h4 id="删除主题"><a href="#删除主题" class="headerlink" title="删除主题"></a>删除主题</h4><p>kafka-topics脚本中delete指令就可以用来删除主题。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/bin/kafka-topics.sh --zookeeper localhost:2181 --delete --topicc topic-delete</span><br></pre></td></tr></table></figure>
<p>主题是否删除和broker端配置参数<code>delete.topic.enable</code>有关。</p>
<p>使用kafka-topcis.sh脚本删除主题的行为本质上只是在zookeeper中的&#x2F;admin&#x2F;delete_topics路径上创建一个与待删除主题同名的节点，以此标记改主题为待删除状态。与创建主题相同的是，<strong>真正删除主题的动作也是由kafka的控制器负责实现。</strong></p>
<p>我们可以直接通过Zookeeper的客户端来删除主题。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create /admin/delete_topics/topic-delete</span><br></pre></td></tr></table></figure>
<blockquote>
<p>可以通过手动的方式删除主题，主题中的元数据存储在Zookeeper中&#x2F;brokers&#x2F;topics和&#x2F;config&#x2F;topics路径下，主题中的消息存储在log.dir或log.dirs配置路径下。</p>
</blockquote>
<p>zookeeper中删除主题topic-delete的步骤：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">deleteall /config/topics/topic-delete</span><br><span class="line">delete /brokers/topics/topic-delete  </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1 2 步骤可互换</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">删除集群中所有与主题topic-delete有关的文件,删除日志文件</span></span><br><span class="line">rm -rf /tmp/kafka-logs/topic-delete*</span><br></pre></td></tr></table></figure>
<h2 id="初识KafkaAdminClient"><a href="#初识KafkaAdminClient" class="headerlink" title="初识KafkaAdminClient"></a>初识KafkaAdminClient</h2><blockquote>
<p>如果我们希望将主题管理类的功能集成到公司的内部系统中，打造集管理、监控、运维、告警为一体的生态平台，那么就需要以程序调用API的方式去实现。KafkaAdminClient不仅可以用来管理broker、配置和ACL，还可以管理主题。</p>
</blockquote>
<h3 id="主题合法性验证"><a href="#主题合法性验证" class="headerlink" title="主题合法性验证"></a>主题合法性验证</h3><blockquote>
<p>一般情况下， kafka在生产环境下<code>auto.create.topics.enable</code>参数会被设置为false，自动创建主题会被禁止。</p>
</blockquote>
<blockquote>
<p>kafka-topics脚本创建的方式一般由运维人员使用kafkaAdminClient就为普通用户提供了一种方式去创建主题。<br>kafka broker端中一个参数<code>create.topic.policy.class.name</code>,默认为null，它提供一个入口用来验证主题创建的合法性。</p>
</blockquote>
<h2 id="分区的管理"><a href="#分区的管理" class="headerlink" title="分区的管理"></a>分区的管理</h2><h3 id="优先副本的选举"><a href="#优先副本的选举" class="headerlink" title="优先副本的选举"></a>优先副本的选举</h3><blockquote>
<p>分区使用多副本机制提升可靠性，但只有Leader副本对外提供读写服务，而follower只负责在内部进行消息的同步。<strong>同一个broker不可能出现一个分区的多个副本</strong>。某个分区的Leader不可用，就意味着整个分区不可用。</p>
</blockquote>
<blockquote>
<p>kafka主题创建之时，会默认将各个副本的leader、副本均匀分布到各个broker节点。但是如果出现故障转移，可能会造成leader副本在各broker上分配不均匀的状况。<strong>为了能够有效的治理负载失衡的概念，kafka引入优先副本。</strong></p>
</blockquote>
<blockquote>
<p>所谓的优先副本是指在 AR 集合列表中的第一个副本。比如主题 topic-partitions 中分区 0的AR集合列表（Replicas）为[1，2，0]，那么分区0的优先副本即为1。理想情况下，优先副本就是该分区的leader副本，所以也可以称之为preferred leader。理想情况下，<code>Kafka要确保所有主题的优先副本在Kafka集群中均匀分布</code>，这样就保证了所有分区的leader均衡分布。如果leader分布过于集中，就会造成集群负载不均衡。<code>优先副本的选举就是通过一定的方式促使优先副本选举成leader副本</code>，以此来促进集群的负载均衡。</p>
</blockquote>
<blockquote>
<p>分区平衡并不意味着kafka集群的负载均衡。</p>
</blockquote>
<blockquote>
<p>kafka可以提供<code>分区自动平衡</code>的功能，对应的broker端参数是<code>auto.leader.rebalance.enable</code>，默认为true。如果开启分区自动平衡功能，kafka的控制器会启动一个<code>定时任务</code>会轮询所有broker节点，计算每个broker节点的<code>分区不平衡率</code>(broker不平衡率 &#x3D; 非优先副本的leader个数&#x2F;分区总数)是否超过<code>leader.imbalance.per.broker.percentage</code>默认为10%。如果超过设定的比值则会自动执行优先副本的选举动作以求分区平衡。执行周期由参数<code>leader.imbalance.check.interval.seconds</code>控制，默认值为300秒，即5分钟。</p>
</blockquote>
<blockquote>
<p>不建议在生产环境将<code>auto.leader.rebalance.enable</code>设置为true,可能会造成负面的性能影响，也有可能引起客户端一定时间的阻塞。建议在合适的时候执行手动分区平衡。</p>
</blockquote>
<blockquote>
<p>kafka-perferred-replica-election.sh脚本提供对分区leader副本进行重新平衡的功能。优先副本选举的过程时是一个安全的过程。已经过时了，<code>kafka-leader-election.sh</code>代替了。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 使用示例</span><br><span class="line">kafka-preferred-replica-election.sh --zookeeper localhost:2182/kafka</span><br><span class="line">//最新</span><br><span class="line">kafka-leader-election.sh --bootstrap-server &lt;bootstrap-server&gt; --election-type preferred</span><br><span class="line"></span><br><span class="line">//可配合path-to-json-file参数来分批、手动执行指定主题分区优先副本选举</span><br></pre></td></tr></table></figure>
<blockquote>
<p>但是最好是手动执行优先副本选举。</p>
</blockquote>
<h3 id="分区重分配"><a href="#分区重分配" class="headerlink" title="分区重分配"></a>分区重分配</h3><blockquote>
<p>当集群中的一个节点突然宕机下线，这个节点上的所有分区副本都属于功能失效的状态，kafka并不会将这些失效的分区副本自动的迁移到集群中剩余的可用broker节点上，如果放任不管，不仅会影响这个集群的负载均衡，还会影响服务的可靠性和可用性。</p>
</blockquote>
<blockquote>
<p>当集群中新增broker节点时，只有新创建的主题分区才有可能被分配到这个节点上。而之前的主题分区并不会自动分配到新加入的节点中。</p>
</blockquote>
<blockquote>
<p><code>kafka-reassign-partitions.sh</code>脚本可以执行分区重分配的工作，它可以在集群扩容、broker节点失效的场景对分区进行迁移。</p>
</blockquote>
<p>kafka-reassign-partitions.sh脚本的使用步骤：</p>
<ul>
<li>创建一个包含主题清单的JSON文件。</li>
<li>根据主题清单和broker节点清单生成一个重分配的方案。</li>
<li>根据生成的方案执行具体的重分配动作。</li>
</ul>
<blockquote>
<p>分区重分配的基本原理是先通过控制器为每个分区添加新副本（增加副本因子），新的副本将从分区的leader副本那里复制所有的数据。复制完成之后，控制器将旧副本从副本清单里清除（恢复原先的副本因子数）。<code>重分配过程中要确保足够的空间</code>。</p>
</blockquote>
<blockquote>
<p>分区重分配对集群的性能有很大影响，需要占用额外的资源，网络和磁盘。在实际操作中，我们将降低重分配的力度，分成多个小批次来执行，以此来降低影响。如果需要将某个Broker下线，那么在执行分区重分配之前最好先关闭或重启，这样这个Broker就不再是任何分区的leader了。</p>
</blockquote>
<h3 id="复制限流"><a href="#复制限流" class="headerlink" title="复制限流"></a>复制限流</h3><blockquote>
<p><strong>数据复制会占用额外的资源，如果重分配的量太大必然会严重影响整体的性能</strong>，尤其是业务高峰期的时候。减小重分配的粒度，以小批次的方式来操作是一种可行的解决思路。如果某个分区的流量在某段时间非常大，减少粒度不足应对。可以<strong>对副本间复制流量加以限制</strong>保证重分配过程中整体服务不受影响。</p>
</blockquote>
<blockquote>
<p>副本间复制限流有两种实现方式:kafka-config.sh和kafka-reassign-partitions.sh脚本。</p>
</blockquote>
<blockquote>
<p>kafka-config.sh脚本主要以动态配置的方式来达到限流的目的，在broker级别有两个与复制限流相关的配置参数:<code>follower.replication.throttled.rate</code>和<code>leader.replication.throttled.rate</code>，前者用来设置follower副本复制的速度，后者用于设置leader副本传输的速度。单位为B&#x2F;S。<br>   在主题级别也有两个相关的参数来限制复制的速度:<code>leader.replication.throttled.replicas</code>和<code>follower.replication.throttled.replicas</code>分别用来设置被限制速度的主题所对应的leader副本列表和follower副本列表。<br>可以使用<code>kafka-reassign-partitions.sh</code>脚本配合throttle参数方式，可以在重分配之后自动删除复制限流的配置。</p>
</blockquote>
<blockquote>
<p>如果分区重分配会引起某个分期的AR集合变更，那么这个分区中与leader的有关限制会应用于重分配之前的所有副本，因为任何一个副本都可能是leader，而与follower有关的限制会应用于所有移动的目的地。</p>
</blockquote>
<h3 id="修改副本因子"><a href="#修改副本因子" class="headerlink" title="修改副本因子"></a>修改副本因子</h3><blockquote>
<p>创建主题之后可以修改分区个数，同样可以修改副本因子。修改副本因子的功能也是通过重分配所使用的<code>kafka-reassign-partition.sh</code>脚本实现。<strong>与分区不一样，副本数还可以减少。</strong></p>
</blockquote>
<h3 id="如何选择合适的分区数"><a href="#如何选择合适的分区数" class="headerlink" title="如何选择合适的分区数"></a>如何选择合适的分区数</h3><blockquote>
<p>在kafka中，性能和分区数有着必然的关系，在设定分区数时一般也需要考虑性能的因素。</p>
</blockquote>
<blockquote>
<p>kafka本身提供用于生产者性能测试的kafka-producer-perf.sh和用于消费者性能测试的kafka-consumer-perf-test.sh。</p>
</blockquote>
<blockquote>
<p>分区是Kafka中最小的并行操作单元，对生产者而言，每一个分区的数据写入是完全可以并行化的。对消费者而言，kafka只允许单个分区中的消息被一个消费者线程消费，一个消费组的并行消费完全依赖于分区数。</p>
</blockquote>
<blockquote>
<p>随着分区数增加，相应的吞吐量会增加，一旦分区数超过某个阈值之后，整体的吞吐量不升反降。</p>
</blockquote>
<blockquote>
<p>可以在创建主题时指定分区数为1，这样可以通过分区消费一致性达到主题消费一致性。</p>
</blockquote>
<h2 id="日志存储"><a href="#日志存储" class="headerlink" title="日志存储"></a>日志存储</h2><h3 id="文件目录布局"><a href="#文件目录布局" class="headerlink" title="文件目录布局"></a>文件目录布局</h3><blockquote>
<p>kafka中消息以主题为基本单位进行归类，各个主题在逻辑上相互独立。每个主题又可以分为一个或多个分区，分区的数量可以在主题创建的时候指定，也可以在之后进行修改。每条消息在发送的时候会根据分区规则被追加到指定的分区中，分区中每条消息会被分配一个唯一的序列号，也就是偏移量。</p>
</blockquote>
<blockquote>
<p>如果<strong>分区规则设置得合理，那么所有的消息可以均匀的分布在不同的分区中</strong>，这样就可以实现水平拓展。不考虑多副本的情况，一个分区对应一个日志，<code>为了防止Log过大，kafka又引入日志分段的概念</code>，将Log切分成多个LogSegment，相当于将一个巨型文件被平均分配为多个相对较小的文件，这样也便于消息的维护和清理。</p>
</blockquote>
<blockquote>
<p>Log在物理上只以文件夹的形式存储，而<code>LogSegment对应磁盘上的一个日志文件和两个索引文件</code>，以及可能的其他的文件（比如.txnindex为后缀的事务索引文件）。索引文件：偏移量索引文件、时间戳索引文件。</p>
</blockquote>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6312604de9ca4176a11949a6fa1b6fe3~tplv-k3u1fbpfcp-watermark.image" alt="_1675413511994.png"></p>
<blockquote>
<p>向Log中追加消息是<strong>顺序写入</strong>的，只<strong>有最后一个LogSegment才能执行写入操作，在此之前所有Segement都不能插入数据</strong>。为了便于消息的检索，每个LogSegement的日志文件都对应两个索引文件:<strong>偏移量索引文件</strong>(.index结尾)和<strong>时间戳索引文件</strong>(“.timeindex”为文件后缀)。每个LogSegment都有一个<strong>基准偏移量baseOffset</strong>,表示当前LogSegement中第一条消息的Offset。日志文件和两个索引文件都是根据基准偏移量命名的。</p>
</blockquote>
<p>v1版本的消息结构，新增了timestamp时间戳类型，同时atrributes字段的第四位，用来标志时间戳是消息创建时间还是日志记录时间。通过broker端参数<code>log.message.timestamp.type</code>进行配置。</p>
<h3 id="消息压缩"><a href="#消息压缩" class="headerlink" title="消息压缩"></a>消息压缩</h3><blockquote>
<p>常见的压缩算法是数据量越大压缩效果越好。<strong>kafka实现的压缩方式是将多条消息一起进行压缩，这样就可以保证较好的压缩效果</strong>。在一般情况下，生产者发送的压缩数据在broker中也是保持压缩状态进行存储的，消费者从服务端获取的也是压缩信息，消费者在处理消息之前才会解压消息，这样保证了端对端的压缩。</p>
</blockquote>
<blockquote>
<p>kafka日志使用哪种压缩方式是通过<code>compression.type</code>来配置的，默认值为producer，表示保留生产者使用的压缩方式。压缩率是压缩后的大小与压缩之前对比。压缩率越小越好。</p>
</blockquote>
<h3 id="日志索引"><a href="#日志索引" class="headerlink" title="日志索引"></a>日志索引</h3><blockquote>
<p>日志分段文件对应两个索引文件，主要用来提高查找消息的效率。<strong>偏移量索引文件用来建立消息偏移量(offset)到物理地址之间的映射关系</strong>，方便快速定位消息所在的物理文件位置；<strong>时间戳索引文件则根据指定的时间戳来查找对应的偏移量信息</strong>。</p>
</blockquote>
<blockquote>
<p>kafka中的索引文件以<code>稀疏索引</code>的方式构造消息的索引，并不保证每个消息在索引文件中都有对应的索引项。每当写入一定量(<code>log.index.interval.bytes</code>指定)的消息时，偏移量索引文件和时间戳索引文件分别增加一个偏移量索引项和时间戳索引项。</p>
</blockquote>
<blockquote>
<p><strong>稀疏索引通过MappedByteBuffer将索引文件映射到内存中</strong>，以加快索引的查询速度。</p>
</blockquote>
<blockquote>
<p>偏移量索引文件中偏移量是<code>单调递增</code>的，查询指定偏移量使用二分查找法快速定位偏移量的位置，如果指定的偏移量不在索引文件中，则会返回小于指定偏移量的最大偏移量,要找到对应的物理文件位置还需要根据偏移量索引文件进行再次定位。</p>
</blockquote>
<blockquote>
<p>时间戳索引文件中时间戳也是保持严格递增的，查询指定时间戳时，也会根据二分查找来查找不大于该时间戳的最大偏移量，如果要找到对应的物理文件位置还需要根据偏移量索引文件来进行再次定位。</p>
</blockquote>
<p>日志分段文件切分包含以下几个条件，满足一个即可：</p>
<ul>
<li>当前日志分段文件大小超过broker端参数<code>log.segment.bytes</code>配置值.</li>
<li>当前日志分段中消息的最大时间戳与当前系统的时间戳的差值大于<code>log.roll.ms</code>或<code>log.roll.hour</code>参数配置的值log.roll.ms的优先级高。</li>
<li>偏移量索引文件或时间戳索引文件的大小达到broker端参数<code>log.index.size.max.byte</code>s配置的值。</li>
<li>追加的消息偏移量与当前日志分段的偏移量之间的差值大于<code>Integer.MAX_VAULE.</code>，即要追加的消息偏移量不能转化为相对偏移量。</li>
</ul>
<blockquote>
<p>对于非活跃日志分段，其对应的索引文件内容已经固定，索引被设定为<code>只读</code>。kafka在创建索引的时候会为其预分配<code>log.index.size.max.bytes</code>大小的空间，只有当索引文件进行切分的时候，kafka会把索引文件裁剪到实际的数据大小。也就代表着当前活跃的日志分段对应的索引文件大小固定为<code>log.index.size.max.bytes</code>,其余日志分段对应的索引文件为实际占用的空间。</p>
</blockquote>
<h4 id="偏移量索引"><a href="#偏移量索引" class="headerlink" title="偏移量索引"></a>偏移量索引</h4><p>每个索引项占用8个字节，分为两个部分：</p>
<ul>
<li>relativeOffset:相对偏移量，表示消息相对于baseOffset的偏移量，占用4个字节。</li>
<li>position：物理地址，消息在日志分段文件中对应的物理地址。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/67559291e963465da55a73e2fe442179~tplv-k3u1fbpfcp-watermark.image" alt="偏移量索引.png"></li>
</ul>
<blockquote>
<p>索引项中没有直接使用绝对偏移量而改为只占用4个字节的相对偏移量，这样可以减小索引文件占用的空间。如何确定查找的日志分段呢？kafka使用跳跃表结构，Kafka 的每个日志对象中使用了<code>ConcurrentSkipListMap</code>来保存各个日志分段，每个日志分段的baseOffset作为key，这样可以根据指定偏移量来快速定位到消息所在的日志分段。</p>
</blockquote>
<blockquote>
<p>kafka中要求索引大小文件必须是索引项大小的整数倍，对于偏移量索引文件而言，必须为8的整数倍。</p>
</blockquote>
<h4 id="时间戳索引"><a href="#时间戳索引" class="headerlink" title="时间戳索引"></a>时间戳索引</h4><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d77c71ae8bf94eedb04eaaeef3c285e6~tplv-k3u1fbpfcp-watermark.image" alt="时间戳索引.png"><br>每个索引项占12个字节</p>
<ul>
<li>timestamp:当前日志分段的最大时间戳。</li>
<li>relativeoffset:时间戳所对应的消息的相对偏移量。</li>
</ul>
<blockquote>
<p>时间戳索引文件中包含若干时间戳索引项，每个追加的时间戳索引项中的timestamp必须大于之前追加的索引项的timestamp，否则不予追加。如果broker端参数<code>log.message.timestamp.type</code>设置为CreateTime则无法保证递增,生产者可以指定时间戳的值，不同时钟问题可能会导致时间戳无法单调递增。</p>
</blockquote>
<blockquote>
<p>时间戳索引文件大小必须是索引项（12B）的整数倍。如果<code>log.index.size.max.bytes</code>不满足，kafka默认会进行转换。</p>
</blockquote>
<blockquote>
<p>每当写入一定量的消息，就会在偏移量索引和时间戳索引文件中分别增加一个偏移量索引项和时间戳索引项。两个文件增加索引项是同时进行的但不意味着偏移量索引中的相对偏移量和时间戳索引中的相对偏移量是一个值。</p>
</blockquote>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/94f32f4df14742c182495b08070c1b4f~tplv-k3u1fbpfcp-watermark.image" alt="时间戳索引示意图.png"></p>
<h3 id="日志清理"><a href="#日志清理" class="headerlink" title="日志清理"></a>日志清理</h3><blockquote>
<p>kafka将消息存储在磁盘中，为了控制磁盘占用空间的不断增加就需要对消息做一个定时清理。kafka每一个分区对应一个Log，而Log又分为多个日志分段，便于日志清理操作。</p>
</blockquote>
<p>kafka提供了两个日志清理策略：</p>
<ul>
<li>日志删除：按照一定的保留策略直接删除不符合条件的日志分段。</li>
<li>日志压缩：针对每个消息的key进行整合，对于有相同key的不同value值，<code>只保留最后一个版本</code>。</li>
</ul>
<blockquote>
<p>通过broker端参数<code>log.cleanup.policy</code>来设置日志清理策略，此参数的默认值为delete。compact是压缩同时还需要<code>log.clean,enable</code>设置为true。可以通过将log.cleanup.policy参数设置为<code>delete,compact</code>还可以同时支持日志删除和日志策略两种策略。<strong>日志清理的粒度可以控制到主题级别。</strong></p>
</blockquote>
<h4 id="日志删除"><a href="#日志删除" class="headerlink" title="日志删除"></a>日志删除</h4><blockquote>
<p>kafka的日志管理器中会有一个<strong>专门的日志删除任务</strong>来周期性地检测和删除不符合保留条件地日志分段文件。周期通过<code>log.retention.check.interval.ms</code>来进行设置。</p>
</blockquote>
<p>保留策略：</p>
<ul>
<li>基于时间：日志删除会检查当前日志文件是否有保留时间超过设置阈值来寻找可删除日志分段文件集合。通过broker端<code>log.retention.hours</code>进行设置。超过阈值会对过期地日志段和索引文件进行delete标记，然后由延迟删除任务来进行执行。通过时间戳索引进行查找。若该日志所有日志分段都过期，必须保证有一个活跃的日志分段，会先切分出一个新的日志分段。</li>
<li>基于日志大小：日志删除任务会检查当前日志的大小是否超过设定阈值来寻找可删除的日志分段的文件集合。阈值通过broker段参数<code>log.retention.bytes</code>来配置整个Log所有日志文件大小，默认值为-1，表示无穷大。单个日志文件大小由<code>log.segment.bytes</code>来设置。</li>
<li>基于日志起始偏移量：某日志分段的下一个日志分段的起始偏移量baseoffset是否小于等于logStartOffset，若是则可以删除此日志分段。</li>
</ul>
<blockquote>
<p>一般情况下，日志文件的其实偏移量logStartOffset等于第一个日志分段的baseOffset,但不是绝对的。logStartOffset的值可以通过DeleteRecordsRequest请求、日志的清理和截断等操作进行修改。</p>
</blockquote>
<blockquote>
<p>删除日志分段时，首先会从Log对象中所维护的日志分段跳跃表中移除待删除的日志分段，保证没有线程对这些日志分段进行读取，然后将日志分段所对应的所有文件添加.deleted后缀。最后交给一个以<code>delete-file</code>命名的延迟任务删除这些文件，延迟任务执行时间可以使用<code>file.delete.delay.ms</code>参数调配。</p>
</blockquote>
<h4 id="日志压缩"><a href="#日志压缩" class="headerlink" title="日志压缩"></a>日志压缩</h4><blockquote>
<p>Log Compaction对于由相同key的不同value值，只保留最后一个版本。如果应用只关心key对应的最新value值，则可以开启kafka的日志清理功能，kafka会定期将相同key的消息进行合并，只保留最新的value。</p>
</blockquote>
<blockquote>
<p>Log Compaction执行前后，<code>日志分段中的每条消息的偏移量和写入时的偏移量保持一致</code>。Log Compaction会生成新的日志分段文件，日志分段中每条消息的物理位置会重新按照新文件来组织。<code>Log Compaction执行过后的偏移量不再是连续的</code>，不过这并不影响日志的查询。</p>
</blockquote>
<blockquote>
<p>在log.dir或log.dirs参数设置的kafka日志存放目录，每一个日志目录下都有一个<code>cleaner-offset-checkpoint</code>文件，这个文件就是清理检查点文件，用来<code>记录每个主题的每个分区已清理的偏移量</code>，通过清理检查点文件可以将Log分为已经清理的clean部分和未清理的dirty部分。<br>在日志清理的同时，客户端也可以读取日志中的消息。dirty部分的消息时逐一增加的而clean部分的消息偏移量是断续的，如果客户端总能赶上dirty部分，就能读取到日志的所有信息。</p>
</blockquote>
<blockquote>
<p>activeSegment不会参与Log Compaction的执行。Kafka 支持通过参数<code>log.cleaner.min.compaction.lag.ms</code>来配置消息在被清理前的最小保留时间。</p>
</blockquote>
<blockquote>
<p>Log Compaction是针对key的，所以使用时应注意每个消息的key值不为null。每个broker会启动<code>Log.cleaner.thread</code>个日志清理线程负责执行清理任务，这些线程会优先选择污浊率最高的日志文件进行清理。为了防止日志不必要的频繁清理操作，kafka使用<code>log.cleaner.min.cleanable.ratio</code>来限定可进行清理操作的最小污浊率。</p>
</blockquote>
<blockquote>
<p>kafka中用于保存消费者消费唯一的主题_consumer_offsets使用的就是Log Compaction策略。</p>
</blockquote>
<blockquote>
<p>Kafka中的每个日志清理线程会使用一个名为“SkimpyOffsetMap”的对象来构建 key与offset 的映射关系的哈希表。日志清理需要<code>遍历两次日志文件</code>，第一次遍历把每个key的哈希值和最后出现的offset都保存在SkimpyOffsetMap中，第二次遍历会检查每个消息是否符合保留条件，如果符合就保留下来，否则就会被清理。</p>
</blockquote>
<blockquote>
<p>log compaction会保留key相应的最新value值，那么当需要删除一个key时，kafka提供一个墓碑消息（key不为null，value为null）。</p>
</blockquote>
<blockquote>
<p>日志清理线程发现墓碑消息会先进性常规的清理，并把保留墓碑消息一段时间。墓碑消息的保留条件是当前墓碑消息所在的日志分段的最近修改时间lastModifiedTime大于deleteHorizonMs。通过 broker 端参数<code>log.cleaner.delete.retention.ms</code>配置。</p>
</blockquote>
<blockquote>
<p>Log Compaction执行过后的日志分段的大小会比原先的日志分段要小。为了防止出现大量小文件，kafka在实际清理过程中并不会对单个日志分段进行单独清理，而是对多个文件分组，减少生成的日志分段。</p>
</blockquote>
<h3 id="磁盘存储"><a href="#磁盘存储" class="headerlink" title="磁盘存储"></a>磁盘存储</h3><blockquote>
<p>kafka依赖文件系统（磁盘）来存储和缓存消息.事实上磁盘可能比我们预想的要快，也可能比我们预想的要慢，这完全取决于我们如何使用它。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ef0f608ff4724361b94e3373d465e237~tplv-k3u1fbpfcp-watermark.image" alt="各个存储介质的速度层级.png"></p>
</blockquote>
<blockquote>
<p>操作系统针对线性读写做了深层次的优化，比如预读（提前将一个比较大的磁盘块读入内存）和后写（将很多小的逻辑写操作合并成一个大的物理写操作）技术。<strong>顺序写盘的速度不仅比随机写盘的速度快，而且也比随机写内存的速度快。</strong></p>
</blockquote>
<blockquote>
<p>kafka在设计时采用了文件追加的方式来写入消息，属于典型的顺序写盘的操作。但这并不是kafka在性能具备足够竞争力的唯一因素。</p>
</blockquote>
<h4 id="页缓存"><a href="#页缓存" class="headerlink" title="页缓存"></a>页缓存</h4><blockquote>
<p>操作系统实现的一种主要磁盘缓存，以此用来减少对磁盘I&#x2F;O的操作。把磁盘中的数据缓存到内存中，把对磁盘的访问变为对内存的访问。</p>
</blockquote>
<blockquote>
<p>kafka中大量使用页缓存，这是kafka实现高吞吐的重要因素之一。虽然消息都是先被写入页缓存，然后由操作系统负责具体的刷盘任务的。但是kafka中同样提供了同步刷盘及间接性强制刷盘的功能，这些功能可以通过<code>log.flush.interval.message</code>、<code>log.flush.interval.ms</code>等参数进行控制。同步刷盘可以保证消息的可靠性，但不建议通过这种方式，刷盘任务应该交由操作系统去调配，消息的可靠性应交给多副本机制来实现，同步刷盘太消耗性能。</p>
</blockquote>
<blockquote>
<p>Linux系统会使用磁盘的一部分作为swap分区，这样就可以进行进程的调度：把非活跃的进程调入swap分区，以此把内存空出来让给活跃的进程。对大量使用系统页缓存的kafka而言，应该尽量避免这种内存交换。可以通过修改linux系统<code>vm.swappindess</code>参数来进行调节。</p>
</blockquote>
<h4 id="磁盘I-O流程"><a href="#磁盘I-O流程" class="headerlink" title="磁盘I&#x2F;O流程"></a>磁盘I&#x2F;O流程</h4><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e4f4c6981777486e866d5349bfc447b6~tplv-k3u1fbpfcp-watermark.image" alt="磁盘I/O流程.png"><br>一般磁盘I&#x2F;O的场景由以下四种：</p>
<ul>
<li>用户调用标准C库进行I&#x2F;O操作，数据流为：应用程序buffer-&gt;C库标准IObuffer-&gt;文件系统缓存页—&gt;通过具体文件系统到磁盘。</li>
<li>用户调用文件I&#x2F;O，数据流为：应用程序buffer-&gt;文件系统页缓存-&gt;通过具体文件系统到磁盘。</li>
<li>用户打开文件时使用O_DIRECT,绕过页缓存直接读写磁盘。</li>
<li>用户使用类似dd工具，并使用direct参数，绕过系统cache与文件系统直接写磁盘。</li>
</ul>
<blockquote>
<p>IO请求处理：通用块层根据I&#x2F;O请求构造一个或多个bio结构并提交给调度层。调度器将bio结构进行排序和合并成队列且确保读写操作即可能理想：将一个或多个进程的读操作合并到一起读，将一个或多个进程的写操作合并到一起写，即可能变随机为顺序，读必须优先满足，写也不能等太久。</p>
</blockquote>
<p>选择具备不同io调度策略的I&#x2F;O调度器也会影响kafka的写入性能。<br>Linux系统中IO调度策略：</p>
<h5 id="NOOP"><a href="#NOOP" class="headerlink" title="NOOP"></a>NOOP</h5><blockquote>
<p>该算法实现了最简单的FIFO队列，所有I&#x2F;O请求大致按照先来后到的顺序进行操作通过会在FIFO的基础上做相邻I&#x2F;O请求的合并，并不完全按照先进先出规则。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">//IO请求顺序</span><br><span class="line">100 500 101 10 56 1000</span><br><span class="line">//NOOP排序顺序</span><br><span class="line">100(101) 500 10 56 1000</span><br></pre></td></tr></table></figure>

<h5 id="CFQ"><a href="#CFQ" class="headerlink" title="CFQ"></a>CFQ</h5><blockquote>
<p>按照I&#x2F;O请求地址进行排序，而不是先来后到的顺序进行相应。</p>
</blockquote>
<blockquote>
<p>CFQ是默认磁盘调度算法。试图均匀的分布对I&#x2F;O带宽的访问。CFQ为每个进程单独创建一个队列来管理该进程所产生的请求，各个队列之间使用时间片进行调度，I&#x2F;O调度器每次执行一个进程的4次请求。CFQ出发点是尽量少的磁盘旋转来满足尽可能多的I&#x2F;O请求去。相比于NOOP的缺点是，先来的I&#x2F;O请求并不一定能被满足，可能会出现IO饿死情况。</p>
</blockquote>
<h5 id="DEADLINE"><a href="#DEADLINE" class="headerlink" title="DEADLINE"></a>DEADLINE</h5><blockquote>
<p>DEADLINE在CFQ的基础上，解决了I&#x2F;O请求饿死的极端情况。除了CFQ本身的I&#x2F;O排序队列，额外分为读I&#x2F;O和写I&#x2F;O提供了FIFO队列，读IO队列的最大等待时间为500ms,写FIFO的最大等待时间为5s。FIFO队列中的I&#x2F;O请i去优先级比CFQ队列中的高，读优先级高于写优先级。 </p>
</blockquote>
<h5 id="ANTICIPATORY"><a href="#ANTICIPATORY" class="headerlink" title="ANTICIPATORY"></a>ANTICIPATORY</h5><blockquote>
<p>CFQ和DEADLINE考虑的满足零散I&#x2F;O请求上。对于连续的I&#x2F;O请求并没有做优化。ANTICIPATORY在DEADLINE的基础上，为每个读I&#x2F;O都设置了6ms的等待时间窗口，如果6ms内OS收到相邻位置的读I&#x2F;O请求，就可以立即满足。将多个随机的小写入流合并成一个大的写入流。</p>
</blockquote>
<h4 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h4><blockquote>
<p>kafka还使用零拷贝技术来进一步提升性能。零拷贝就是将数据从磁盘文件复制到网卡设备中，而不需要经由应用程序之手。零拷贝大大提高了应用程序的性能，减少了内核和用户模式之间的上下文切换。对应linux系统的sendfile()方法。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/23775022b3ad4719b3bda7a58c5de14e~tplv-k3u1fbpfcp-watermark.image" alt="企业微信截图_16757564096081.png"></p>
</blockquote>
<p>不适用零拷贝一个文件发送的步骤：</p>
<ul>
<li>读取文件内容复制到内核模式的Read Buffer。</li>
<li>CPU控制将内核模式的数据复制到用户模式下</li>
<li>将用户模式下的数据复制到内核模式下的Socket Buffer。</li>
<li>将内核模式下的Socket Buffer的数据复制到网卡设备中传送。</li>
</ul>
<blockquote>
<p>零拷贝技术通过<code>DMA技术</code>将文件内容复制到内核模式下的Read Buffer。不过没有复制到Socket Buffer，相反只有包含数据的位置和长度的信息描述符被加到Socket Buffer。DMA引擎直接将数据从内核模式中传递到网卡设备（协议引擎）。这里数据只经历两次复制就从磁盘中传送出去了，并且上下文切换也变为两次。零拷贝是针对内核模式而言的，数据在内核模式下实现了零拷贝。</p>
</blockquote>
<h2 id="深入服务端"><a href="#深入服务端" class="headerlink" title="深入服务端"></a>深入服务端</h2><h3 id="协议设计"><a href="#协议设计" class="headerlink" title="协议设计"></a>协议设计</h3><blockquote>
<p>kafka经常被用作高性能、可拓展的消息中间件。kafka自定义了一组基于<strong>TCP的二进制协议</strong>，只要遵守这组协议的格式，就可以向kafka发送消息，也可以从kafka中拉取消息，或者比如提交消费位移等操作。</p>
</blockquote>
<blockquote>
<p>每种类型的请求都包含相同结构的协议请求头和不同结构的请求体。</p>
</blockquote>
<p>协议请求头中包含：</p>
<ul>
<li>api_key:API标识，比如PRODUCE代表发送消息。</li>
<li>api_version:API版本号</li>
<li>correlation_id:客户指定一个数字来唯一标识这次请求的id，服务端处理完请求后也会把这个id通过response返回给客户端，客户端通过这个能把请求和相应对应起来。</li>
<li>client_id：客户端id。<br>协议响应头：</li>
<li>correlation_id：和请求头中的相对应。</li>
</ul>
<h3 id="时间轮"><a href="#时间轮" class="headerlink" title="时间轮"></a>时间轮</h3><blockquote>
<p> kafka中存在大量延时操作，如延迟生产、延时拉取和延时删除。<strong>kafka使用基于时间轮的概念自定义了一个用于延时功能的定时器</strong>。 基于时间轮可以<strong>将插入和删除操作的时间复杂度都降为O(1)</strong></p>
</blockquote>
<blockquote>
<p>Kafka中的时间轮（TimingWheel）是一个<strong>存储定时任务的环形队列</strong>，底层采用数组实现，数组中的每个元素可以存放一个<strong>定时任务列表</strong>（TimerTaskList）。TimerTaskList是一个环形的双向链表，链表中的每一项表示的都是定时任务项（TimerTaskEntry），其中封装了真正的定时任务（TimerTask）。</p>
</blockquote>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f1dbac0e66e54a64ba7b75a46b8be222~tplv-k3u1fbpfcp-watermark.image" alt="企业微信截图_16763601337516.png"></p>
<blockquote>
<p>时间轮由多个时间格组成，每个时间格代表当前时间轮的基本时间跨度（tickMs）。时间轮的<strong>时间格个数是固定的</strong>，用wheelSize表示。整个事件轮的总体事件跨度通过tickMs x wheelSize计算得出。时间轮由一个表盘指针，用来表示当前时间轮当前所处的时间，currentTime是tickMs的整数倍。currentTime可以将整个时间轮划分为过期部分和未到期过程。到期意味着需要处理此时间格对应的TimerTaskList中的所有任务。</p>
</blockquote>
<blockquote>
<p>层次时间轮，当任务的到期时间超过当前时间轮所表示的时间范围时，就会尝试添加到上层时间轮。上一层时间轮的tickMs &#x3D; 当前层tickMs * wheelSize。<br><strong>层级时间轮</strong>解决单层时间轮延迟时间优先的问题，上一层的tickMs是下一层的interval（总时间跨度）。<strong>时间轮升级和降级</strong>。</p>
</blockquote>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://gitee.com/yangxiao2000/md_img/raw/master/images/20231005014454.png" alt="1696441457459.png"></p>
<p>kafka实现时间轮的小细节</p>
<ul>
<li>TimingWheel中每个双向环形链表都会有一个哨兵节点。用来简化边界条件。</li>
<li>kaka中定时器只需要持有TimingWheel的第一层时间轮引用，每一层时间轮都会有一个引用指向更高一层的一个用。<blockquote>
<p>kafka使用JDK的DelayQueue来协助推进时间轮，DelayQueue会根据TimerTaskList对应的超时时间expiration来排序，最短expiration的TimerTaskList会被排在DelayQueue的队头。</p>
</blockquote>
</li>
</ul>
<h3 id="延时操作"><a href="#延时操作" class="headerlink" title="延时操作"></a>延时操作</h3><blockquote>
<p>如果在使用生产者客户端发送消息的时候将acks参数设置为-1，那么就意味着需要等待ISR集合中的所有副本都确认收到消息之后才能正确收到相应消息，或者捕获超时异常。</p>
</blockquote>
<blockquote>
<p>在将消息写入leader副本的本地日志之后，kafka会创建一个延时的生产操作，用来处理消息正常写入所有副本或超时的情况，以返回相应的响应结果给客户端。</p>
</blockquote>
<h3 id="控制器"><a href="#控制器" class="headerlink" title="控制器"></a>控制器</h3><blockquote>
<p>kafka集群中会有一个或多个broker,其中有一个broker会被选举为<strong>控制器</strong>，<strong>它负责管理整个集群中所有分区和副本的状态。</strong> 某个分区leader副本出现故障、某个分区的ISR集合发生变化（控制器负责通知所有broker更新其元信息）、增加分区数量（控制分区分配），</p>
</blockquote>
<h4 id="控制器的选举及异常恢复"><a href="#控制器的选举及异常恢复" class="headerlink" title="控制器的选举及异常恢复"></a>控制器的选举及异常恢复</h4><blockquote>
<p>kafka的控制器选举工作依赖于Zookeeper，成功竞选为控制器的broker会在Zookeeper中创建&#x2F;controller这个临时节点。在任意时刻，集群中有且仅有一个控制器。每个broker启动的时候会去尝试读取<code>/controller</code>节点的brokerid的值，如果不为-1，则放弃竞选。否则尝试去尝试创建这个节点。<strong>每个broker都会在内存中保存当前控制器的brokerid值。</strong></p>
</blockquote>
<blockquote>
<p>Zookeeper中有个<code>/controller_epoch</code>节点，这个节点是持久节点，节点中存放一个整型的controller_epoch值，<code>代表控制器发生变更的次数</code>。每个和控制器交互的请求都会携带controler_epoch这个字段，判断消息是不是无效请求。<strong>通过controller_epoch的值进行比较，来保证控制器的唯一性。</strong></p>
</blockquote>
<p>控制器身份的broker需要承担更多的职责: </p>
<ul>
<li>监听分区相关的变化。为Zookeeper的&#x2F;admin&#x2F;ressign_partitions节点注册PartitionReassignmentHandler，用来处理分区重分配的工作。为Zookeeper中的&#x2F;isr_change_notification节点注册IsrChangeNotificationHandler，用来处理ISR集合变更的动作。为Zookeeper中的&#x2F;admin&#x2F;preferred-replica-election节点添加PreferredReplicaElectionHandler,用来处理优先副本的选举动作。</li>
<li>监听主题相关的变化。为zookeeper中的brokers&#x2F;topics节点添加TopicChangeHandler，用来处理主题增减变化；为Zookeeper中的&#x2F;admin&#x2F;delete_topics节点添加TopicDeletionHandler，用来处理删除主题的动作。</li>
<li>监听broker的变化。为Zookeeper中的&#x2F;broker&#x2F;ids节点添加BrokerChangeHandler，用来处理broker增减的变化。</li>
<li>从Zookeeper中获取当前所有与主题、分区及broker有关消息并进行相应的管理。对所有主题对应的&#x2F;brokers&#x2F;topics&#x2F;topic添加PartitionModificationsHandler，用来监听主题中分区分配变化。</li>
<li>启动并管理分区状态机和副本状态机。</li>
<li>更新集群的元数据信息。</li>
<li>如果参数auto.leader.rebalance.enable设置为true,则会开启一个名为auto-leader-rebalance-task的定时任务来维护分区的优先副本的均衡。</li>
</ul>
<blockquote>
<p>控制器在选举成功之后会 读取Zookeeper中各个节点的数据来初始化上下文信息，并且管理这些上下文信息。</p>
</blockquote>
<blockquote>
<p>kafka的controller处理监听的事件采用单线程基于事件队列的模型。将每个事件都做一层封装，然后按照事件发生的先后顺序暂存到LinkedBlockingQueue中，最后使用一个专用的线程按照FIFO的原则顺序处理各个事件，在多线程间维护线程安全。</p>
</blockquote>
<blockquote>
<p>在kafka的早期版本，并没有采用controller这样的概念来对分区和副本的状态进行管理，而是依赖于zookeeper,每个broker都会在Zookeeper上为分区和副本注册大量的监听器。会唤醒很多不必要的监听器。现在除controller之后只需要鉴定&#x2F;controller，以此监听此节点的数据变化(ControllerChangeHandler).</p>
</blockquote>
<p>关闭过程<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/600f8a21dc4d471895a69209c1dde2cc~tplv-k3u1fbpfcp-watermark.image" alt="controlledShutdown的过程.png"></p>
<h4 id="分区leader的选举"><a href="#分区leader的选举" class="headerlink" title="分区leader的选举"></a>分区leader的选举</h4><blockquote>
<p>分区leader副本的选举由控制器负责具体实施。当创建分区（创建主题或增加分区）或分区上线（分区中原先的leader副本下线）的时候都需要执行leader的选举动作，对应的策略为OfflinePartitionLeaderElectionStrategy.这种策略的基本思路是<strong>按照AR集合中副本的顺序查找第一个存活的副本，并且这个副本在ISR集合中</strong>。如果ISR集合中没有可用副本，那么还要检查以下所配置<code>unclean.leader.election.enable</code>是否为true，为true会从AR集合中找到第一个存活的副本作为leader。</p>
</blockquote>
<blockquote>
<p>当分区进行重分配的时候也需要执行leader选举动作，对应的选举策略为<code>ReassignPartitionLeaderElectionStrategy</code>。选举思路：从重分配的AR列表找到第一个存活的副本，且这个副本在目前ISR列表。</p>
</blockquote>
<blockquote>
<p>当发生优先副本的选举时，直接将优先副本设置为leader即可，AR集合中第一个副本即为优先副本。</p>
</blockquote>
<blockquote>
<p>还有一种情况会发生 leader 的选举，当某节点被优雅地关闭（也就是执行ControlledShutdown）时，位于这个节点上的leader副本都会下线，所以与此对应的分区需要执行leader的选举。与此对应的选举策略（ControlledShutdownPartitionLeaderElectionStrategy）为：从AR列表中找到第一个存活的副本，且这个副本在目前的ISR列表中，与此同时还要确保这个副本不处于正在被关闭的节点上。</p>
</blockquote>
<h3 id="参数含义"><a href="#参数含义" class="headerlink" title="参数含义"></a>参数含义</h3><ul>
<li>auto.create.topics.enable: 自动创建主题功能</li>
<li>auto.leader.rebalance,enable:  自动leader在均衡功能</li>
<li>background,threads : 后台任务的线程数</li>
<li>compression.type: 消息的压缩类型</li>
<li>delete.topic.enable: 是否可以删除主题</li>
<li>leader.imbalance.check.interval.seconds: 检查leader是否分布不均衡的周期</li>
<li>leader.imbalance.per.broker.percentage: 允许leader不均衡的比例，超过就会触发在均衡。</li>
</ul>
<h2 id="kafka客户端"><a href="#kafka客户端" class="headerlink" title="kafka客户端"></a>kafka客户端</h2><h3 id="分配分区策略"><a href="#分配分区策略" class="headerlink" title="分配分区策略"></a>分配分区策略</h3><blockquote>
<p>kafka中提供了消费者客户端参数<code>partition.assignment.strategy</code>来设置消费者与订阅主题之间的分区分配策略。默认情况此参数的值为<code>RangeAssignor</code>，此外还有两种分配策略：<code>RoundRobinAssignor</code>和<code>StickyAssignor</code>。消费者客户端参数可以配置多个分配策略，彼此之间以逗号分隔。</p>
</blockquote>
<h4 id="RangeAssignor分配策略"><a href="#RangeAssignor分配策略" class="headerlink" title="RangeAssignor分配策略"></a>RangeAssignor分配策略</h4><blockquote>
<p>按照消费者总数和分区总数进行整除运算来获得一个跨度，然后将分区按照跨度进行平均分配，以保证分区尽可能均匀的分配给所有消费者。对于每个主题，RangeAssignor策略会将消费组内所有订阅这个主题的消费者按照名称的字典序进行排序，然后为每个消费者划分固定的分区范围，如果不够平均分配，那么字典序靠前的消费者会被多分配一个分区。</p>
</blockquote>
<h4 id="RoundRobinAssignor分配策略"><a href="#RoundRobinAssignor分配策略" class="headerlink" title="RoundRobinAssignor分配策略"></a>RoundRobinAssignor分配策略</h4><blockquote>
<p>将消费组内所有消费者及消费者订阅的所有主题的分区按照字典序排序，然后通过轮询的方式以此分配给每个消费者。如果同一个消费组内所有的订阅信息都是相同的，那么RoundRobinAssignor分配策略会是均匀的。<strong>如果同一个消费者内的消费者订阅的消息是不同的，那么在执行分区的时候就并不是完全的轮询分配</strong>，有可能导致分区分配得不均匀。</p>
</blockquote>
<h4 id="StickyAssignor分配策略"><a href="#StickyAssignor分配策略" class="headerlink" title="StickyAssignor分配策略"></a>StickyAssignor分配策略</h4><p>这种分配的目的是</p>
<ul>
<li>分区的分配要尽可能均匀。</li>
<li>分区的分配尽可能与上次分配的保持相同。1的优先级大于2.</li>
</ul>
<blockquote>
<p>这种分配策略在出现分区重分配情况下，尽可能让前后两次分配保持相同，进而减少系统资源的损耗以及其他异常情况的发生。</p>
</blockquote>
<h4 id="自定义分区分配策略"><a href="#自定义分区分配策略" class="headerlink" title="自定义分区分配策略"></a>自定义分区分配策略</h4><blockquote>
<p><code>partition.assignment.strategy</code>用于定义消费者成员如何分配分区，这个策略决定了当新的消费者加入消费者组、现有的消费者离开消费者组 或者主题的分区数发生变化，分区如何重新分配给消费者组中的成员。</p>
</blockquote>
<p>kafka中机架感知<code>broker.rack</code>的主要好处和作用：</p>
<ul>
<li>提高数据冗余： kafka的主题可以有多个副本，通过机架感知，kafka可以确保主题的各个副本分布在不同的机架上 ，这样即使整个机架发生故障，仍然可以从其他机架上的副本中读取和写入数据。</li>
<li>故障隔离： 机架感知确保单个机架或者多个机架的故障不会导致数据丢失或者服务中断，因为至少有一个副本位于健康的机架。</li>
<li>网络流量优化： 机架内的服务器之间的网络流量通常比跨机架之间的流量更快、更稳定。kakfa的机架感知可以优化数据的复制流程，使得大部分的数据复制操作都在机架内部完成，同时提高效率。</li>
</ul>
<h3 id="消费者协调器和组协调器"><a href="#消费者协调器和组协调器" class="headerlink" title="消费者协调器和组协调器"></a>消费者协调器和组协调器</h3><blockquote>
<p> 如果消费者客户端中配置了多个分区分配策略，那么以哪个为准，多个消费者之间的分区分配是需要协同的，这一切都是交给消费者<code>消费者协调器</code>和<code>组协调器</code>来完成的。</p>
</blockquote>
<p>消费者协调器和组协调器的概念是针对消费者客户端而言。</p>
<p>早期通过监听zookeeper节点实现在均衡操作，zookeeper集群中两个比较严重的问题：</p>
<ul>
<li>羊群效应：zookeeper中一个被监听的节点变化，大量的water通知被发送到客户端，导致在通知期间的其它操作延迟，也有可能发生类似死锁的问题。</li>
<li>脑裂问题：消费者进行再均衡操作时每个消费者都与Zookeeper进行通信以判断消费者或broker变化的情况，由于zookeeper本身特性，可能导致再同一时刻各个消费者获取的状态不一致，这样会导致异常问题发生。</li>
</ul>
<h4 id="再均衡的原理"><a href="#再均衡的原理" class="headerlink" title="再均衡的原理"></a>再均衡的原理</h4><blockquote>
<p>新的消费者客户端进行了重新设计，将全部消费组分成多个子集，每个消费组的子集在服务端对应一个<code>GroupCoordinator</code>对其进行管理。GroupCoordinator是kafka服务端用于管理消费组的组件。而消费者客户端的ConsumerCoordinator组件负责与GroupCoordinator进行交互。</p>
</blockquote>
<blockquote>
<p>ConsumerCoordinator与GroupCoordinator之间最重要的职责就是负责执行消费者在均衡的操作，包括前面提及的分区分配工作也是在再均衡期间完成的。</p>
</blockquote>
<p>会触发再均衡的操作：</p>
<ul>
<li>有新的消费者加入消费组。</li>
<li>有消费者宕机下线，消费者并不一定需要真正下线，长时间GC、网络延迟导致消费者长期未向GroupCoordinator发送心跳等情况时，GroupCoordinator会认为消费者已经下线。</li>
<li>有消费者主动退出消费组（LeaveGroup请求）</li>
<li>消费组对应的GroupCoordinator节点发生了变更。</li>
<li>消费组内所订阅的任意主题或者主题的分区发生了变化。</li>
</ul>
<p>当有消费者加入消费组时，消费者、消费组及组协调器之间经历的阶段。</p>
<ul>
<li><code>FIND_COORDINATOR</code>：<code>消费者需要确定它所属消费组对应的GroupCoordinator所在的broker</code>，并创建与该broker相互通信的网络连接。如果消费者已经保存了与消费者对应的GroupCooridinator信息，并且正确建立了连接，则可以进入第二阶段。否则，向集群中某个节点（负载最小的节点）发送FindCoordinatorRequest请求来查找对应的GroupCoordinator。<code>GroupCoordinator</code>位于该消费组对应<code>__consumer_offsets</code>分区的leader副本所在的broker节点。</li>
<li>JOIN_GROUP：在成功找到消费组对应的GroupCoordinator之后就进入加入消费组的阶段，消费者会发送 JoinGroupRequest请求，并处理响应。<ul>
<li>JoinGroupRequest的结构包含的域：<br>- group_id<br>- session_time: GroupCoordintaor超过session_timeout指定时间内没有收到心跳报文则认定此消费者已经下线。<br>- rebalance_timeout: 对应消费端参数<code>max.poll.interval.ms</code>，当消费组再平衡的时候，GroupCoordinator等待各个消费者重新加入的最长等待时间。<br>- member_id: GroupCoordinator分配给消费者的id标识，消费者第一次发送JoinGroupRequest请求时设置此字段为null。<br>- protocol_type: 消费组实现的协议，对于消费者此字段设置为consumer.<br>- group_protocols: 数组类型，囊括多个分区分配策略。</li>
</ul>
</li>
</ul>
<p>如果原有的消费者重新加入消费组，那么在真正发送JoinGroupRequest请求之前还要执行一些准备工作：</p>
<ol>
<li>如果消费者参数<code>enable.auto.commit</code>设置为true，自动提交位移功能，那么在请求加入消费组之前需向GroupCoordinator提交消费位移。阻塞执行。</li>
<li>如果消费者添加了自定义的再均衡监听器，那么此时会调用onPartitionsRevoked()方法再重新加入消费组之前实施自定义的规则逻辑，比如清除一些状态、提交位移。</li>
<li>重新加入消费组，之前和GroupCoordinator节点之间的心跳检测就不需要了，所以成功加入消费组之前需要禁止心跳检测的运作。</li>
</ol>
<h4 id="选举消费组中的leader"><a href="#选举消费组中的leader" class="headerlink" title="选举消费组中的leader"></a>选举消费组中的leader</h4><blockquote>
<p>GroupCoordinator需要为消费组内的消费者选举出一个消费组的leader。分两种情况，如果消费组内还没有leader，那么第一个加入消费组的消费者即为消费组的leader。如果存在leader，取GroupCoordinator中保存消费者信息hashmap的第一个key对应的消费者元信息，比较随意。</p>
</blockquote>
<h4 id="选举分区分配策略"><a href="#选举分区分配策略" class="headerlink" title="选举分区分配策略"></a>选举分区分配策略</h4><blockquote>
<p>每个消费者都可以设置自己的分区分配策略，对消费组而言需要从各个消费者选举的分配策略中选举出一个彼此都信服的策略来进行整体的分区分配。<code>这个分区分配的选举是根据消费组内各个消费者投票决定的</code>。</p>
</blockquote>
<p>最终选举的分配策略基本上是被各个消费者支持最多的策略，具体选举过程：</p>
<ul>
<li>收集各个消费者支持的所有分配策略，组成候选集。</li>
<li>每个消费者从候选集中找出第一个自身支持的策略，为这一策略投一票。</li>
<li>计算候选集中各个策略的选票数，选票最多的策略即为消费者的分配策略。<blockquote>
<p>如果有的消费者不支持选出来的分配策略，会抛出异常，就是这个消费者没有配置这个分配策略就会不支持。</p>
</blockquote>
</li>
<li>SYNC_GROUP<blockquote>
<p>leader 消费者根据在第二阶段中选举出来的分区分配策略来实施具体的分区分配，在此之后需要将分配的方案同步给各个消费者，通过GroupCoordinator进行转发同步分配方案。在第三阶段，也就是同步阶段，各个消费者会向GroupCoordinator发送SyncGroupRequest请求来同步分配方案。</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>服务端在收到消费者发送的SyncGroupRequest请求之后会交由GroupCoordinator来负责具体的逻辑处理。GroupCoordinator同样会先对SyncGroupRequest请求做合法性校验，在此之后会将从leader 消费者发送过来的分配方案提取出来，连同整个消费组的元数据信息一起存入Kafka的__consumer_offsets主题中，最后发送响应给各个消费者以提供给各个消费者各自所属的分配方案</p>
</blockquote>
<blockquote>
<p>当消费者收到所属的分配方案之后会调用PartitionAssignor中的onAssignment（）方法。随后再调用ConsumerRebalanceListener中的OnPartitionAssigned（）方法。之后开启心跳任务，消费者定期向服务端的GroupCoordinator发送HeartbeatRequest来确定彼此在线。</p>
</blockquote>
<blockquote>
<p>消费者客户端提交的消费位移会保存再kafka的__consumer_offsets主题中，消费组的元数据信息也会保存在这里。</p>
</blockquote>
<ul>
<li>HeartBeat阶段<blockquote>
<p>进入这个阶段，消费组中的所有消费者都进入正常工作状态。在正式消费之前，<strong>消费者还需要确定拉取消息的起始位置</strong>。假设之前已经将最后的消费位移提交到了GroupCoordinator，并且GroupCoordinator将其保存到了Kafka内部的__consumer_offsets主题中，此时消费者可以通过<strong>OffsetFetchRequest</strong>请求获取上次提交的消费位移并从此处继续消费。</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>消费者通过向 GroupCoordinator 发送心跳来维持它们与消费组的从属关系，以及它们对分区的所有权关系。只要消费者以正常的时间间隔发送心跳，就被认为是活跃的，说明它还在读取分区中的消息。心跳线程是一个独立的线程，可以在轮询消息的空档发送心跳。如果消费者停止发送心跳的时间足够长，则整个会话就被判定为过期，GroupCoordinator 也会认为这个消费者已经死亡，就会触发一次再均衡行为。消费者的心跳间隔时间由参数<code>heartbeat.interval.ms</code>指定，默认值为3000，即3秒，这个参数必须比<code>session.timeout.ms</code>参数设定的值要小，一般情况下heartbeat.interval.ms的配置值不能超过session.timeout.ms配置值的1&#x2F;3。这个参数可以调整得更低，以控制正常重新平衡的预期时间。</p>
</blockquote>
<blockquote>
<p>如果一个消费者发生崩溃，并停止读取消息，那么 GroupCoordinator 会等待一小段时间，确认这个消费者死亡之后才会触发再均衡。在这一小段时间内，死掉的消费者并不会读取分区里的消息。这个一小段时间由session.timeout.ms参数控制，该参数的配置值必须在broker端参数group.min.session.timeout.ms（默认值为 6000，即 6 秒）和 group.max.session.timeout.ms（默认值为300000，即5分钟）允许的范围内。还有一个参数 max.poll.interval.ms，它用来指定使用消费者组管理时 poll（）方法调用之间的最大延迟，也就是消费者在获取更多消息之前可以空闲的时间量的上限</p>
</blockquote>
<h3 id="consumer-offsets主题"><a href="#consumer-offsets主题" class="headerlink" title="consumer_offsets主题"></a>consumer_offsets主题</h3><blockquote>
<p>位移提交的内容最终会保存到kafka的内部主题<code>_consumer_offsets</code>中。一般情况下，当集群中第一次由消费者消费消息时会自动创建主题_consumer_offsets，它的副本因子受<code>offsets.topic.replication.factor</code>约束，默认为3.分区数可以通过<code>offsets.topic.num.partitions</code>参数设置，默认为50.客户端提交消费位移使用OffsetCommitRequest请求实现。请求体中包含<code>retention_time</code>表示当前提交的消费位移所能保留的时长，不过对于消费者而言这个值保持为-1.表示按照broker端的配置<code>offsets.retention.minutes</code>来确定保留时长。默认为7天，超过这个时长后消费位移的消息就会被删除（使用墓碑消息或日志压缩策略）。</p>
</blockquote>
<blockquote>
<p>有些定时消费的任务在执行完某次消费任务之后保存了消费位移，之后隔了一段时间再次执行消费任务，如果这个间隔时间超过offsets.retention.minutes的配置值，那么原先的位移信息就会丢失，最后只能根据客户端参数 auto.offset.reset 来决定开始消费的位置，遇到这种情况时就需要根据实际情况来调配<code>offsets.retention.minutes</code>参数的值。</p>
</blockquote>
<p>OffsetCommitRequest中的其余字段大抵也是按照分区的粒度来划分消费位移的。</p>
<blockquote>
<p>如果有若干消费者消费了某个主题中的消息，并且也提交了相应的消费位移，那么再删除这个主题之后会一并将这些消费位移消息删除。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://gitee.com/yangxiao2000/md_img/raw/master/images/20231007133645.png" alt="1696656981671.png"></p>
</blockquote>
<ul>
<li>offset： 位移</li>
<li>metadata: 自定义元数据信息</li>
<li>commit_timestamp: 位移提交的时间戳</li>
<li>expire_timestamp: 消息位移被判断超时的时间戳</li>
</ul>
<blockquote>
<p>删除主题之后会一起将这些消费位移信息删除。</p>
</blockquote>
<h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><p>一般而言，消息中间件的消息传输保证有三个层级：</p>
<ul>
<li>at most once: 至多一次。消息可能会丢失，但绝对不会重复传输。</li>
<li>at least once:最少一次，消息绝不会丢失，但可能会重复传输。</li>
<li>exactly once:恰好一次。每条消息肯定会被传输一次且仅传输一次。</li>
</ul>
<blockquote>
<p>kafka的消息传输保障机制非常直观。当生产者向kafka发送消息时，<strong>一旦消息被成功提交到日志文件</strong>，由于多副本机制的存在，这条消息就不会被丢失。</p>
</blockquote>
<blockquote>
<p>对于生产者来说，如果生产者发送到kafka之后，遇到网络问题而造成通信中断，那么生产者无法判断该消息是否提交。虽然kafka无法确定网络故障期间发生了什么，但生产者可以进行多次重试来确保消息已经写入kafka，这个重试过程中有可能会造成消息的重复写入，kafka提供的消息传输保障为at least once。</p>
</blockquote>
<blockquote>
<p>对于消费者而言，<strong>消费者处理消息和提交消费位移的顺序</strong>再很大程度上决定了消费者提供哪一种消息传输保障。如果消费者在拉取完消息之后，应用逻辑先处理消息后提交消息位移，宕机可能出现重复消费对应的是<code>at least once</code>.如果消费者在拉完消息之后，应用逻辑先提交消费位移，宕机重启之后可能会丢失数据，此时对应的是at most once</p>
</blockquote>
<blockquote>
<p>kafka引入<code>幂等</code>和<code>事务</code>特性以此来实现EOS（精确一次）；</p>
</blockquote>
<h4 id="幂等"><a href="#幂等" class="headerlink" title="幂等"></a>幂等</h4><blockquote>
<p>幂等就是对接口的多次调用所产生的结果和调用一次是一致的。<code>生产者在进行重试的时候可能会重复写入消息，而使用幂等性功能之后就可以避免这种情况</code>。开启幂等性功能需要显示将生产者客户端参数<code>enable.idempotence</code>设置为true。</p>
</blockquote>
<blockquote>
<p>为了使用生产者的幂等性，kafka引入了<code>producer id</code>和<code>序列号</code>。每个生产者实例在初始化时都会被分配一个PID对于每个PID，消息发送的每一个分区都有对应的序列号，这些序列号从0开始递增。生产者每发送一条消息就会将&lt;PID,分区&gt;对应序列号的值加1.</p>
</blockquote>
<blockquote>
<p>broker端会在内存为每一对&lt;PID,分区&gt;维护一个序列号。对于接收到的每一条消息，只有当他的序列号的值比broker端中维护的对应的序列号的值大1时，broker才会接收它。否则丢弃。如果序列号大于2或更大，则标志出现消息丢失，生产者会抛出异常。</p>
</blockquote>
<blockquote>
<p>引入序列号来实现幂等也只是针对每一对《PID,分区》而言，代表着<strong>幂等只能保证单个生产者会话单分区的幂等</strong>。</p>
</blockquote>
<h4 id="事务-1"><a href="#事务-1" class="headerlink" title="事务"></a>事务</h4><blockquote>
<p>幂等性并不能跨多个分区运作，而事务可以弥补这个缺陷。<strong>事务可以保证对多个分区写入操作的原子性</strong>。</p>
</blockquote>
<blockquote>
<p>对流式应用而言，一个典型的应用模式为”consumer-transform-produce”。在这种模式下消费和生产并存：应用程序从某个主题中消费消息，经过一系列转换写入另一个主题，消费者可能在提交消费位移的过程中出现问题而导致重复消费，也有可能生产重复生产消息。<strong>kafka中的事务可以使应用程序将消费消息、生产消息、提交消费位移当作原子操作来处理，同时成功或失败。</strong></p>
</blockquote>
<blockquote>
<p>为了实现事务，应用程序必须提供唯一的<code>transactionalid</code>,可以通过客户端参数<code>transactional.id</code>来显式设置。事务要求生产者开启幂等特性，因此通过将transactional.id参数设置为非空从而开启事务特性的同时需要将<code>enable.idempotence</code>设置为true。</p>
</blockquote>
<blockquote>
<p><strong>transactionlId与PID一一对应</strong>，两者之间所不同的是transactionalId由用户显式设置，PID由kafka内部分配。另外，<strong>为了保证新的生产者启动后具有相同的transactionId的旧生产者能够立即生效，每个生产者通过transactionalid获取PID的同时，还会获取一个单调递增的producer epoch</strong>。如果使用同一个transactionId开启两个生产者，那么前一个生产者会报错。</p>
</blockquote>
<blockquote>
<p>从生产者的角度分析，通过事务，kafka可以保证跨生产者会话的消息幂等发送，以及跨生产者会话的事务恢复。前者表示具有相同transactionalid的新生产者示例被创建且工作的时候，旧的且拥有相同的transactionalId的生产者示例将不再工作。或者指当某个生产者实例宕机后，新的生产者实例可以保证任务未完成的旧事务要么被提交，要么被中止。</p>
</blockquote>
<p>消费者的角度分析，事务保证的语义相对偏弱，以下原因，kakfa不能保证已提交的事务中的所有消息都能够被消费</p>
<ul>
<li>对采用日志压缩策略的主题而言，事务中的某些消息可能被清理。</li>
<li>事务中消息可能分布在同一个分区的多个日志分段，当老的日志分段被删除，对应的消息可能会丢失。</li>
<li>消费者可以通过seek方法访问任意offset消息，可能遗漏事务中的部分消息。</li>
<li>消费者在消费时可能没有分配到事务内的所有分区，如此它就不能读取事务中的所有消息。</li>
</ul>
<p>java中提供的事务相关的方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> <span class="title function_">initTransactions</span><span class="params">()</span>;<span class="comment">//初始化事务</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">beginTransaction</span><span class="params">()</span>;<span class="comment">//开启事务</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">sendOffsetsToTransaction</span><span class="params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, String consumerGroupId)</span><span class="comment">//消费在事务内的位移提交操作</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">commitTransaction</span><span class="params">()</span>;<span class="comment">//提交事务</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">abortTransactions</span><span class="params">()</span>;<span class="comment">//终止事务</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>在消费端有一个参数<code>isolation.level</code>，这个参数默认值为<code>read_uncommitted</code>，意思是消费端应用可以看到未提交的事务。可以设置未<code>read_committed</code>表示消费端不可以看到尚未提交事务内的消息。不过kafkaConsumer内部会缓存这些消息，知道生产者执行commitTransaction才能将这些消息推送给消费端应用。</p>
</blockquote>
<blockquote>
<p>日志文件除了普通的消息，还有<code>一种消息专门用来标志一个事务的结束，那就是控制消息</code>。控制消息包括COMMIT和ABORT,分别表示事务已经成功提交或已经被成功终止。kafkaConsumer可以通过事务已经成功提交或被成功中断，结合isolation.level来决定是否将对应的消息返回给消费者应用。</p>
</blockquote>
<blockquote>
<p>为了实现事务的功能，kafka还引入了<code>事务协调器</code>来处理事务，类似组协调器。每一个生产者都会被指派一个特定的TransactionCoordinator，所有的事务逻辑包括PID等都是由TransactionCoordinator来负责实施的。TransactionCoordinator 会将事务状态持久化到内部主题<code>__transaction_state</code>中。</p>
</blockquote>
<blockquote>
<p>事务状态包含empty(0)、Ongoing(1)、PrepareCommit(2)、PrepareAbort(3)、CompleteCommit(4)、CompleteAbort(5)、Dead(6)。</p>
</blockquote>
<h2 id="可靠性"><a href="#可靠性" class="headerlink" title="可靠性"></a>可靠性</h2><h3 id="副本刨析"><a href="#副本刨析" class="headerlink" title="副本刨析"></a>副本刨析</h3><p>副本是分布式系统对数据和服务提供的一种冗余方式。副本分为数据副本和服务副本。</p>
<ul>
<li>数据副本：不同的节点持久化同一份副本，当某个节点存储的数据丢失，可以从副本读取数据。</li>
<li>服务副本：多个节点提供同样的服务，每个节点都有能力接收来自外部的请求并进行相应的处理。</li>
</ul>
<blockquote>
<p>任何在设计阶段考虑的异常情况，一定会在系统实际运行中发生，并且在系统实际运行过程中还会遇到很多在设计时没有考虑到的异常故障。</p>
</blockquote>
<blockquote>
<p>正常情况下，所有分区的副本都处于ISR状态，但是难免会出现异常，从而某些副本不处于ISR集合中，这些副本被称为失效副本。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 显式主题中包含失效副本分区的情况</span><br><span class="line">kafka-topic.sh --zookeeper xxxx --describe --topic xxx --under-replicated-partitions</span><br></pre></td></tr></table></figure>

<blockquote>
<p>kafka通过为一个的broker参数<code>replica.lag.time.max.ms</code>，当ISR集合中follower副本之后leader副本时间超过则判断为同步失败。</p>
</blockquote>
<p>失效副本的判断实现原理:</p>
<blockquote>
<p>当follower副本将leader副本LEO之前的日志全部同步时，则任务follower副本已经追赶上leader副本，此时更新该副本的<code>lastCaughtTimeMs</code>标识。kafka的<code>副本管理器</code>会启动一个副本过期检测的定时任务取检查当前时间与副本<code>lastCaughtTimeMs</code>差值是否大于参数<code>replica.lag.time.max.ms</code>指定的值。</p>
</blockquote>
<h4 id="ISR的伸缩"><a href="#ISR的伸缩" class="headerlink" title="ISR的伸缩"></a>ISR的伸缩</h4><blockquote>
<p>kafka启动的时候会开启两个与ISR相关的定时任务，分别为<code>isr-expiration</code>和<code>isr-change-propagation</code>。isr-expiration任务会周期性检测（<code>replication.lag.time.max.ms</code>一半的值）每个分区是否需要缩减其ISR集合。存在ISR中的失效副本，就会被缩容。如果某个分区的ISR集合发生变更，则会将变更后的数据记录到Zookeeper对应的&#x2F;broker&#x2F;topics&#x2F;topic&#x2F;partition&#x2F;state节点中。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//state节点的数据</span><br><span class="line">&#123;&quot;controller_epoch&quot;:1,&quot;leader&quot;:0,&quot;version&quot;:1,&quot;leader_epoch&quot;:0,&quot;isr&quot;:[0]&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>controller_epoch: kafka控制器的epoch</li>
<li>leader：当前分区leader副本所在的broker节点</li>
<li>version: 版本号</li>
<li>leader_epoch: 当前分区leader纪元</li>
<li>isr: 变更后的ISR列表</li>
</ul>
<blockquote>
<p>除此之外，当ISR集合发生变更时还会将变更后的记录缓存到<code>isrChangeSet</code>中，isr-change-propagation任务会周期性检查isrChangeSet,如果发现isrChangSet存在变更记录，那么它会在ZooKeeper的<code>/isr_change_notification</code>路径下创建一个以isr_change_开头的持久顺序节点并将isrChangeSet中的信息保存到这个节点中。<code>Kafka控制器为/isr_change_notification添加了一个Watcher</code>，当这个节点中有子节点发生变化时会触发Watcher的动作，以此通知控制器更新相关元数据信息并向它管理的broker节点发送更新元数据的请求，最后删除&#x2F;isr_change_notification路径下已经处理过的节点。</p>
</blockquote>
<p>频繁的触发Watcher会影响kafka控制器、zookeeper甚至其它broker的性能，为了避免，添加了如下限定条件。需要满足1个才可以将ISR集合的变化写入<code>目标节点</code>：</p>
<ul>
<li>上一次ISR集合发生变化距离已经超过5s。</li>
<li>上一次写入Zookeeper的时间距离现在超过60s。</li>
</ul>
<blockquote>
<p>随着follower副本不断与leader副本进行消息同步，follower副本的LEO也会逐渐后移，并追赶上leader副本，此时就有资格进入ISR集合.追赶上leader副本的标准是LEO不小于leader副本的HW。接下来和isr集合减少情况相同通过定时任务创建zookeeper节点。</p>
</blockquote>
<p>多分区消息追加过程：</p>
<ul>
<li>生产者客户端发送消息至leader副本中。</li>
<li>消息被追加到leader副本的本地日志，并且会更新日志的偏移量。</li>
<li>follower副本(副本2和副本3)向leader副本请求同步数据</li>
<li>leader副本所在服务器读取本地日志，并更新对应拉取的follower副本的信息。</li>
<li>follower副本收到leader副本返回的拉取结果，将消息追加到本地日志中，并更新日志的偏移量信息。</li>
</ul>
<blockquote>
<p>follower副本向leader副本拉取信息，在拉取的请求中会自带自身的LEO信息，这个LEO信息对应的是FetchRequest请求中的<code>fetch_offset</code>。会根据所有follower传递的LEO来更新leader的HW。leader副本返回给follower副本响应的信息，并且还自带自身的HW信息。follower收到leader副本的响应会更新自己的LEO并且会更新自己的HW信息。</p>
</blockquote>
<blockquote>
<p>leader副本所在的节点会记录所有副本的LEO，而follower副本所在节点只会记录自身的LEO，而不会记录其他副本的LEO。kafka根目录下<code>cleaner-offset-checkpoint</code>、<code>log-start-offset-checkpoint</code>、<code>recovery-point-offset-checkpoint</code>和<code>replication-offset-checkpoint</code>四个检查点文件。<code>recovery-point-offset-checkpoint</code>和<code>replication-offset-checkpoint</code>这两个文件分别对应的LEO和HW。kafka中会有定时任务负责将<strong>所有分区的LEO刷写</strong>到恢复点文件<code>recovery-point-offset-checkpoint</code>中，定时周期由broker端参数<code>replica.high.watermark.checkpoint.interval.ms</code>来配置。<code>log-start-offset-checkpoint</code>文件对应logStartOffset。</p>
</blockquote>
<blockquote>
<p>kafka开始引入leader epoch的概念，再需要截断数据的时候使用leader epoch作为参考依据而不是原本的HW。每个副本还会增设一个矢量 leaderEpoch &#x3D;&gt; startOffset，其中StartOffset用来标识当前leaderEpoch下写入的第一条消息的偏移量。写入到<code>leader-epoch-checkpoint</code>文件，再leader发生变更时，对应的矢量写入到这个文件中。</p>
</blockquote>
<blockquote>
<p>kafka是主写主读的生产消费模型, kafka为什么不支持读写分离(主写从读的缺点)：</p>
</blockquote>
<ul>
<li>数据一致性问题。数据从主节点到从节点之间必然有一个延时的时间窗口，这个时间窗口可能导致主从节点数据不一致问题。</li>
<li>延时问题:  kafka主从同步需要经过网络-&gt; 主节点内存-&gt;主节点磁盘-&gt;网络-&gt;从节点内存-&gt;从节点磁盘。这期间会耗费大量的时间，对于延时敏感的应用，主写从读的功能并不太适用。</li>
</ul>
<h3 id="日志同步机制"><a href="#日志同步机制" class="headerlink" title="日志同步机制"></a>日志同步机制</h3><blockquote>
<p>在分布式系统中，日志同步机制既要保证数据的一致性，也要保证数据的顺序性。<strong>最简单的方式是从集群中选出一个leader来负责处理数据写入的顺序性。</strong></p>
</blockquote>
<blockquote>
<p>通常情况下，只要leader不宕机我们就不需要关心follower的同步问题。不过当leader宕机时，我们就需要从follower中选举出一个新的leader。follower的同步状态可能落后leader很多。甚至还可能处于宕机状态，所需必须确保选择具有最新日志消息的follower作为新的leader。日志同步机制的一个基本原则：<strong>如果告知客户端已经成功提交了某条消息，那么即使leader宕机，也要保证新选举出来的leader中能够包含这些消息</strong>。这里就有一个需要权衡的地方，如果leader在消息提交前需要等待更多的follower确认，那么在它宕机之后就有更多的follower替代它，不过会造成性能的下降。</p>
</blockquote>
<blockquote>
<p>有一种方案是少数服从多数，它可以用来负责提交决策和选举决策。2f+1副本，保证提交之前f+1进行确认。这种方案有一个很大的优势，系统的延迟取决于最快的几个节点。劣势就是为了保证leader选举的正确进行，它所能容忍的失败的follower比较少。比较经典使用案例：Zab、Raft。</p>
</blockquote>
<blockquote>
<p>kafka使用的更像是微软<code>PacificA</code>算法。kafka动态维护着一个ISR集合，处于ISR集合内的节点保持于leader相同的HW。只要位列其中的副本<code>(unclean.leader.election.enable配置为false</code>)才有资格被选举为新的leader。在ISR模型（f+1）副本数配置下，一个kafka分区能够容忍最大f个节点失败，相比于少数服从多数所需副本数大大减少。</p>
</blockquote>
<blockquote>
<p><strong>一般同步策略依赖于稳定的存储系统来做数据恢复</strong>，表明在数据恢复时日志文件不可丢失且不能有数据上的丢失。而kafka不是必须宕机之后之后只能在本地数据日志进行恢复，kafka允许宕机副本重新加入ISR集合，但是进行ISR之前必须保证自己能够重新同步完leader中所有数据。</p>
</blockquote>
<h3 id="kafka高级应用"><a href="#kafka高级应用" class="headerlink" title="kafka高级应用"></a>kafka高级应用</h3><h4 id="过期时间（TTL）"><a href="#过期时间（TTL）" class="headerlink" title="过期时间（TTL）"></a>过期时间（TTL）</h4><blockquote>
<p>使用消息的timestamp字段和拦截器ConsumerInterceptor接口的onConsumer()方法，不过还需要消息中headers字段来做配合。将消息的TTL的设定值以键值对的形式保存在消息的headers中，这样消费者消费这条消息可以在拦截器中根据headers中设定的超时时间来判断是否超时。</p>
</blockquote>
<h4 id="延时队列"><a href="#延时队列" class="headerlink" title="延时队列"></a>延时队列</h4><p>队列是存储消息的载体，延时队列存储的对象是延时消息。延时消息：消息被发送以后，并不想让消费者立即获取，而是等待特定时间后，消费者才能获取这些消息。</p>
<p>原生的kafka并不具备延时队列的功能，不过我们可以对其进行改造和实现。kafka实现延时队列的方式有很多种，延时队列可以通过消费者客户端拦截器来实现。但存在不好处理的情况：</p>
<blockquote>
<p>某一批拉取到的消息集中有一条消息的延迟时间很长，其它的消息延时时间很短而很快被消费，那么如何进行处理？</p>
</blockquote>
<ol>
<li>如果这时提交消费位移，那么延时时间很长的那条消息会丢失。</li>
<li>如果这时不继续拉取消息而等待这条延时时间很长的消息到达延时时间，这样又会导致消费滞后很多，而且如果位于这条消息后面的很多消息的延迟时间很短，那么就会导致这些消息无端的拉长延时时间。</li>
<li>如果这时候不提交消费位移而继续拉取消息，等待这条延时时间很长的消息满足条件之后再提交消费位移。那么在此期间这些消息需要常驻内存中，而且还需要一个定时机制来定时检测是否满足被消费的条件。会引起内存保障，并且如果发生异常，会造成大量数据的重复消费。</li>
</ol>
<p>有一种改变方案就是消费者拉取一批消息，如果这批消息中有未达到延时时间的消息，那么就将这写消息重新写入主题等待后续消费。但是如果出现消息堆积，会造成消息严重的滞后消费。</p>
<p>另一种可行性方案：在发送延时消息的时候并不是先投递到要发送的真实主题，而是先投递到一些kafka的内部主题中，这些主题对用户不可见，然后通过一个自定义服务拉取这些内部主题中的消息，并将满足条件的消息再投递到要发送的真实主题中，消费者所订阅的还是真实的主题。</p>
<p>延时时间一般以秒来计算，若要支持2小时（7200）之内的延时时间的消息，那么显然不能按照延时时间来分类这些主题。如果采用这种方案一般是按照不同的延时等级来划分的，比如设定5s、10s、30s等级，延时的消息按照延时时间投递到不同等级的主题中，投递到同一主题中的消息的延迟时间会被强转为与此主题延时等级一致的延时时间，这样<strong>延时误差就控制再两个延时等级的时间差范围内。</strong>具体实现消息拉取重新投递通过java代码中DelayQueue，可以保证消息按照再次投递时间进行有序排序，这样下游的消息发送线程就能按照先后顺序获取最先投递条件的消息。</p>
<h4 id="消息路由"><a href="#消息路由" class="headerlink" title="消息路由"></a>消息路由</h4><p>消息路由时消息中间件中常见的概念。rabbitmq中就使用路由键RoutingKey来进行消息路由。rabbitmq中生产者将消息发送到交换机Exchange中，然后由交换器根据指定的路由键将消息路由到一个或多个队列中，消费者消费的是队列中的消息。从整体上看，RabbitMQ通过路由键将原本发往一个地方的消息做了区分，然后让不同的消费者消费到自己关注的消息。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/582813e312c74d21be16ad19ebef827f~tplv-k3u1fbpfcp-watermark.image" alt="rabbitmq生产消费模型.png"></p>
<p>kafka默认按照主题进行路由，消息发往主题之后会被订阅的消费者全盘接收，这里没有类似消息路由的功能来将消息进行二级路由，这一点从逻辑概念上来说并无任何问题。但是如果业务需要复用相同的主题，就会出现消息接收时的混乱，如果Kafka需要消息路由，那么完全可以通过细粒度化切分主题来实现。</p>
<p>除了设计缺陷，还有一些历史遗留问题希望kafka具备一个消息路由功能。如果原先系统使用rabbitmq这种具备消息路由的生产消费模型，运行一段时间之后，需要更换为kafka，并且还需要保留原有系统的逻辑。我们可以进行一层映射。消费者根据消息特定的标识来获取消息，其余的都全部过滤。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0a40b459b15949c4b0c9595cdfd5beb6~tplv-k3u1fbpfcp-watermark.image" alt="rabbitmq和kafka映射关系.png"><br>具体的实现方式可以在消息的headers字段中加入一个键”routingkey”、值为特定业务标识的Header，然后再消费端中使用拦截器挑选出特定业务标识的消息。kafka中消息路由的实现架构如下图所示。消费组ConsuerGroup1根据特定的Header标识rk2和rk3来消费主题TopicA和TopicB中对应的消息而忽略Header标识为rk1的消息。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c71cc5aa0c6b4a76a3cfe4fe783aa7ad~tplv-k3u1fbpfcp-watermark.image" alt="kafka中消息路由的实现架构.png"></p>
<h4 id="消息轨迹"><a href="#消息轨迹" class="headerlink" title="消息轨迹"></a>消息轨迹</h4><p>问题消息发送成功了吗？为什么发送的消息在消费端消费不到？为什么消费端重复消费了消息？对于此类问题，我们可以引入<code>消息轨迹</code>来解决。消息轨迹指的是一条消息从生产者发出，经由broker存储，再到消费者消费的整个过程中，各个相关节点的状态、时间、地点等数据汇聚而成的完整链路消息。生产者、broker、消费者这3个角色在处理消息的过程中都会在链路中增加相应的信息，将这些信息汇聚、处理之后就可以查询任意消息的状态，进而为生产环境中的故障排除提供强有力的数据支持。</p>
<p>对消息轨迹而言，最常见的实现是封装客户端，在保证正常生产消费的同时添加相应的轨迹消息埋点逻辑。无论生产，还是消费在执行之后都会由相应的轨迹信息，我们需要将这些消息保存起来。下面这种实现方式参考kafka的做法，它将消费位移消息保存到__consumer_offset中。对应地，我们同样将轨迹消息保存到kafka地某个主题中。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/632a0b921b794714a41473c72ae21f94~tplv-k3u1fbpfcp-watermark.image" alt="消费轨迹实现方式.png"></p>
<h2 id="Kafka简介"><a href="#Kafka简介" class="headerlink" title="Kafka简介"></a>Kafka简介</h2><p> Kafka是一种分布式的，基于发布&#x2F;订阅的消息系统。主要设计目标如下：</p>
<ul>
<li>以时间复杂度为O（1）的方式提供消息持久化能力，即使TB级以上数据也能保证常数时间复杂度的访问性能。</li>
<li>高吞吐率，即使在非常廉价的商用机器上也能做到单机支持每秒100K以上消息的传输。</li>
<li>支持Kafka Server间的消息分区及分布式消费，同时保证每个分区内消息顺序传输。</li>
<li>同时支持离线数据处理和实时数据处理。</li>
<li>Scale out：支持在线水平扩展</li>
</ul>
<h2 id="kafka消息删除机制"><a href="#kafka消息删除机制" class="headerlink" title="kafka消息删除机制"></a>kafka消息删除机制</h2><p> kafka会保留消息数据，无论消费与否，当然因为磁盘限制，不可能永远保留所有数据。提供两种策略删除数据。一是基于时间，二是基于Partition文件大小。</p>
<p>因为Kafka读取特定消息的时间复杂度为O(1)，即与文件大小无关，所以这里删除过期文件与提高Kafka性能无关。选择怎样的删除策略只与磁盘以及具体的需求有关。另外，Kafka会为每一个Consumer Group保留一些metadata信息——当前消费的消息的position，也即offset。这个offset由Consumer控制。正常情况下Consumer会在消费完一条消息后递增该offset。当然，Consumer也可将offset设成一个较小的值，重新消费一些消息。因为offset由Consumer控制，所以Kafka broker是无状态的，它不需要标记哪些消息被哪些消费过，也不需要通过broker去保证同一个Consumer Group只有一个Consumer能消费某一条消息，因此也就不需要锁机制，这也为Kafka的高吞吐率提供了有力保障</p>
<h2 id="Producer消息路由"><a href="#Producer消息路由" class="headerlink" title="Producer消息路由"></a>Producer消息路由</h2><p>Producer发送消息到broker时，会根据<strong>Paritition机制</strong>选择将其存储到哪一个Partition。如果Partition机制设置合理，所有消息可以均匀分布到不同的Partition里，这样就实现了负载均衡。可以通过修改配置文件进行设置新建topic的默认数量，也可以在新建topic时进行指定。</p>
<p>在发送一条消息时，可以指定这条消息的key，Producer根据这个key和Partition机制来判断应该将这条消息发送到哪个Parition。Paritition机制可以通过指定Producer的<code>paritition. class</code>这一参数来指定，该class必须实现<code>kafka.producer.Partitioner</code>接口。</p>
<h2 id="Push-vs-Pull"><a href="#Push-vs-Pull" class="headerlink" title="Push vs Pull"></a>Push vs Pull</h2><p>作为一个消息系统，Kafka遵循了传统的方式，选择由Producer向broker push消息，由Consumer从broker pull消息。<br>push模式和pull模式各有优劣：<br>    push模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的，push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成Consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据Consumer的消费能力以适当的速率消费消息，但是pull有个缺点就是broker没有可供消费的消息，将导致consumer不断在循环中轮询，直到新消息到达。为了避免这点，kafka有个参数可以让consumer阻塞直到新消息到达（也可以阻塞直到消息的数量达到某个特定的量进行批量发）。</p>
<h2 id="kafka副本同步机制"><a href="#kafka副本同步机制" class="headerlink" title="kafka副本同步机制"></a>kafka副本同步机制</h2><blockquote>
<p>kafka的每个Partition有一个预写式日志文件，每个Partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到Partition中，Partition中的每个消息都有一个连续的序列号叫做offset,确定它在分区日志中唯一的位置。</p>
</blockquote>
<blockquote>
<p>kafka每个topic的partition具有多个副本，采用多副本机制实现故障自动转移。副本分为leader和follower。leader断线，会自动选举一个follower作为leader，证kafka的可用性。只要有一个副本没有断线，kafka就可用。leader处理partition的所有读写请求，与此同时，follower会被动定期地去复制leader上的数据（类似与消费者）。</p>
</blockquote>
<blockquote>
<p>消息成功复制到所有同步副本之后才算提交成功，消息复制延迟受最慢的follower限制,重要的是快速检测慢副本,如果follower”落后”太多或者失效,leader将会把它从replicas从ISR移除。</p>
</blockquote>
<blockquote>
<p><strong>replica.lag.max.messages</strong>（在kafka0.10.0中移除）设置为4，表明只要follower落后leader不超过3，就不会从同步副本列表中移除。<strong>replica.lag.time.max.ms</strong>设置为500 ms，表明只要follower向leader每隔200ms都能发送fetchRequest，就不会被标记为死亡,也不会从同步副本列中移除。</p>
</blockquote>
<p>kafka的复制机制既不是单纯的同步复制也不是简单的异步复制。事实上，同步复制要求所有能工作的Follower都复制完，这条消息才会被认为commit，这种复制方式极大的影响了吞吐率（高吞吐率是Kafka非常重要的一个特性）。而异步复制方式下，Follower异步的从Leader复制数据，数据只要被Leader写入log就被认为已经commit，这种情况下如果Follower都落后于Leader，而如果Leader突然宕机，则会丢失数据。而Kafka的这种使用<strong>ISR</strong>的方式则很好的均衡了确保数据不丢失以及吞吐率。Follower可以<strong>批量</strong>的从Leader复制数据，这样极大的提高复制性能（批量写磁盘），极大减少了Follower与Leader的差距。</p>
<p>Kafka只解决fail&#x2F;recover，不处理“Byzantine”（“拜占庭”）问题。一条消息只有被ISR里的所有Follower都从Leader复制过去才会被认为已提交。这样就避免了部分数据被写进了Leader，还没来得及被任何Follower复制就宕机了，而造成数据丢失（Consumer无法消费这些数据）。而对于Producer而言，它可以选择是否等待消息commit，这可以通过<code>request.required.acks</code>来设置。这种机制确保了只要ISR有一个或以上的Follower，一条被commit的消息就不会丢失。<br>request.required.acks的三种取值：</p>
<ul>
<li>0:代表生产者producer不需要等待broker同步完成的确认继续发送下一条消息。（当服务器发生故障某些数据会丢失，如leader已死，但producer不知情，发出去的消息broker就收不到）。</li>
<li>1：这意味着producer在leader已成功收到的数据并得到确认后发送下一条message。leader宕机（未与follower同步），可能会丢失数据。</li>
<li>-1：这意味者producer在follow副本确认接受到数据后才算一次发送完成。<br>三种机制，性能一次递减，数据健壮性则一次递增。</li>
</ul>
<p>如何处理所有Replica都不工作？<br>ISR中至少有一个follower时，Kafka可以确保已经commit的数据不丢失，但如果某个Partition的所有Replica都宕机了，就无法保证数据不丢失了。这种情况下有两种可行的方案：</p>
<ul>
<li>等待ISR中的任一个Replica恢复，并且选它作为Leader。</li>
<li>选择第一个恢复的Replica作为Leader。<br>两种方案需要在可用性和一致性当中作出选择。<br>如果一定要等待ISR中的Replica“活”过来，那不可用的时间就可能会相对较长。而且如果ISR中的所有Replica都无法“活”过来了，或者数据都丢失了，这个Partition将永远不可用。<br>选择第一个“活”过来的Replica作为Leader，而这个Replica不是ISR中的Replica，那即使它并不保证已经包含了所有已commit的消息，它也会成为Leader而作为consumer的数据源（前文有说明，所有读写都由Leader完成）。</li>
</ul>
<p>什么原因导致副本follower和leader不一致：</p>
<ul>
<li>慢副本：在一定周期时间内follower不能追赶上leader。最常见的原因之一是I&#x2F;O瓶颈导致follower追加复制消息速度慢于从leader拉取速度。</li>
<li>卡住副本：在一定周期时间内follower停止从leader拉取请求。follower replica卡住了是由于GC暂停或follower失效或死亡。</li>
<li>新启动副本：当用户给主题添加副本因子时，新的follower不在同步副本列表中，直至它们完全追上leader日志。</li>
</ul>
<h2 id="Partition-Recovery机制"><a href="#Partition-Recovery机制" class="headerlink" title="Partition Recovery机制"></a>Partition Recovery机制</h2><p>每个Partition会在磁盘记录一个<strong>RecoveryPoint</strong>，记录已经flush到磁盘的最大offset。当broker fail 重启时,会进行loadLogs首先会读取该Partition的RecoveryPoint,找到包含RecoveryPoint的segment及以后的segment, 这些segment就是可能没有完全flush到磁盘segments。然后调用segment的recover,重新读取各个segment的msg,并重建索引。</p>
<p><strong>Consumer只从Leader拉取数据。</strong></p>
<p>数据可靠性保证：<br>   当Producer向Leader发送数据时，可以通过acks参数设置数据可靠性的级别：</p>
<ul>
<li>0：无论写入是否成功，server不需要给Producer发送Rsponse，如果发生异常，server会终止连接，触发Producer更新meta数据;</li>
<li>1：Leader写入成功后即发送Response，此种情况如果Leader fail，会丢失数据。</li>
<li>-1：等待所有ISR接收到消息后再给Producer发送Response,这是最强保证。<ul>
<li>仅设置acks&#x3D;-1也不能保证数据不丢失,当Isr列表中只有Leader时,同样有可能造成数据丢失。要保证数据不丢除了设置acks&#x3D;-1, 还要保 证ISR的大小大于等于2,具体参数设置:</li>
<li>request.required.acks:设置为-1 等待所有ISR列表中的Replica接收到消息后采算写成功;</li>
<li>min.insync.replicas: 设置为大于等于2,保证ISR中至少有两个Replica（ISR包括leader节点）。</li>
</ul>
</li>
</ul>
<p>数据一致性保证：<br>一致性定义：若某条消息对Consumer可见，那么Leader宕机了，在新Leader上数据依然可以得到。</p>
<ul>
<li>HighWaterMark简称HW: Partition的高水位，取一个partition对应的ISR中最小的LEO作为HW，消费者最多只能消费到HW所在的位置，另外每个replica都有highWatermark，leader和follower各自负责更新自己的highWatermark状态，highWatermark &lt;&#x3D; leader. LogEndOffset</li>
<li>对于Leader新写入的msg，Consumer不能立刻消费，Leader会等待该消息被所有ISR中的replica同步后,更新HW,此时该消息才能被Consumer消费，即Consumer最多只能消费到HW位置</li>
</ul>
<p>对于内部Broker的读取请求，没有HW的限制。Follower也会自己设置一份HW。Folloer.HW &#x3D; min(Leader.HW, Follower.offset)</p>
<p>Kafka集群partitions&#x2F;<a target="_blank" rel="noopener" href="https://blog.csdn.net/lizhitao/article/details/41778193">replicas默认分配解析</a></p>
<p>Kafka中partition replica复制机制：</p>
<blockquote>
<p>Kafka中每个Broker启动时都会创建一个副本管理服务(ReplicaManager)，该服务负责维护ReplicaFetcherThread与其他Broker链路连接关系，该Broker中存在多少Follower的partitions对应leader partitions分布在不同的Broker上，有多少Broker就会创建相同数量的ReplicaFetcherThread线程同步对应partition数据，Kafka中partition间复制数据是由follower(扮演consumer角色)主动向leader获取消息，follower每次读取消息都会更新HW状态。每当Follower的partitions发生变更影响leader所在Broker变化时，ReplicaManager就会新建或销毁相应的ReplicaFetcherThread。</p>
</blockquote>
<h2 id="kafka高可用设置"><a href="#kafka高可用设置" class="headerlink" title="kafka高可用设置"></a>kafka高可用设置</h2><ul>
<li>将所有Replica均匀分布到整个集群，为了更好的做负载均衡，Kafka尽量将所有的Partition均匀分配到整个集群上。一个典型的部署方式是一个Topic的Partition数量大于Broker的数量。<br>Kafka分配Replica的算法如下：</li>
</ul>
<ol>
<li>将所有Broker（假设共n个Broker）和待分配的Partition排序</li>
<li>将第i个Partition分配到第（i mod n）个Broker上</li>
<li>将第i个Partition的第j个Replica分配到第（(i + j) mod n）个Broker上</li>
</ol>
<h2 id="Data-Replication"><a href="#Data-Replication" class="headerlink" title="Data Replication"></a>Data Replication</h2><p>为了提高性能，每个Follower在接收到数据后就立马向Leader发送ACK，而非等到数据写入Log中。因此，对于已经commit的消息，Kafka只能保证它被存于多个Replica的内存中，而不能保证它们被持久化到磁盘中，也就不能完全保证异常发生后该条消息一定能被Consumer消费。但考虑到这种场景非常少见，可以认为这种方式在性能和数据持久化上做了一个比较好的平衡。在将来的版本中，Kafka会考虑提供更高的持久性。</p>
<p>如何选举leader？</p>
<p>Kafka启动时，会在所有broker中选择一个作为controller。<br>创建topic、添加分区、修改副本数量之类的管理任务都是由controller完成。<br>Kafka分区Leader选举也是由controller决定的。<br>在Kafka集群启动的时候，每个broker都会尝试去ZooKeeper上注册成为Controller（ZK临时节点）</p>
<ul>
<li><p>但只有一个竞争成功，其他的broker会注册该节点的监视器</p>
</li>
<li><p>一旦该临时节点状态发生变化，就可以进行相应的处理</p>
</li>
<li><p>Controller也是高可用的，一旦某个broker崩溃，其他的broker会重新注册为Controller</p>
</li>
</ul>
<ol>
<li><p> 所有Partition的leader选举都由controller决定</p>
</li>
<li><p>controller会将leader的改变直接通过RPC的方式通知需为此作出响应的Broker</p>
</li>
<li><p>controller读取到当前分区的ISR，只要有一个Replica还幸存，就选择其中一个作为leader，否则任意选一个Replica作为leader</p>
</li>
<li><p>如果该partition的所有Replica都已经宕机，则新的leader为-1</p>
</li>
</ol>
<h2 id="Broker-failover过程简介"><a href="#Broker-failover过程简介" class="headerlink" title="Broker failover过程简介"></a>Broker failover过程简介</h2><ol>
<li>Controller在Zookeeper注册Watcher，一旦有Broker宕机，其在Zookeeper对应的Znode会自动删除，Zookeeper会fire Controller注册的watch，Controller读取最新的幸存的Broker。</li>
<li>Controller决定set_p，该集合包含了宕机的所有Broker上的所有Parttion。</li>
<li>对set_p中的每一个Partition<ul>
<li>从<code>/brokers/topics/[topic]/partitions/[partition]/state</code>读取该Partition当前的ISR</li>
<li>决定该Partition的新Leader。如果当前ISR中有至少一个Replica还幸存，则选择其中一个作为新Leader，新的ISR则包含当前ISR中所有幸存的Replica。否则选择该Partition中任意一个幸存的Replica作为新的Leader以及ISR（该场景下可能会有潜在的数据丢失）。如果该Partition的所有Replica都宕机了，则将新的Leader设置为-1。</li>
<li>将新的Leader，ISR和新的<code>leader_epoch</code>及<code>controller_epoch</code>写入<code>/brokers/topics/[topic]/partitions/[partition]/state</code>。注意，该操作只有其version在第一步至第三部的过程中无变化时才会执行，否则跳转到第一步</li>
</ul>
</li>
<li>直接通过RPC向set_p相关的Broker，发送LeaderAndISRRequest命令。Controller可以在一个RPC操作中发送多个命令从而提高效率。</li>
</ol>
<h2 id="创建-删除Topic"><a href="#创建-删除Topic" class="headerlink" title="创建&#x2F;删除Topic"></a>创建&#x2F;删除Topic</h2><ol>
<li>Controller在Zookeeper上的<code>/brokers/topics</code>节点上注册Watch，一旦某个Topic被创建或删除，则Controller会通过Watch得到新创建&#x2F;删除的Topic的Partition&#x2F;Replica分配。</li>
<li>对于删除Topic操作，Topic工具会将该Topic名字存于<code>/admin/delete_topics</code>。若<code>delete.topic.enable</code>为true，则Controller注册在<code>/admin/delete_topics</code>上的Watch被fire，Controller通过回调向对应的Broker发送StopReplicaRequest；若为false则Controller不会在<code>/admin/delete_topics</code>上注册Watch，也就不会对该事件作出反应，此时Topic操作只被记录而不会被执行。</li>
<li>对于创建topic操作，Controller会从<code>/brokers/ids</code>读取当前所有可用的Broker列表，对于set_p中的每一个Partition：<ul>
<li>从分配给该Partition的所有Replica（称为AR）中任选一个可用的Broker作为新的Leader，并将AR设置为新的ISR（因为该Topic是新创建的，所以AR中所有的Replica都没有数据，可认为它们都是同步的，也即都在ISR中，任意一个Replica都可作为Leader）</li>
<li>将新的Leader和ISR写入<code>/brokers/topics/[topic]/partitions/[partition]</code></li>
</ul>
</li>
<li>直接通过RPC向相关的Broker发送LeaderAndISRRequest。</li>
</ol>
<h2 id="Broker相应请求流程"><a href="#Broker相应请求流程" class="headerlink" title="Broker相应请求流程"></a>Broker相应请求流程</h2><p>Broker通过<code>kafka.network.SocketServer</code>及相关模块接受各种请求并作出响应。整个网络通信模块基于Java NIO开发，并采用Reactor模式，其中包含<code>1个Acceptor负责接受客户请求，N个Processor负责读写数据，M个Handler处理业务逻辑。</code></p>
<blockquote>
<p>Acceptor的主要职责是监听并接受客户端（请求发起方，包括但不限于Producer，Consumer，Controller，Admin Tool）的连接请求，并建立和客户端的数据传输通道，然后为该客户端指定一个Processor，至此它对该客户端该次请求的任务就结束了，它可以去响应下一个客户端的连接请求了。</p>
</blockquote>
<blockquote>
<p>Processor主要负责从客户端读取数据并将响应返回给客户端，它本身并不处理具体的业务逻辑，并且其内部维护了一个队列来保存分配给它的所有SocketChannel。Processor的run方法会循环从队列中取出新的SocketChannel并将其<code>SelectionKey.OP_READ</code>注册到selector上，然后循环处理已就绪的读（请求）和写（响应）。Processor读取完数据后，将其封装成Request对象并将其交给RequestChannel。</p>
</blockquote>
<blockquote>
<p>RequestChannel是Processor和KafkaRequestHandler交换数据的地方，它包含一个队列requestQueue用来存放Processor加入的Request，KafkaRequestHandler会从里面取出Request来处理；同时它还包含一个respondQueue，用来存放KafkaRequestHandler处理完Request后返还给客户端的Response。</p>
</blockquote>
<blockquote>
<p>Processor会通过processNewResponses方法依次将requestChannel中responseQueue保存的Response取出，并将对应的<code>SelectionKey.OP_WRITE</code>事件注册到selector上。当selector的select方法返回时，对检测到的可写通道，调用write方法将Response返回给客户端。</p>
</blockquote>
<blockquote>
<p>KafkaRequestHandler循环从RequestChannel中取Request并交给<code>kafka.server.KafkaApis</code>处理具体的业务逻辑</p>
</blockquote>
<h2 id="Broker启动过程"><a href="#Broker启动过程" class="headerlink" title="Broker启动过程"></a>Broker启动过程</h2><p>Broker启动后首先根据其ID在Zookeeper的&#x2F;brokers&#x2F;ids创建临时节点。创建成功后Controller的ReplicaStateMachine注册其上的Broker Change Watch会被fire，从而通过回调KafkaController.onBrokerStartup方法完成以下步骤：</p>
<ol>
<li>向所有新启动的Broker发送UpdateMetadataRequest。</li>
<li>将新启动的Broker上的所有Replica设置为OnlineReplica状态，同时这些Broker会为这些Partition启动high watermark线程。</li>
<li>通过partitionStateMachine触发OnlinePartitionStateChange。</li>
</ol>
<h2 id="Controller-Failover"><a href="#Controller-Failover" class="headerlink" title="Controller Failover"></a>Controller Failover</h2><p>Controller也需要Failover。每个Broker都会在Controller Path (<code>/controller</code>)上注册一个Watch。当前Controller失败时，对应的Controller Path会自动消失（因为它是Ephemeral Node），此时该Watch被fire，所有“活”着的Broker都会去竞选成为新的Controller（创建新的Controller Path），但是只会有一个竞选成功（这点由Zookeeper保证）。竞选成功者即为新的Leader，竞选失败者则重新在新的Controller Path上注册Watch。因为<code>Zookeeper的Watch是一次性的，被fire一次之后即失效</code><br>Broker成功竞选为新的Controller后会触发KafkaController.onControllerFailover方法，并在该方法中完成如下操作：</p>
<ol>
<li>读取并增加Controller Epoch。</li>
<li>在ReassignedPartitions Path(<code>/admin/reassign_partitions</code>)上注册Watch。</li>
<li>在PreferredReplicaElection Path(<code>/admin/preferred_replica_election</code>)上注册Watch。</li>
<li>通过partitionStateMachine在Broker Topics Patch(<code>/brokers/topics</code>)上注册Watch。</li>
<li>若<code>delete.topic.enable</code>设置为true（默认值是false），则partitionStateMachine在Delete Topic Patch(<code>/admin/delete_topics</code>)上注册Watch。</li>
<li>通过replicaStateMachine在Broker Ids Patch(<code>/brokers/ids</code>)上注册Watch。</li>
<li>初始化ControllerContext对象，设置当前所有的Topic，“活”着的Broker列表，所有Partition的Leader及ISR等。</li>
<li>启动replicaStateMachine和partitionStateMachine。</li>
<li>将brokerState状态设置为RunningAsController。</li>
<li>将每个Partition的Leadership信息发送给所有“活”着的Broker</li>
<li>若<code>auto.leader.rebalance.enable</code>配置为true（默认值是true），则启动partition-rebalance线程</li>
<li>若<code>delete.topic.enable</code>设置为true且Delete Topic Patch(<code>/admin/delete_topics</code>)中有值，则删除相应的Topic。</li>
</ol>
<h2 id="Partition重新分配"><a href="#Partition重新分配" class="headerlink" title="Partition重新分配"></a>Partition重新分配</h2><p> 管理工具发出重新分配Partition请求后，会将相应信息写到<code>/admin/reassign_partition</code>上，而该操作会触发ReassignedPartitionsIsrChangeListener，从而通过执行回调函数KafkaController.onPartitionReassignment来完成以下操作：</p>
<ol>
<li>将Zookeeper中的AR（Current Assigned Replicas）更新为OAR（Original List of replicas for partition ）+RAR（Reassigned replicas）。</li>
<li>强制更新Zookeeper中leader epoch，向AR中的每个Replica发送LeaderAndIsrRequest。</li>
<li>将RAR - OAR中的Replica设置为NewReplica状态。</li>
<li>等待直到RAR中所有的Replica都与其Leader同步。</li>
<li>将RAR中所有的Replica都设置为OnlineReplica状态。</li>
<li>将Cache中的AR设置为RAR。</li>
<li>若leader不在RAR中，则从RAR中重新选举出一个新的Leader并发送LeaderAndIsrRequest。若新的Leader不是从RAR中选举而来，则还要增加Zookeeper中的leader epoch。</li>
<li>将OAR - RAR中的所有Replica设置为OfflineReplica状态，该过程包含两部分。第一，将Zookeeper上ISR中的OAR - RAR移除并向Leader发送LeaderAndIsrRequest从而通知这些Replica已经从ISR中移除；第二，向OAR - RAR中的Replica发送StopReplicaRequest从而停止不再分配给该Partition的Replica。</li>
<li>将OAR - RAR中的所有Replica设置为NonExistentReplica状态从而将其从磁盘上删除。</li>
<li>将Zookeeper中的AR设置为RAR。</li>
<li>删除<code>/admin/reassign_partition</code></li>
</ol>
<p><strong>注意</strong>：最后一步才将Zookeeper中的AR更新，因为这是唯一一个持久存储AR的地方，如果Controller在这一步之前crash，新的Controller仍然能够继续完成该过程。</p>
<table>
<thead>
<tr>
<th>AR</th>
<th>Leader&#x2F;isr</th>
<th>step</th>
</tr>
</thead>
<tbody><tr>
<td>{1,2,3}</td>
<td>1&#x2F;{1,2,3}</td>
<td>(initial state)</td>
</tr>
<tr>
<td>{1,2,3,4,5,6}</td>
<td>1&#x2F;{1,2,3}</td>
<td>2</td>
</tr>
<tr>
<td>{1,2,3,4,5,6}</td>
<td>1&#x2F;{1,2,3,4,5,6}</td>
<td>4</td>
</tr>
<tr>
<td>{1,2,3,4,5,6}</td>
<td>4&#x2F;{1,2,3,4,5,6}</td>
<td>7</td>
</tr>
<tr>
<td>{1,2,3,4,5,6}</td>
<td>4&#x2F;{1,2,3,4,5,6}</td>
<td>8</td>
</tr>
<tr>
<td>{4,5,6}</td>
<td>4&#x2F;{4,5,6}</td>
<td>10</td>
</tr>
</tbody></table>
<h2 id="Follower从Leader-Fetch数据"><a href="#Follower从Leader-Fetch数据" class="headerlink" title="Follower从Leader Fetch数据"></a>Follower从Leader Fetch数据</h2><p>Follower通过向Leader发送FetchRequest获取消息。</p>
<p>每个Fetch请求都要指定最大等待时间和最小获取字节数，以及由TopicAndPartition和PartitionFetchInfo构成的Map。实际上，Follower从Leader数据和Consumer从Broker Fetch数据，都是通过FetchRequest请求完成，所以在FetchRequest结构中，其中一个字段是clientID，并且其默认值是ConsumerConfig.DefaultClientId。<br>Leader收到Fetch请求后，Kafka通过kafkaApis.handleFetchRequest相应该请求，响应结果如下：</p>
<ol>
<li>replicaManager根据请求读出数据存入dataRead中。</li>
<li>如果该请求来自Follower则更新其相应的LEO（log end offset）以及相应Partition的High Watermark</li>
<li>根据dataRead算出可读消息长度（字节），并存入bytesReadable中。</li>
<li>满足下面4个条件中1个，即立即将对应数据返回：<ul>
<li>Fetch请求不希望等待，即fetchRequest.macWait &lt;&#x3D; 0</li>
<li>fetch请求不要求一定能取到消息，即fetchRequest.numPartitions &lt;&#x3D; 0，也即requestInfo为空</li>
<li>有足够的数据可供返回，即bytesReadable &gt;&#x3D; fetchRequest.minBytes。</li>
<li>读取数据时发生异常。</li>
</ul>
</li>
<li>若不满足以上4个条件，FetchRequest将不会立即返回，并将该请求封装成DelayedFetch。检查该DeplayedFetch是否满足，若满足则返回请求，否则将该请求加入Watch列表 。</li>
</ol>
<h2 id="High-Level-Consumer-Rebalance"><a href="#High-Level-Consumer-Rebalance" class="headerlink" title="High Level Consumer Rebalance"></a>High Level Consumer Rebalance</h2><p>   Kafka保证同一Consumer Group中只有一个Consumer会消费某条消息，实际上，Kafka保证的是稳定状态下每一个Consumer实例只会消费某一个或多个特定Partition的数据，而某个Partition的数据只会被某一个特定的Consumer实例所消费。也就是说Kafka对消息的分配是以Partition为单位分配的，而非以每一条消息作为分配单元。这样设计的劣势是无法保证同一个Consumer Group里的Consumer均匀消费数据，优势是每个Consumer不用都跟大量的Broker通信，减少通信开销，同时也降低了分配难度，实现也更简单。另外，因为同一个Partition里的数据是有序的，这种设计可以保证每个Partition里的数据可以被有序消费。<br>  Consumer Rebalance的算法如下：</p>
<ul>
<li>将目标Topic下的所有Partirtion排序，存于PT集合</li>
<li>对某Consumer Group下所有Consumer排序，存于CG集合，第i个Consumer记为Ci</li>
<li>N&#x3D;size(PT)&#x2F;size(CG)，向上取整</li>
<li>解除Ci对原来分配的Partition的消费权（i从0开始）</li>
<li>将第i* N 到（i+1）* N-1个Partition分配个Ci。<br>  在这种策略下，每一个Consumer或者Broker的增加或者减少都会出发Consumer Rebalance。每个Consumer只负责调整自己所消费的Partition，为了保证整个Consumer Group的一致性，当一个Consumer出发Rebalance时，该Consumer Group的其它所有Consumer也应该同时出发Rebalance。有以下缺点：</li>
<li>Herd effect：任何Broker或者Consumer的增减都会触发所有Consumer的Rebalance。</li>
<li>Split Brain：每个Consumer分别单独通过Zookeeper判断哪些Broker和Consumer宕机了，那么不同Consumer在同一时刻从Zookeeper看到的View就可能不一样，这就<strong>可能造成不正确的Reblance尝试。</strong></li>
<li>调节结果不可控：所有Consumer都并不知道其他Consumer的Rebalance是否正确，这可能会导致Kafka工作在一个不正确的状态。<br>0.9以后的版本，提供了coordinator来解决上述缺点</li>
</ul>
<h3 id="coordinator和Rebalance"><a href="#coordinator和Rebalance" class="headerlink" title="coordinator和Rebalance"></a>coordinator和Rebalance</h3><p>新的consumer加入组、已有consumer主动离开组或已有consumer崩溃的时候会出发rebalance。每个consumer group都会分配一个coordinate用于组管理和位移管理。<br>这个group coordinator比原来承担了更多的责任，比如组成员管理、位移提交保护机制等。当consumer group的consumer启动时，他会去和kafka server确定谁是它们组的coordinate，之后该group内所有成员都会和coordinate进行协调通信。<strong>这种coordinator设计不再需要zookeeper了，性能得到很大提升，</strong>,topic的group消费offset信息由之前存在在zookeeper改为存储到一个特殊的topic(__consumer_offsets)中。<br>如何确定coordinator？</p>
<blockquote>
<p>组内第一个消费者向kafka集群中任意一个broker发送一个GroupCoordinatorRequest请求，服务端会返回一个负载最小的broker节点的id，并将该broker设置为coordinator。<br>consumer group的位移信息写入哪个consumer_offsets_*，那么其分区leader所在broker就是coordinator。</p>
</blockquote>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4a05cdf2a79b4dabb7e3228772e15ecc~tplv-k3u1fbpfcp-watermark.image" alt="1090328-20180325204859717-628914897.png"><br>generation用来标识rebalance之后的一代成员，主要用于保护consumer group，隔离无效offset提交的。比如上一代的consumer成员无法提交位移到下一代consumer group，会报ILLEGAL_GENERATION错误。每次rebalance之后，generation+1.<br>kafka采用五个协议来处理consumer group coordination问题。</p>
<ul>
<li>Hearbeat请求：consumer需要定期给coordinator发送心跳来表明自己还活着。</li>
<li>leavegroup请求：主动告诉coordinator我要离开consumer group。</li>
<li>syncgroup请求：group leader（第一个加入group的消费者）把分配方案告诉组内所有成员。</li>
<li>joingroup请求：成员请求加入组。</li>
<li>descibegroup：显示组的所有信息，包括成员信息，协议名称，分配方案、订阅信息等。<br>group的五种状态：</li>
<li>dead：组内已经没有任何成员的最终状态，组的元数据信息也已经被coordinator移除。这种状态响应各种请求都是一个response，UNHNOWN_MEMBER_ID.</li>
<li>empty：组内无成员，但是位移信息还没有过期，这种状态只能响应joingroup请求。如果所有offsets都过期的话就会变成Dead。</li>
<li>preparingRebalance：组准备开始新的rebalance，等待成员加入。</li>
<li>awatingsync:正在等待group leader 分配方案给各个成员。</li>
<li>stable：稳定的状态</li>
</ul>
<p>具体过程<br>加入（join）</p>
<blockquote>
<p>加入组，这一步所有成员都向coordinator发送JoinGroup请求，请求入组。一旦所有成员都发送了joinGroup请求，coordinator会从中选择一个consumer担任leader的角色，coordinator和consumer leader不是一个概念，Leader负责消费方案的执行。<br>同步（sync）<br>group leader开始分配消费方案，即哪个consumer负责消费哪些topic的哪些partition.一旦完成分配，leader会将这个方案封装进syncGroup请求发送给coordinator，非leader也会发syncGroup请求，只是内容为空。coordinator接受到分配方案之后会把方案塞进syncGroup的response发送给各个consumer，这样组内的成员都直到自己应该消费哪些分区。<br>新增consumer：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9f5f142e5e954f528d3e3c1c4cd8b089~tplv-k3u1fbpfcp-watermark.image" alt="1090328-20180325210104510-1347478045.png"><br>移除consumer：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c66dca837b8a47f0881708058ce0f8b3~tplv-k3u1fbpfcp-watermark.image" alt="1090328-20180325210207426-402986818.png"><br>consumer崩掉</p>
</blockquote>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/99bb467b49f9409f8f508fc812e9bf3b~tplv-k3u1fbpfcp-watermark.image" alt="1090328-20180325210257134-13000529.png"></p>
<h2 id="High-Level-Consumer"><a href="#High-Level-Consumer" class="headerlink" title="High Level Consumer"></a>High Level Consumer</h2><p>  客户端只希望从Kafka顺序读取并处理数据，而不太关心具体的offset。也希望提供一些语义，例如同一条消息只被某一个consumer消息（单播）或被所有consumer消息。<br>  kafka high level API提供一个从Kafka消费数据的高层抽象，从而屏蔽掉其中的细节，并提供丰富的语义。</p>
<ol>
<li>ConsumerGroup：consumer group下订阅的topic下的每个分区只能分配给某个group下的一个consumer。High level consumer将从某个partition读取最后一条信息的offset存储于zookeeper中。consumer group是整个kafka集群全局唯一的，而非针对某个topic。<blockquote>
<p>kafka消费完的数据不会被立即删除，可以选择立即删除或者对数据进行压缩。</p>
</blockquote>
</li>
</ol>
<h2 id="Low-Level-Consumer"><a href="#Low-Level-Consumer" class="headerlink" title="Low Level Consumer"></a>Low Level Consumer</h2><p>   使用Low Level Consumer的主要原因是，用户希望比Consumer Group更好的控制数据的消费。比如：</p>
<ul>
<li><p>同一条消息读多次</p>
</li>
<li><p>只读取某个Topic的部分Partition。</p>
</li>
<li><p><strong>管理事务</strong>，从而确保每条消息被处理一次，且仅被处理一次。<br>   与Consumer Group相比，Low Level Consumer要求用户做大量的额外工作。</p>
</li>
<li><p>必须在应用程序中跟踪offset，从而确定下一条应该消费哪条信息。</p>
</li>
<li><p>应用程序需要通过程序获知每个Partition的Leader是谁</p>
</li>
<li><p>必须处理Leader的变化<br>   使用Low Level Consumer的一般流程如下：</p>
</li>
<li><p>查找到一个“活着”的Broker，并且找出每个Partition的Leader。</p>
</li>
<li><p>找出每个Partition的Follower。</p>
</li>
<li><p>定义好请求，该请求应该能描述应用程序需要哪些数据。</p>
</li>
<li><p>Fetch数据。</p>
</li>
<li><p>识别Leader的变化，并对之作出必要的响应。</p>
</li>
</ul>
<h2 id="如何通过中心Coordinator实现Rebalance"><a href="#如何通过中心Coordinator实现Rebalance" class="headerlink" title="如何通过中心Coordinator实现Rebalance"></a>如何通过中心Coordinator实现Rebalance</h2><p>　　成功Rebalance的结果是，被订阅的所有Topic的每一个Partition将会被Consumer Group内的一个（有且仅有一个）Consumer拥有。每一个Broker将被选举为某些Consumer Group的Coordinator。某个Cosnumer Group的Coordinator负责在该Consumer Group的成员变化或者所订阅的Topic的Partititon变化时协调Rebalance操作。</p>
</article><div class="post-copyright"><div class="copyright-cc-box"><i class="anzhiyufont anzhiyu-icon-copyright"></i></div><div class="post-copyright__author_box"><a class="post-copyright__author_img" href="/yangxiao.github.io/" title="头像"><img class="post-copyright__author_img_back" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/yangxiao.github.io/img/headimg.jpg" title="头像" alt="头像"><img class="post-copyright__author_img_front" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/yangxiao.github.io/img/headimg.jpg" title="头像" alt="头像"></a><div class="post-copyright__author_name">XIAO YANG</div><div class="post-copyright__author_desc">笔记</div></div><div class="post-copyright__post__info"><a class="post-copyright__original" title="该文章为原创文章，注意版权协议" href="https://yangxiao23.github.io/yangxiao.github.io/2023/12/20/kafka/">原创</a><a class="post-copyright-title"><span onclick="rm.copyPageUrl('https://yangxiao23.github.io/yangxiao.github.io/2023/12/20/kafka/')">Kafka</span></a></div><div class="post-tools" id="post-tools"><div class="post-tools-left"><div class="rewardLeftButton"></div><div class="shareRight"><div class="share-link mobile"><div class="share-qrcode"><div class="share-button" title="使用手机访问这篇文章"><i class="anzhiyufont anzhiyu-icon-qrcode"></i></div><div class="share-main"><div class="share-main-all"><div id="qrcode" title="https://yangxiao23.github.io/yangxiao.github.io/2023/12/20/kafka/"></div><div class="reward-dec">使用手机访问这篇文章</div></div></div></div></div><div class="share-link weibo"><a class="share-button" target="_blank" href="https://service.weibo.com/share/share.php?title=Kafka&amp;url=https://yangxiao23.github.io/yangxiao.github.io/2023/12/20/kafka/&amp;pic=" rel="external nofollow noreferrer noopener"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a></div><script>function copyCurrentPageUrl() {
  var currentPageUrl = window.location.href;
  var input = document.createElement("input");
  input.setAttribute("value", currentPageUrl);
  document.body.appendChild(input);
  input.select();
  input.setSelectionRange(0, 99999);
  document.execCommand("copy");
  document.body.removeChild(input);
}</script><div class="share-link copyurl"><div class="share-button" id="post-share-url" title="复制链接" onclick="copyCurrentPageUrl()"><i class="anzhiyufont anzhiyu-icon-link"></i></div></div></div></div></div><div class="post-copyright__notice"><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://yangxiao23.github.io/yangxiao.github.io" target="_blank">后端开发</a>！</span></div></div><div class="post-tools-right"><div class="tag_share"><div class="post-meta__box"><div class="post-meta__box__tag-list"><a class="post-meta__box__tags" href="/yangxiao.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>中间件<span class="tagsPageCount">3</span></a><a class="post-meta__box__tags" href="/yangxiao.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>分布式<span class="tagsPageCount">1</span></a></div></div><div class="post_share"><div class="social-share" data-image="/yangxiao.github.io/img/headimg.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"/><script src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer="defer"></script></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/yangxiao.github.io/2023/12/19/test/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/yangxiao.github.io/" onerror="onerror=null;src='/yangxiao.github.io/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">test</div></div></a></div><div class="next-post pull-right"><a href="/yangxiao.github.io/2023/12/20/Mysql/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/yangxiao.github.io/" onerror="onerror=null;src='/yangxiao.github.io/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Mysql</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="anzhiyufont anzhiyu-icon-thumbs-up fa-fw" style="font-size: 1.5rem; margin-right: 4px"></i><span>喜欢这篇文章的人也看了</span></div><div class="relatedPosts-list"><div><a href="/yangxiao.github.io/2023/12/26/ElasticSearch/" title="ElasticSearch"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/yangxiao.github.io/" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2023-12-26</div><div class="title">ElasticSearch</div></div></a></div><div><a href="/yangxiao.github.io/2023/12/20/Mysql/" title="Mysql"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/yangxiao.github.io/" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2023-12-20</div><div class="title">Mysql</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-content"><div class="author-info__sayhi" id="author-info__sayhi" onclick="anzhiyu.changeSayHelloText()"></div><div class="author-info-avatar"><img class="avatar-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/yangxiao.github.io/img/headimg.jpg" onerror="this.onerror=null;this.src='/yangxiao.github.io/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__description">后端开发记录</div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bars"></i><span>文章目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Kafka"><span class="toc-number">1.</span> <span class="toc-text">Kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#kafka%E6%80%BB%E4%BD%93%E6%A6%82%E8%A7%88"><span class="toc-number">1.1.</span> <span class="toc-text">kafka总体概览</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE"><span class="toc-number">1.2.</span> <span class="toc-text">服务端参数配置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E7%9B%B8%E5%85%B3"><span class="toc-number">1.3.</span> <span class="toc-text">生产者相关</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%8F%E5%88%97%E5%8C%96%E5%99%A8"><span class="toc-number">1.3.1.</span> <span class="toc-text">序列化器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%E5%99%A8"><span class="toc-number">1.3.2.</span> <span class="toc-text">分区器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8B%A6%E6%88%AA%E5%99%A8"><span class="toc-number">1.3.3.</span> <span class="toc-text">拦截器</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kafka%E7%94%9F%E4%BA%A7%E8%80%85%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%8E%9F%E7%90%86"><span class="toc-number">1.4.</span> <span class="toc-text">kafka生产者客户端原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%83%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9B%B4%E6%96%B0"><span class="toc-number">1.4.1.</span> <span class="toc-text">元数据的更新</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E9%87%8D%E8%A6%81%E5%8F%82%E6%95%B0"><span class="toc-number">1.4.2.</span> <span class="toc-text">生产者重要参数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E5%92%8C%E6%B6%88%E8%B4%B9%E7%BB%84"><span class="toc-number">1.5.</span> <span class="toc-text">消费者和消费组</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%BC%80%E5%8F%91"><span class="toc-number">1.6.</span> <span class="toc-text">客户端开发</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BF%85%E8%A6%81%E7%9A%84%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE"><span class="toc-number">1.6.1.</span> <span class="toc-text">必要的参数配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A2%E9%98%85%E4%B8%BB%E9%A2%98%E5%92%8C%E5%88%86%E5%8C%BA"><span class="toc-number">1.6.2.</span> <span class="toc-text">订阅主题和分区</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96"><span class="toc-number">1.6.3.</span> <span class="toc-text">反序列化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E6%B6%88%E8%B4%B9"><span class="toc-number">1.6.4.</span> <span class="toc-text">消费者消费</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%8D%E7%A7%BB%E6%8F%90%E4%BA%A4"><span class="toc-number">1.6.5.</span> <span class="toc-text">位移提交</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%A7%E5%88%B6%E6%88%96%E5%85%B3%E9%97%AD%E6%B6%88%E8%B4%B9"><span class="toc-number">1.6.6.</span> <span class="toc-text">控制或关闭消费</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%87%E5%AE%9A%E4%BD%8D%E7%A7%BB%E6%B6%88%E8%B4%B9"><span class="toc-number">1.6.7.</span> <span class="toc-text">指定位移消费</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%8D%E5%9D%87%E8%A1%A1"><span class="toc-number">1.6.8.</span> <span class="toc-text">再均衡</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E6%8B%A6%E6%88%AA%E5%99%A8"><span class="toc-number">1.6.9.</span> <span class="toc-text">消费者拦截器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E9%87%8D%E8%A6%81%E5%8F%82%E6%95%B0"><span class="toc-number">1.6.10.</span> <span class="toc-text">消费者重要参数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BB%E9%A2%98%E5%92%8C%E5%88%86%E5%8C%BA"><span class="toc-number">1.7.</span> <span class="toc-text">主题和分区</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E9%A2%98%E7%9A%84%E7%AE%A1%E7%90%86"><span class="toc-number">1.7.1.</span> <span class="toc-text">主题的管理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E4%B8%BB%E9%A2%98"><span class="toc-number">1.7.1.1.</span> <span class="toc-text">创建主题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%E5%89%AF%E6%9C%AC%E7%9A%84%E5%88%86%E9%85%8D"><span class="toc-number">1.7.1.2.</span> <span class="toc-text">分区副本的分配</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E4%B8%BB%E9%A2%98"><span class="toc-number">1.7.1.3.</span> <span class="toc-text">查看主题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E4%B8%BB%E9%A2%98"><span class="toc-number">1.7.1.4.</span> <span class="toc-text">修改主题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86"><span class="toc-number">1.7.1.5.</span> <span class="toc-text">配置管理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%A0%E9%99%A4%E4%B8%BB%E9%A2%98"><span class="toc-number">1.7.1.6.</span> <span class="toc-text">删除主题</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9D%E8%AF%86KafkaAdminClient"><span class="toc-number">1.8.</span> <span class="toc-text">初识KafkaAdminClient</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E9%A2%98%E5%90%88%E6%B3%95%E6%80%A7%E9%AA%8C%E8%AF%81"><span class="toc-number">1.8.1.</span> <span class="toc-text">主题合法性验证</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%E7%9A%84%E7%AE%A1%E7%90%86"><span class="toc-number">1.9.</span> <span class="toc-text">分区的管理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E5%85%88%E5%89%AF%E6%9C%AC%E7%9A%84%E9%80%89%E4%B8%BE"><span class="toc-number">1.9.1.</span> <span class="toc-text">优先副本的选举</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%E9%87%8D%E5%88%86%E9%85%8D"><span class="toc-number">1.9.2.</span> <span class="toc-text">分区重分配</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%8D%E5%88%B6%E9%99%90%E6%B5%81"><span class="toc-number">1.9.3.</span> <span class="toc-text">复制限流</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E5%89%AF%E6%9C%AC%E5%9B%A0%E5%AD%90"><span class="toc-number">1.9.4.</span> <span class="toc-text">修改副本因子</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E5%88%86%E5%8C%BA%E6%95%B0"><span class="toc-number">1.9.5.</span> <span class="toc-text">如何选择合适的分区数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8"><span class="toc-number">1.10.</span> <span class="toc-text">日志存储</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%87%E4%BB%B6%E7%9B%AE%E5%BD%95%E5%B8%83%E5%B1%80"><span class="toc-number">1.10.1.</span> <span class="toc-text">文件目录布局</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E5%8E%8B%E7%BC%A9"><span class="toc-number">1.10.2.</span> <span class="toc-text">消息压缩</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A5%E5%BF%97%E7%B4%A2%E5%BC%95"><span class="toc-number">1.10.3.</span> <span class="toc-text">日志索引</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%81%8F%E7%A7%BB%E9%87%8F%E7%B4%A2%E5%BC%95"><span class="toc-number">1.10.3.1.</span> <span class="toc-text">偏移量索引</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%97%B6%E9%97%B4%E6%88%B3%E7%B4%A2%E5%BC%95"><span class="toc-number">1.10.3.2.</span> <span class="toc-text">时间戳索引</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A5%E5%BF%97%E6%B8%85%E7%90%86"><span class="toc-number">1.10.4.</span> <span class="toc-text">日志清理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%97%A5%E5%BF%97%E5%88%A0%E9%99%A4"><span class="toc-number">1.10.4.1.</span> <span class="toc-text">日志删除</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%97%A5%E5%BF%97%E5%8E%8B%E7%BC%A9"><span class="toc-number">1.10.4.2.</span> <span class="toc-text">日志压缩</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A3%81%E7%9B%98%E5%AD%98%E5%82%A8"><span class="toc-number">1.10.5.</span> <span class="toc-text">磁盘存储</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A1%B5%E7%BC%93%E5%AD%98"><span class="toc-number">1.10.5.1.</span> <span class="toc-text">页缓存</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A3%81%E7%9B%98I-O%E6%B5%81%E7%A8%8B"><span class="toc-number">1.10.5.2.</span> <span class="toc-text">磁盘I&#x2F;O流程</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#NOOP"><span class="toc-number">1.10.5.2.1.</span> <span class="toc-text">NOOP</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#CFQ"><span class="toc-number">1.10.5.2.2.</span> <span class="toc-text">CFQ</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#DEADLINE"><span class="toc-number">1.10.5.2.3.</span> <span class="toc-text">DEADLINE</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#ANTICIPATORY"><span class="toc-number">1.10.5.2.4.</span> <span class="toc-text">ANTICIPATORY</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%B6%E6%8B%B7%E8%B4%9D"><span class="toc-number">1.10.5.3.</span> <span class="toc-text">零拷贝</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B7%B1%E5%85%A5%E6%9C%8D%E5%8A%A1%E7%AB%AF"><span class="toc-number">1.11.</span> <span class="toc-text">深入服务端</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%8F%E8%AE%AE%E8%AE%BE%E8%AE%A1"><span class="toc-number">1.11.1.</span> <span class="toc-text">协议设计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%B6%E9%97%B4%E8%BD%AE"><span class="toc-number">1.11.2.</span> <span class="toc-text">时间轮</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BB%B6%E6%97%B6%E6%93%8D%E4%BD%9C"><span class="toc-number">1.11.3.</span> <span class="toc-text">延时操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%A7%E5%88%B6%E5%99%A8"><span class="toc-number">1.11.4.</span> <span class="toc-text">控制器</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8E%A7%E5%88%B6%E5%99%A8%E7%9A%84%E9%80%89%E4%B8%BE%E5%8F%8A%E5%BC%82%E5%B8%B8%E6%81%A2%E5%A4%8D"><span class="toc-number">1.11.4.1.</span> <span class="toc-text">控制器的选举及异常恢复</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E5%8C%BAleader%E7%9A%84%E9%80%89%E4%B8%BE"><span class="toc-number">1.11.4.2.</span> <span class="toc-text">分区leader的选举</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E5%90%AB%E4%B9%89"><span class="toc-number">1.11.5.</span> <span class="toc-text">参数含义</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kafka%E5%AE%A2%E6%88%B7%E7%AB%AF"><span class="toc-number">1.12.</span> <span class="toc-text">kafka客户端</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E9%85%8D%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5"><span class="toc-number">1.12.1.</span> <span class="toc-text">分配分区策略</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#RangeAssignor%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5"><span class="toc-number">1.12.1.1.</span> <span class="toc-text">RangeAssignor分配策略</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#RoundRobinAssignor%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5"><span class="toc-number">1.12.1.2.</span> <span class="toc-text">RoundRobinAssignor分配策略</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#StickyAssignor%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5"><span class="toc-number">1.12.1.3.</span> <span class="toc-text">StickyAssignor分配策略</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5"><span class="toc-number">1.12.1.4.</span> <span class="toc-text">自定义分区分配策略</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E5%8D%8F%E8%B0%83%E5%99%A8%E5%92%8C%E7%BB%84%E5%8D%8F%E8%B0%83%E5%99%A8"><span class="toc-number">1.12.2.</span> <span class="toc-text">消费者协调器和组协调器</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%8D%E5%9D%87%E8%A1%A1%E7%9A%84%E5%8E%9F%E7%90%86"><span class="toc-number">1.12.2.1.</span> <span class="toc-text">再均衡的原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%89%E4%B8%BE%E6%B6%88%E8%B4%B9%E7%BB%84%E4%B8%AD%E7%9A%84leader"><span class="toc-number">1.12.2.2.</span> <span class="toc-text">选举消费组中的leader</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%89%E4%B8%BE%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5"><span class="toc-number">1.12.2.3.</span> <span class="toc-text">选举分区分配策略</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#consumer-offsets%E4%B8%BB%E9%A2%98"><span class="toc-number">1.12.3.</span> <span class="toc-text">consumer_offsets主题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8B%E5%8A%A1"><span class="toc-number">1.12.4.</span> <span class="toc-text">事务</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B9%82%E7%AD%89"><span class="toc-number">1.12.4.1.</span> <span class="toc-text">幂等</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8B%E5%8A%A1-1"><span class="toc-number">1.12.4.2.</span> <span class="toc-text">事务</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%AF%E9%9D%A0%E6%80%A7"><span class="toc-number">1.13.</span> <span class="toc-text">可靠性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%AF%E6%9C%AC%E5%88%A8%E6%9E%90"><span class="toc-number">1.13.1.</span> <span class="toc-text">副本刨析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#ISR%E7%9A%84%E4%BC%B8%E7%BC%A9"><span class="toc-number">1.13.1.1.</span> <span class="toc-text">ISR的伸缩</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A5%E5%BF%97%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6"><span class="toc-number">1.13.2.</span> <span class="toc-text">日志同步机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kafka%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8"><span class="toc-number">1.13.3.</span> <span class="toc-text">kafka高级应用</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4%EF%BC%88TTL%EF%BC%89"><span class="toc-number">1.13.3.1.</span> <span class="toc-text">过期时间（TTL）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BB%B6%E6%97%B6%E9%98%9F%E5%88%97"><span class="toc-number">1.13.3.2.</span> <span class="toc-text">延时队列</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E8%B7%AF%E7%94%B1"><span class="toc-number">1.13.3.3.</span> <span class="toc-text">消息路由</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E8%BD%A8%E8%BF%B9"><span class="toc-number">1.13.3.4.</span> <span class="toc-text">消息轨迹</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka%E7%AE%80%E4%BB%8B"><span class="toc-number">1.14.</span> <span class="toc-text">Kafka简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kafka%E6%B6%88%E6%81%AF%E5%88%A0%E9%99%A4%E6%9C%BA%E5%88%B6"><span class="toc-number">1.15.</span> <span class="toc-text">kafka消息删除机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Producer%E6%B6%88%E6%81%AF%E8%B7%AF%E7%94%B1"><span class="toc-number">1.16.</span> <span class="toc-text">Producer消息路由</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Push-vs-Pull"><span class="toc-number">1.17.</span> <span class="toc-text">Push vs Pull</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kafka%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6"><span class="toc-number">1.18.</span> <span class="toc-text">kafka副本同步机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Partition-Recovery%E6%9C%BA%E5%88%B6"><span class="toc-number">1.19.</span> <span class="toc-text">Partition Recovery机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kafka%E9%AB%98%E5%8F%AF%E7%94%A8%E8%AE%BE%E7%BD%AE"><span class="toc-number">1.20.</span> <span class="toc-text">kafka高可用设置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Data-Replication"><span class="toc-number">1.21.</span> <span class="toc-text">Data Replication</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Broker-failover%E8%BF%87%E7%A8%8B%E7%AE%80%E4%BB%8B"><span class="toc-number">1.22.</span> <span class="toc-text">Broker failover过程简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA-%E5%88%A0%E9%99%A4Topic"><span class="toc-number">1.23.</span> <span class="toc-text">创建&#x2F;删除Topic</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Broker%E7%9B%B8%E5%BA%94%E8%AF%B7%E6%B1%82%E6%B5%81%E7%A8%8B"><span class="toc-number">1.24.</span> <span class="toc-text">Broker相应请求流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Broker%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B"><span class="toc-number">1.25.</span> <span class="toc-text">Broker启动过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Controller-Failover"><span class="toc-number">1.26.</span> <span class="toc-text">Controller Failover</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Partition%E9%87%8D%E6%96%B0%E5%88%86%E9%85%8D"><span class="toc-number">1.27.</span> <span class="toc-text">Partition重新分配</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Follower%E4%BB%8ELeader-Fetch%E6%95%B0%E6%8D%AE"><span class="toc-number">1.28.</span> <span class="toc-text">Follower从Leader Fetch数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#High-Level-Consumer-Rebalance"><span class="toc-number">1.29.</span> <span class="toc-text">High Level Consumer Rebalance</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#coordinator%E5%92%8CRebalance"><span class="toc-number">1.29.1.</span> <span class="toc-text">coordinator和Rebalance</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#High-Level-Consumer"><span class="toc-number">1.30.</span> <span class="toc-text">High Level Consumer</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Low-Level-Consumer"><span class="toc-number">1.31.</span> <span class="toc-text">Low Level Consumer</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87%E4%B8%AD%E5%BF%83Coordinator%E5%AE%9E%E7%8E%B0Rebalance"><span class="toc-number">1.32.</span> <span class="toc-text">如何通过中心Coordinator实现Rebalance</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-history"></i><span>最近发布</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/yangxiao.github.io/2023/12/26/ElasticSearch/" title="ElasticSearch">ElasticSearch</a><time datetime="2023-12-25T16:03:26.971Z" title="发表于 2023-12-26 00:03:26">2023-12-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/yangxiao.github.io/2023/12/20/Mysql/" title="Mysql">Mysql</a><time datetime="2023-12-20T14:48:43.327Z" title="发表于 2023-12-20 22:48:43">2023-12-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/yangxiao.github.io/2023/12/20/kafka/" title="Kafka">Kafka</a><time datetime="2023-12-20T14:48:08.499Z" title="发表于 2023-12-20 22:48:08">2023-12-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/yangxiao.github.io/2023/12/19/test/" title="test">test</a><time datetime="2023-12-19T13:18:38.000Z" title="发表于 2023-12-19 21:18:38">2023-12-19</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/yangxiao.github.io/2023/12/18/hello-world/" title="Hello World">Hello World</a><time datetime="2023-12-18T14:51:37.606Z" title="发表于 2023-12-18 22:51:37">2023-12-18</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"></div><div id="footer-bar"><div class="footer-bar-links"><div class="footer-bar-left"><div id="footer-bar-tips"><div class="copyright">&copy;2020 - 2023 By <a class="footer-bar-link" href="/yangxiao.github.io/" title="XIAO YANG" target="_blank">XIAO YANG</a></div></div><div id="footer-type-tips"></div></div><div class="footer-bar-right"><a class="footer-bar-link" target="_blank" rel="noopener" href="https://github.com/anzhiyu-c/hexo-theme-anzhiyu" title="主题">主题</a></div></div></div></footer></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="sidebar-site-data site-data is-center"><a href="/yangxiao.github.io/archives/" title="archive"><div class="headline">文章</div><div class="length-num">5</div></a><a href="/yangxiao.github.io/tags/" title="tag"><div class="headline">标签</div><div class="length-num">5</div></a><a href="/yangxiao.github.io/categories/" title="category"><div class="headline">分类</div><div class="length-num">2</div></a></div><span class="sidebar-menu-item-title">功能</span><div class="sidebar-menu-item"><a class="darkmode_switchbutton menu-child" href="javascript:void(0);" title="显示模式"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span>显示模式</span></a></div><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://blog.anheyu.com/" title="博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/favicon.ico" alt="博客"/><span class="back-menu-item-text">博客</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">项目</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://image.anheyu.com/" title="安知鱼图床"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://image.anheyu.com/favicon.ico" alt="安知鱼图床"/><span class="back-menu-item-text">安知鱼图床</span></a></div></div></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/yangxiao.github.io/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/yangxiao.github.io/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/yangxiao.github.io/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/yangxiao.github.io/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于本人</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/yangxiao.github.io/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="javascript:toRandomPost()"><i class="anzhiyufont anzhiyu-icon-shoe-prints1 faa-tada" style="font-size: 0.9em;"></i><span> 随便逛逛</span></a></li></ul></div></div><span class="sidebar-menu-item-title">标签</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/yangxiao.github.io/tags/Mysql/" style="font-size: 0.88rem;">Mysql<sup>1</sup></a><a href="/yangxiao.github.io/tags/test/" style="font-size: 0.88rem;">test<sup>1</sup></a><a href="/yangxiao.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/" style="font-size: 0.88rem;">中间件<sup>3</sup></a><a href="/yangxiao.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 0.88rem;">分布式<sup>1</sup></a><a href="/yangxiao.github.io/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/" style="font-size: 0.88rem;">搜索引擎<sup>1</sup></a></div></div><hr/></div></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="anzhiyufont anzhiyu-icon-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="anzhiyufont anzhiyu-icon-gear"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></button></div></div><div id="nav-music"><a id="nav-music-hoverTips" onclick="anzhiyu.musicToggle()" accesskey="m">播放音乐</a><div id="console-music-bg"></div><meting-js id="8152976493" server="netease" type="playlist" mutex="true" preload="none" theme="var(--anzhiyu-main)" data-lrctype="0" order="random" volume="0.7"></meting-js></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="anzhiyufont anzhiyu-icon-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="anzhiyufont anzhiyu-icon-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right" style="font-size: 1rem;"></i></div><div class="rightMenu-item" id="menu-top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></div></div><div class="rightMenu-group rightMenu-line rightMenuPlugin"><div class="rightMenu-item" id="menu-copytext"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制选中文本</span></div><div class="rightMenu-item" id="menu-pastetext"><i class="anzhiyufont anzhiyu-icon-paste"></i><span>粘贴文本</span></div><a class="rightMenu-item" id="menu-commenttext"><i class="anzhiyufont anzhiyu-icon-comment-medical"></i><span>引用到评论</span></a><div class="rightMenu-item" id="menu-newwindow"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开</span></div><div class="rightMenu-item" id="menu-copylink"><i class="anzhiyufont anzhiyu-icon-link"></i><span>复制链接地址</span></div><div class="rightMenu-item" id="menu-copyimg"><i class="anzhiyufont anzhiyu-icon-images"></i><span>复制此图片</span></div><div class="rightMenu-item" id="menu-downloadimg"><i class="anzhiyufont anzhiyu-icon-download"></i><span>下载此图片</span></div><div class="rightMenu-item" id="menu-newwindowimg"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开图片</span></div><div class="rightMenu-item" id="menu-search"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>站内搜索</span></div><div class="rightMenu-item" id="menu-searchBaidu"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>百度搜索</span></div><div class="rightMenu-item" id="menu-music-toggle"><i class="anzhiyufont anzhiyu-icon-play"></i><span>播放音乐</span></div><div class="rightMenu-item" id="menu-music-back"><i class="anzhiyufont anzhiyu-icon-backward"></i><span>切换到上一首</span></div><div class="rightMenu-item" id="menu-music-forward"><i class="anzhiyufont anzhiyu-icon-forward"></i><span>切换到下一首</span></div><div class="rightMenu-item" id="menu-music-playlist" onclick="window.open(&quot;https://y.qq.com/n/ryqq/playlist/8802438608&quot;, &quot;_blank&quot;);" style="display: none;"><i class="anzhiyufont anzhiyu-icon-radio"></i><span>查看所有歌曲</span></div><div class="rightMenu-item" id="menu-music-copyMusicName"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制歌名</span></div></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" id="menu-randomPost"><i class="anzhiyufont anzhiyu-icon-shuffle"></i><span>随便逛逛</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="anzhiyufont anzhiyu-icon-cube"></i><span>博客分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item" id="menu-copy" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制地址</span></a><a class="rightMenu-item" id="menu-commentBarrage" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-message"></i><span class="menu-commentBarrage-text">关闭热评</span></a><a class="rightMenu-item" id="menu-darkmode" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span class="menu-darkmode-text">深色模式</span></a><a class="rightMenu-item" id="menu-translate" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-language"></i><span>轉為繁體</span></a></div></div><div id="rightmenu-mask"></div><div><script src="/yangxiao.github.io/js/utils.js"></script><script src="/yangxiao.github.io/js/main.js"></script><script src="/yangxiao.github.io/js/tw_cn.js"></script><script src="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.umd.js"></script><script src="https://cdn.cbd.int/instant.page@5.2.0/instantpage.js" type="module"></script><script src="https://cdn.cbd.int/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script src="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.js"></script><canvas id="universe"></canvas><script async src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/dark/dark.js"></script><script>// 消除控制台打印
var HoldLog = console.log;
console.log = function () {};
let now1 = new Date();
queueMicrotask(() => {
  const Log = function () {
    HoldLog.apply(console, arguments);
  }; //在恢复前输出日志
  const grt = new Date("04/01/2021 00:00:00"); //此处修改你的建站时间或者网站上线时间
  now1.setTime(now1.getTime() + 250);
  const days = (now1 - grt) / 1000 / 60 / 60 / 24;
  const dnum = Math.floor(days);
  const ascll = [
    `欢迎使用安知鱼!`,
    `生活明朗, 万物可爱`,
    `
        
       █████╗ ███╗   ██╗███████╗██╗  ██╗██╗██╗   ██╗██╗   ██╗
      ██╔══██╗████╗  ██║╚══███╔╝██║  ██║██║╚██╗ ██╔╝██║   ██║
      ███████║██╔██╗ ██║  ███╔╝ ███████║██║ ╚████╔╝ ██║   ██║
      ██╔══██║██║╚██╗██║ ███╔╝  ██╔══██║██║  ╚██╔╝  ██║   ██║
      ██║  ██║██║ ╚████║███████╗██║  ██║██║   ██║   ╚██████╔╝
      ╚═╝  ╚═╝╚═╝  ╚═══╝╚══════╝╚═╝  ╚═╝╚═╝   ╚═╝    ╚═════╝
        
        `,
    "已上线",
    dnum,
    "天",
    "©2020 By 安知鱼 V1.6.12",
  ];
  const ascll2 = [`NCC2-036`, `调用前置摄像头拍照成功，识别为【小笨蛋】.`, `Photo captured: `, `🤪`];

  setTimeout(
    Log.bind(
      console,
      `\n%c${ascll[0]} %c ${ascll[1]} %c ${ascll[2]} %c${ascll[3]}%c ${ascll[4]}%c ${ascll[5]}\n\n%c ${ascll[6]}\n`,
      "color:#425AEF",
      "",
      "color:#425AEF",
      "color:#425AEF",
      "",
      "color:#425AEF",
      ""
    )
  );
  setTimeout(
    Log.bind(
      console,
      `%c ${ascll2[0]} %c ${ascll2[1]} %c \n${ascll2[2]} %c\n${ascll2[3]}\n`,
      "color:white; background-color:#4fd953",
      "",
      "",
      'background:url("https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/tinggge.gif") no-repeat;font-size:450%'
    )
  );

  setTimeout(Log.bind(console, "%c WELCOME %c 你好，小笨蛋.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(
      console,
      "%c ⚡ Powered by 安知鱼 %c 你正在访问 XIAO YANG 的博客.",
      "color:white; background-color:#f0ad4e",
      ""
    )
  );

  setTimeout(Log.bind(console, "%c W23-12 %c 你已打开控制台.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(console, "%c S013-782 %c 你现在正处于监控中.", "color:white; background-color:#d9534f", "")
  );
});</script><script async src="/anzhiyu/random.js"></script><div class="js-pjax"><input type="hidden" name="page-type" id="page-type" value="post"></div><script>var visitorMail = "";
</script><script async data-pjax src="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/waterfall/waterfall.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/qrcodejs/1.0.0/qrcode.min.js"></script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.9/icon/ali_iconfont_css.css"><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/aplayer/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.cbd.int/anzhiyu-blog-static@1.0.1/js/APlayer.min.js"></script><script src="https://cdn.cbd.int/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script src="https://cdn.cbd.int/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]
var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {
  // removeEventListener scroll 
  anzhiyu.removeGlobalFnEvent('pjax')
  anzhiyu.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/yangxiao.github.io/404.html')
  }
})</script><script charset="UTF-8" src="https://cdn.cbd.int/anzhiyu-theme-static@1.1.5/accesskey/accesskey.js"></script></div><div id="popup-window"><div class="popup-window-title">通知</div><div class="popup-window-divider"></div><div class="popup-window-content"><div class="popup-tip">你好呀</div><div class="popup-link"><i class="anzhiyufont anzhiyu-icon-arrow-circle-right"></i></div></div></div></body></html>